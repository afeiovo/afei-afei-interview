# 1. 计算机网络

## 1.1 分层模型

### 1.1.1 TCP/IP五层模型：

**应用层**：负责为【应用程序】提供交互服务。在互联网中的应用层协议很多，如域名系统DNS、HTTP协议、SMTP协议等。 

**传输层**：负责为【两台主机进程】之间的通信提供数据传输服务。传输层的协议主要有【传输控制协议TCP】和【用户数据协议UDP】。 

**网络层**：为【两台主机】提供通信服务，选择合适的【路由和交换结点】，确保数据及时传送。主要包括IP协议。 

**数据链路层**：将网络层交下来的 IP 数据报组装成【帧】，在两个【相邻节点】间的链路上传送帧。 

**物理层**：实现【相邻节点】间【比特流】的透明传输，尽可能屏蔽传输介质和物理设备的差异。

<img src="D:/Typora/picture/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDQwMzAwMw==,size_16,color_FFFFFF,t_70.png" alt="img" style="zoom: 80%;" />

### 1.1.2 为什么分层

大问题化小：将复杂的网络间题分解为许多界线清晰简单的小问题来处理。使得计算机网络系统变得易于设计和标准化。

提高可扩展性和灵活性：各层之间相互独立，每一层只需负责如何向上层提供功能接口，一层的结构发生变化不会影响其他层。

### 1.1.3 路由器和交换机区别

路由器属于【网络层】，主要工作是依据【IP地址】进行寻址，转发。

交换机属于【数据链路层】，主要工作是依据【MAC地址】进行过滤，转发。

每一个路由器与其之下连接的设备，其实构成一个【局域网】;交换机工作在路由器之下，也就是交换机工作在局域网内。

交换机用于【局域网内网】的数据转发；路由器用于【连接局域网和外网】。

## 1.2 HTTP协议

### 1.2.1 协议内容

【超文本传输协议】：就是用来规范超文本的传输，超文本也就是网络上的包括文本在内的各式各样的消息。

HTTP 是一个【无状态协议】，服务器不会主动维护跟【客户端过去所发请求】有关的信息。

### 1.2.2 HTTP协议通信过程

以 TCP 协议作为底层协议，默认端口为 80。通信过程主要如下：

1. 服务器在 80 端口等待客户的请求。
2. 浏览器发起到服务器的 TCP 连接请求（创建套接字 Socket）。
3. 服务器接收来自浏览器的 TCP 连接请求，通过三次握手建立TCP连接。
4. 浏览器与服务器交换 HTTP 消息。
5. 关闭 TCP 连接。

### 1.2.3 HTTP1.0 和 1.1 区别

#### 1. 响应状态码

HTTP/1.1中新加入大量的响应码，比如：

- 100 (Continue)—— 在请求大资源前的预热请求。
- 206 (Partial Content)—— 范围请求的标识码。
- 409 (Conflict)—— 请求与当前资源的状态冲突。
- 410 (Gone)—— 资源已被转移，而且没有转发地址。

#### 2. 缓存策略

缓存技术可以在缓存命中时避免与服务器的交互，节约了大量的网络带宽，降低了用户接收信息的延迟。

HTTP1.1引入了更多的缓存控制策略，例如If-None-Match，可以更灵活的使用缓存策略。

#### 3. 连接方式

HTTP/1.0 默认短连接，也可以通过 Connection： keep-alive 字段开启长链接。

HTTP/1.1 优化为默认长连接模式，默认开启 Connection： keep-alive

#### 4. 带宽优化

- 范围请求
  - HTTP/1.1引入了范围请求（range request）机制，以避免带宽的浪费。
  - 客户端可以在请求中加入`Range`头部，表示请求（只能请求字节型数据）数据的一部分。服务器端可以忽略`Range`头部，也可以返回`Range`响应。
  - 如果一个响应只包含部分数据，将带有`206 (Partial Content)`状态码。
- 状态码100
  - HTTP/1.1中新加入了状态码100。有些较大的文件请求，服务器可能不愿意响应，状态码100表示请求会被正常响应。

#### 5. Host头处理

在HTTP1.0中认为每个IP地址对应一个主机，因此请求消息中没有传递主机名(hostname)

但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。

HTTP1.1的请求消息和响应消息【都支持Host头域】，用来表示【主机名】，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。

### 1.2.4 HTTP1.1 和 2.0 区别

HTTP2.0使用了【多路复用】的技术，同一个连接中可以【并发处理多个请求】。

HTTP2.0使用HPACK算法对【头部数据进行压缩】，进一步减小数据体积，节约网络带宽。

HTTP2.0引入了【服务器推送】，允许服务端推送资源给浏览器，例如客户端请求 html，服务端可以主动推送 js、css 文件。

HTTP1.x的【解析】是基于文本，HTTP2.0的协议解析采用【二进制格式】，实现方便且更加健壮。

### 1.2.5 状态码

#### 1. 状态码分类

1xx：表示服务器收到请求，需要请求者继续执行操作

2xx：表示请求成功。

3xx：表示重定向。

4xx：表示请求错误。

5xx：服务器端错误。

#### 2. 常见状态码

100 Continue。

200 请求成功。

301 永久重定向，页面永久性转移，表示为资源或页面永久性地转移到了另一个位置。

302 临时重定向，页面暂时性转移，表示资源或页面暂时转移到另一个位置

400 请求错误

403 服务器禁止访问

404 资源未找到

500 服务器端错误

503 服务器繁忙

### 1.2.6 cookie和session

HTTP协议是无状态的协议，可以使用cookie与session来保存会话状态信息。

Cookie 保存在客户端，常用于保存用户认证信息，发起请求时进行【用户认证】。

Session 保存在服务端，常用于用来跟踪【用户状态】，这个数据可以保存在集群、数据库、文件中。

*区别：*

- 作用【范围】不同，Cookie 保存在客户端，Session 保存在服务器端。 
- 【安全性】不同，Cookie 存储在客户端，容易被窃取；Session 存储在服务端，安全性相对更高。 
- 【有效期】不同，Cookie 可设置为长时间存活，比如我们经常使用的自动登录功能，Session 一般失效时间较短，【Session 超时】会失效。 
- 【存储大小】不同， 单个 Cookie 保存的数据不能超过 4K；对于 Session 来说存储没有上限，但出于对服务器的性能考虑，Session 内不要存放过多的数据，并且需要设置 Session 删除机制。

### 1.2.7 请求转发和重定向

请求转发：客户端发起请求后，Web服务器根据请求进行处理和转发，然后跳转到另一个目标资源，并将该资源返回。

重定向：客户端发起请求后，Web服务器返回3xx状态码表示重定向，并将重定向地址写到响应头的location属性中，客户端根据这个路径再次发起请求。

*区别：*

1. 重定向是【客户端】的跳转，而转发是【服务器】内部的资源跳转。
2. 转发只有一个请求，而重定向有两个不一样的请求。转发的页面能够通过【request作用域】来传递数据，而重定向不能。
3. 重定向会改变【请求地址】，而转发不会改变请求地址。
4. 重定向可以【跨域访问】，转发则不能。
5. 转发能够访问【WEB-INF目录】下的页面，而重定向不能。

### 1.2.8 HTTP报文格式

HTTP请求由【请求行】、【请求头】、【空白行】和【请求体】组成。

- 请求行：包括【请求方法】，访问的【资源URL】，【HTTP版本】
- 请求头：格式为“属性名:属性值”，包括：cookie、host、connection、accept-language、accept-encoding。
- 请求体：用户的请求数据如用户名，密码等。

HTTP响应由【状态行】、【响应头】、【空白行】和【响应体】组成。

- 状态行：【协议版本】，【状态码】及【状态描述】。 
- 响应头：主要有set-cookie、connection、content-type、content-encoding、content-length。 
- 响应体：服务器返回给客户端的内容。

### 1.2.9 POST和GET的区别？

1. GET【请求参数】通过URL传递，POST的参数放在请求体中。
2. GET产生一个【TCP数据包】；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把请求头和请求体一并发送出去；而对于POST，浏览器先发送请求头，服务器响应100 continue，浏览器再发送请求体。
3. GET请求会被浏览器【主动缓存】，而POST不会，除非手动设置。
4. GET请求参数会被完整保留在浏览器【历史记录】里，而POST中的参数不会被保留。
5. GET请求只能进行url编码，而POST支持多种【编码方式】。
6. 获取资源常用get，表单提交常用post。

### 1.2.10 短连接与长连接区别

短连接：浏览器每发起一次HTTP请求，就建立一次TCP连接，数据发送完成后，则断开此连接。

- 每次http请求都要通过三次握手建立tcp连接，比较耗时。
- 并发量大，但每个用户无需频繁操作情况下需用短连接好。

长链接：可以复用一个 TCP 链接来发起多次 HTTP 请求，一次http请求结束后不会断开tcp连接。

- 多次http请求无需频繁通过三次握手建立tcp连接，但是并发量很大可能需要维护大量socket。
- 长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。

### 1.2.11 HTTP与HTTPS的区别

1. HTTP信息是明文传输；HTTPS信息是【加密传输】。  
2. 【端口】不一样，HTTP默认端口是80，HTTPS默认是443。 
3. HTTP运行在TCP协议之上；HTTPS运行在【SSL协议】之上，SSL运行在TCP协议之上。
4. HTTPS协议需要到【CA机构】申请证书，一般需要一定的费用。 

## 1.3 HTTPS 协议

HTTPS 是基于 HTTP 的，也是用 TCP 作为传输层协议，并额外使用 SSL/TLS 协议用作【消息加密】和【安全认证】。默认端口号是 443。

HTTPS 协议中，SSL 通道通常使用基于密钥的加密算法。

https 协议优点：

- 保密性好、信任度高。

### 1.3.1 SSL/TLS协议

SSL 指【安全套接字协议】，SSL3.0升级后，新版本被命名为 TLS 1.0。因此，TLS 是基于 SSL 之上的 。

### 1.3.2 SSL/TLS 的工作原理

- 【通信消息传输】使用的是【对称加密】。
- 【密钥的传输】使用的是【非对称加密】。

#### 非对称加密

非对称加密采用两个密钥：一个公钥，一个私钥。

在通信时，私钥仅由解密者保存，公钥由任何一个想与解密者通信的发送者所知，加密算法已知。

安全性更高，但是计算量大很多。

保密性：公钥加密的信息只有私钥拥有者可以解密，需要认证公钥对应的真实身份。通过CA机构。

#### 对称加密

通信双方共享唯一密钥 k，加解密算法已知，加密方利用密钥 k 加密，解密方利用密钥 k 解密。

保密性：依赖于密钥 k 的保密性。

#### CA进行公钥认证

【证书颁发机构】CA验证某实体身份后，会生成一个证书，证书内容中包含【公钥和公钥所有者的标识信息】，以及自己的【数字签名】。

发送方发送数据时，会带上其CA签署的证书，接收方使用CA的公钥解密，验证身份信息。

**什么是数字证书：**

- 服务端可以向CA申请证书(服务端通过非对称加密将自己的标识信息和公钥发给CA)，以避免中间人攻击。
- 证书包含三部分内容：【证书内容(服务端公钥和标识信息)】、【证书签名算法】和【签名】，签名是为了验证身份。

#### 数字签名

发送报文时生成数字签名：初始报文s经过【散列函数】生成H(s)，使用【私钥加密】，得到数字签名，将数字签名附在报文后面发送(s,K-(H(s)))。

接收方如何验证：对报文s使用散列函数得到H(s)，通过对应公钥解密数字签名得到(H(s)),对比是否相同。

### 1.3.3 HTTPS连接过程

1. 客户端发送自己支持的【加密算法】给服务器。
2. 服务器选择一套【加密算法】和【hash 算法】以及自己的【证书】发送给浏览器，证书中包含服务器信息，加密公钥，证书的颁发机构。
3. 客户端接收信息：

   - 使用CA机构的公钥【验证证书】的合法性，成功后也就得到了【服务器公钥】。
   - 然后生成【客户端密钥】，并用服务器公钥进行加密。
   - 用约定好的 hash 算法计算第一次握手消息，然后用客户端密钥进行加密，然后一起发送给服务器。
4. 服务器接收信息：

   - 用自己的私钥解析出【客户端密钥】，用客户端密钥解析握手消息，验证 hash 值。

   - 使用客户端密钥加密第二次握手消息，发送给客户端。
5. 这时双方都拥有了一个客户端密钥，后续消息都用这个密钥进行【对称加密】。

## 1.4 TCP协议

### 1.4.1 特点

- TCP是【面向连接】的【运输层协议】，通信之前需要先建立连接。
- TCP提供【可靠交付】的服务。
- TCP协议是面向【字节流】的。
- TCP提供【全双工通信】。
- 每一条TCP连接只能有【两个端点】。

### 1.4.2 三次握手

初始时刻客户端处于 CLOSED 状态，服务端处于 LISTEN 状态。

第一次握手：客户端–发送 SYN 报文，表示请求建立TCP连接，此时客户端处于 SYN_Send 状态。

第二次握手：服务端收到后-发送 SYN/ACK 报文，此时服务器处于 SYN_RCVD 的状态。

第三次握手：客户端收到后-发送一个 ACK 报文，此时客户端处于 established 状态。

服务器收到 ACK 报文之后，也处于 established 状态，此时，双方建立链接完成。

syn报文表示发起连接请求，并初始化自己的序列号，ack报文会对已收到的序列号进行确认，TCP协议为了保证可靠传输，要求双方维护一个【序列号】来标识发送的数据包，三次握手的过程即是通信双方相互告知序列号起始值，并确认对方已经收到。

<img src="D:/Typora/picture/0c9f470819684156cfdc27c682db4def.png" alt="img" style="zoom:80%;" />

#### 为什么要三次握手

- 为了实现【可靠数据传输】，TCP 协议的通信双方，都必须维护一个【序列号】，以标识发送出去的数据包中。
- 三次握手的过程即是通信双方相互告知序列号起始值，并确认对方已经收到。
- 如果只是两次握手，至多只有连接发起方的起始序列号能被确认，另一方选择的序列号则得不到确认。

#### 什么是半连接队列

服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，服务器会把此种状态下请求连接放在【半连接队列】中。

【全连接队列】就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

#### 握手过程可以携带数据吗

第三次握手的时候是可以携带数据的。

如果第一次握手可以携带数据，攻击者可以发送大量带有数据的 SYN 报文攻击服务器，让服务器花费很多时间、内存空间来接收这些报文，服务器易受攻击。

对于第三次的话，此时客户端已经处于【established状态】，并且也已经知道服务器的初始化【序列号】，所以能携带数据。

#### 如果最后一次握手丢失

服务端：处于 SYN_RCVD 状态，连接放在【半连接队列】中，未收到 ack 报文，依次等待3秒、6秒、12秒后重新发送SYN+ACK包，重发多次（默认5次）还未收到 ack ，则断开连接。

客户端：发送 ack 后进入 established 状态，如果正常发送数据，服务端将以 RST 报文（Reset，标示复位，用于异常的关闭连接）响应。

#### ISN动态生成

- 为了防止历史报文被下一个相同四元组的连接接收（主要方面）；

- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

### 1.4.3 四次挥手

第一次挥手：客户端发送一个 FIN 报文，表示关闭连接请求，客户端进入fin_wait_1状态。 

第二次挥手：服务端收到后，发送一个ACK给客户端，服务端进入Close_wait状态，客户端收到后进入fin_wait_2状态。此时TCP连接处于【半关闭状态】，客户端已经没有要发送的数据了，但服务端仍可以发送数据。

第三次挥手：服务端发送一个 FIN 报文，用来关闭服务端到客户端的数据传送，服务端进入Last_ack状态。

第四次挥手：客户端收到FIN后，客户端进入Time_wait状态，接着发送一个ACK给服务端，服务端收到后进入Closed状态，完成四次挥手。

<img src="D:/Typora/picture/0520AF3D1F33E3F90D8DBA75BA5A3B10.png" alt="img" style="zoom:80%;" />

#### TIME-WAIT状态

确保服务器是否已经收到了客户端的 ACK 报文。

如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。

#### 为什么四次挥手

主要原因是当服务端收到客户端的 FIN 数据包后，服务端可能还有数据没发完，不会立即close。

所以服务端会先先发送一个 ACK 报文，发送完剩下的数据后，在发送 FIN 报文（也就是断开连接请求），客户端需要收到 FIN 包后发送 ACK 确认断开信息给服务端。

### 1.4.4 TCP 如何实现可靠传输

应用数据被分割成 TCP 认为最适合发送的数据块。

【校验和】

- 发送方对数据求出校验和填充在tcp头部对应位置
- 接收方使用相同算法对数据计算校验和，并与发送方计算结果对比，不同则抛弃这个报文。

【序列号】

- TCP 传输时将每个报文都进行了编号，这就是序列号。

- 序列号的作用:标识数据包，接收方根据序列号进行数据重排，并且去掉重复的数据。


【ACK 确认应答】和【超时重传】

- 接收方接收到消息，返回一个对应的 ACK 报文，发送方在等待时间内未收到 ack 会进行重传。

- 如果尝试成功，则继续发送后面的包。若尝试几次均失败，那么 TCP 会强行断开连接，发送 RST 信息。并告知应用程序连接错误。


【流量控制】

- 为了避免发送方的发送速度太快，导致接收方的接收缓冲区填满来不及接受。接收端可以限制发送端的发送速度。 

- 具体实现方式：

  - 发送方维护一个【接收窗口】变量，发送方【滑动窗口】不能大于这个【接收窗口】。

  - 接收方接收到消息后，返回ack报文，将【剩余缓存大小】放入ack报文的【接收窗口大小字段】中，限制发送方【接收窗口】。


【拥塞控制】

- 避免网络拥塞。


### 1.4.5 ARQ 协议

【自动重传请求】（Automatic Repeat-reQuest，ARQ）：是 OSI 模型中【数据链路层】和【传输层】的【错误纠正协议】之一。

通过使用【确认应答】和【超时重传】这两个机制，在不可靠服务的基础上实现可靠的信息传输。

如果发送方在发送后一段时间之内没有收到确认消息，就会重新发送。

### 1.4.6 滑动窗口

TCP 利用滑动窗口实现流量控制的机制。

TCP发送方会维护两个变量，【未被确认报文的最小序号LastByteAcked】 和 【下一个要发送的报文序号LastByteSent】,两者组成滑动窗口，两者差值就是【已发送但未被确认的报文数量】，不能超过【接收窗口】和【拥塞窗口】的最小值。

<img src="D:/Typora/picture/image-20220515222739613.png" alt="image-20220515222739613" style="zoom: 67%;" />

### 1.4.7 TCP差错恢复机制

TCP仅仅维持【已发送的但未被确认的最小序号】，而不是维护所有已发送序号。从这个方面来看TCP的差错恢复机制有点像【GBN】（向后回退N步）。

另一方面，得知一个报文丢失后，TCP只会要求重新发送接受失败的分组，而不是要求其后分组全部重新发送。所以TCP又结合了【SR(选择重传)】的优点。

TCP差错恢复机制：【选择确认】（selective acknowledgment）

### 1.4.8 拥塞控制

防止发送方发的太快，使得网络来不及处理，从而导致网络拥塞。

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。

- 流量控制是为了让接收方能来得及接收

- 拥塞控制是为了降低整个网络的拥塞程度

  

*TCP 的拥塞控制采用的算法：* **慢启动**、**拥塞避免** 和 **快速恢复**。

【慢启动】：TCP连接刚开始时，进入慢启动状态，cwnd(拥塞窗口) 设置为1，每过一个RTT(往返时间)，cwnd翻倍。

【拥塞避免】：cwnd到达ssthresh(慢启动阈值)后，说明快要造成网络拥挤，减缓cwnd上升速度，进入拥塞避免状态，每过一个RTT,cwnd+1。

如果发生超时重传：说明网络拥挤，ssthresh设置为cwnd的一半，重新开始慢启动，cwnd设置为1。

如果接收到3个冗余ack发生【快速重传】：说明网络没有造成拥挤，进入【快速恢复】，ssthresh设置为cwnd的一半，将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。

<img src="D:/Typora/picture/6B36EF80E9A7EFF22EF4B93EA879951F.png" alt="img" style="zoom: 65%;" />

### 1.4.9 粘包和拆包

TCP 发送数据时会根据 TCP 缓冲区的实际情况进行包的划分。

拆包：一个完整的包可能会被 TCP 拆分成多个包进行发送。

粘包：可能把多个小的包封装成一个大的数据包发送。

#### TCP 粘包原因

1. 传输层接收到应用层的消息后，并不会马上发送，为了优化网络，系统内核会将消息写入发送缓冲区中，当【时钟超时】或【缓冲区满】时才会打包发送。
2. 发送的数据小于 TCP 缓冲区大小，TCP 将缓冲区中多个包的数据一次发送出去可能就会发生粘包。
3. 或者接收端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

#### TCP 拆包原因

1. 待发送数据大于【最大报文长度】，TCP 在传输前将进行拆包。
2. 或者待发送的数据大于【TCP发送缓冲区剩余空间】大小。

#### 粘包解决方案

发送端给每个数据包【添加长度信息】，接收端根据实际长度解析数据。

发送端将每个数据包【设置固定长度】，接收端读取固定长度的数据把多个数据包拆分开。 

可以在数据包之间【设置边界】，如添加特殊符号，接收端可以通过这个特殊符号来拆分包。

### 1.4.10 四元组标识socket

TCP使用四元组（源IP，源端口,目标IP，目标端口）来标识一个TCP套接字。

UDP使用的是二元组（源端口，目标端口）来标识。

为什么不能使用二元组：

- TCP是面向连接的传输协议，每一个连接都会有一个对应的socket管理，与不同客户端建立连接需要四元组区分。

- TCP是流式协议，UDP是数据报协议。TCP有粘包的问题，而UDP没有，UDP有消息边界。

  出现粘包现象时，接收方可以通过四元组区分哪个包属于哪台主机。

## 1.5 UDP协议

### 1.5.1 TCP 和 UDP 的区别

TCP【面向连接】；UDP是无连接的，即发送数据之前不需要建立连接。

TCP提供【可靠的传输服务】；UDP不保证可靠交付。

每一条TCP连接只能有【两个端点】；UDP支持一对一、一对多、多对多的通信方式。

TCP面向【字节流】，把数据看成一连串无结构的字节流；UDP是面向报文的。

TCP【首部开销】20字节；UDP的首部开销小，只有8个字节。

TCP有【拥塞控制】；UDP没有拥塞控制，因此网络出现拥塞不会使发送方的发送速率降低（对实时应用很有用，如实时视频会议等）。

### 1.5.2 UDP如何实现可靠传输

传输层无法保证数据的可靠传输，可以通过应用层来实现了。

最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。

- 添加【序列号】机制，使用序列号标识每个数据包，接收端根据序列号进行重排。
- 添加【确认应答】和【超时重传】机制，接收方接收到消息，返回一个对应的 ACK 报文，发送方在等待时间内未收到 ack 进行重传。
- 添加【滑动窗口】机制，进行流量控制。

## 1.6 DNS协议

### 1.6.1 DNS协议解析过程

1. 【浏览器】搜索自己的DNS缓存。

2. 若没有，则搜索【操作系统】中的DNS缓存和hosts文件。

3. 若没有，则操作系统将域名发送至【本地域名服务器】，【本地域名服务器】查询自己的DNS缓存，查找成功则返回结果，否则依次向【根域名服务器】、【顶级域名服务器】、【权威域名服务器】发起查询请求，最终返回IP地址给本地域名服务器。

4. 【本地域名服务器】将得到的IP地址返回给操作系统，同时自己也将IP地址缓存起来。

5. 操作系统将 IP 地址返回给浏览器，同时自己也将IP地址缓存起来。

6. 浏览器得到域名对应的IP地址。


### 1.6.2 DNS使用的传输层协议

【TCP协议】和【UDP】协议都会使用，并且使用的都是53号端口。

当进行【区域传送】时会使用 TCP，因为数据同步传送的【数据量较多】，并且为了保证数据的【正确性】，会使用基于可靠连接的 TCP。

【域名解析】的时候使用UDP协议，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手建立连接，这样DNS服务器负载更低，响应更快。

## 1.7 浏览器输入URL地址

1. 首先要进行DNS域名解析，根据输入的域名得到访问主机的IP地址。

2. 得到IP地址后生成TCP套接字，通过三次握手与服务器建立TCP连接。

3. 生成HTTP请求报文，发送HTTP请求。

4. 服务器处理请求并返回HTTP报文。

5. 浏览器解析响应报文，渲染页面。


# 2. 操作系统

## 2.1 基础

### 2.1.1 什么是操作系统

1. 操作系统本质上是一个运行在计算机上的【软件程序】，用于管理计算机【硬件】和【软件资源】，操作系统为应用软件【屏蔽了硬件层的复杂性】。
2. 操作系统的【内核】是操作系统的核心部分，它负责系统的【内存管理】，【硬件管理】，【文件管理】以及【应用程序管理】。
3. 【内核】是连接应用程序和硬件的桥梁，决定着系统的【性能】和【稳定性】。

### 2.1.2 操作系统目的

操作系统是一种软件,它的主要目的有三种

- 管理计算机资源,包括CPU、内存等。
- 提供一种图形界面,提供了用户和计算机之间的桥梁。
- 为其他软件提供服务,操作系统与软件进行交互,以便为其分配运行所需的任何必要资源。

### 2.1.3 系统调用

#### 1. 内核模式和用户模式

为了保护系统安全，用户程序不能随意访问和修改计算机所有的资源，为此将CPU分为两种模式，【内核模式】和【用户模式】。

比如文件管理、进程控制等操作只能在高权限的【内核模式】下进行，用户模式下没有权限进行。

#### 2. 系统调用概念

为了让【用户程序】可以受限制的使用【系统态级别】的功能，操作系统提供给用户程序一系列能够实现特定功能的函数接口，也就是系统调用。

#### 3. 系统调用过程

- 发起系统调用通常使用【trap指令】，然后进入特定的【中断处理程序】，并将特权级别提升到【内核模式】，【操作系统】获得CPU使用权。
- 内核模式下，操作系统拥有访问所有资源的权限，完成系统调用的功能。
- 完成后通过【return-from-trap指令】将CPU控制权交给用户，CPU进入用户模式，继续执行用户程序。

#### 4. 系统调用分类

- 内存管理。完成内存的【分配】、【回收】以及获取【作业占用内存区大小及地址】等功能。
- 文件管理。完成文件的【读】、【写】、【创建】及【删除】等功能。
- 设备管理。完成设备的【请求】或【释放】，以及【设备启动】等功能。
- 进程控制。完成进程的【创建】、【撤销】、【阻塞】及【唤醒】等功能。
- 进程通信。完成进程之间的【消息传递】或信号传递等功能。

### 2.1.4 Synchronized耗时、内核态切换耗时

Synchronized 是基于底层操作系统的【Mutex Lock】实现的，每次获取和释放锁操作都会带来用户态和内核态的切换，从而增加系统性能开销。

切换到内核态开销：

1. 切换线程上下文，需要【保护和恢复寄存器数据】。

2. 切换到执行内核线程的时候，内核代码对用户【不信任】，需要进行【额外的检查】。

3. 内核线程执行完返回用户进程时也会做很多额外工作，比如检查【是否需要调度】等。

4. 如果被切换的线程属于不同进程的话，那么还要更新【cr3寄存器】，也就是更换页表的地址。

   【cr3寄存器】用来存放【页表】物理内存基地址。

### 2.1.5 中断

中断可以使CPU从【用户态切换为核心态】,并且中断是CPU从用户态->核心态切换的【唯一途径】。 

核心态->用户态切换只需要执行一个特权指令，将PSW设置为0。

中断分类：

- 内中断(异常/例外/陷入)：信号来源CPU内部，与当前执行的指令有关
  - 陷阱、陷入(trap)：有意而为之的异常，系统调用。

  - 故障(fault)：可能被【故障处理程序】修复的错误，如缺页。

  - 终止(abort)：致命错误，无法修复，【终止处理程序】不再将控制返回给应用程序，如除0。
- 外中断(狭义中断)：信号来源CPU外部，与当前执行的指令无关
  - 外设请求：外设(比如打印机)I/O操作完成发出中断信号 
  - 人工干预：用户强制终止一个进程


## 2.2 进程和线程

### 2.2.1 基本概念

进程：

- 一个在内存中运行的应用程序。每个进程都拥有自己【私有的地址空间】和【独立的资源】。

- 进程特点：
  - 独立性：每个进程都拥有自己【私有的地址空间】和【独立的资源】，一般不可以直接访问其他进程的地址空间。
  - 动态性：进程与程序的区别在于,程序只是一个静态的指令集合,而进程是一个正在系统中活动的指令集合。
  - 并发性：多个进程可以在单个处理器CPU上并发执行,多个进程之间不会互相影响。

线程：

- 线程是进程中实际【运行指令的实体】，也是【CPU调度和分派】的基本单位。
- 一个进程中可以运行多个线程，多个线程可共享进程中数据。线程也被称为轻量级进程。

### 2.2.2 进程和线程区别

【根本区别】：进程是操作系统【资源分配】的基本单位；而线程是【任务调度和执行】的基本单位。

【资源分配】：每个进程都拥有自己【内存】和【资源】；一个进程中的线程共享本进程的【内存】和【资源】。

【切换开销】：进程切换会有【虚拟地址空间】的切换，导致【快表失效】，进程切换开销较大；线程共享本进程的【地址空间】，线程之间切换的开销较小。

【执行过程】：每个独立的进程有【程序入口】、【顺序执行序列】和【程序出口】；线程不能独立执行，必须依存在应用程序中，由应用程序管理。

【影响关系】：一个进程崩溃后，在保护模式下不会对其他进程产生影响；一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

*什么是协程：*

- 协程本质上就是一个【用户态的线程】，实现一个协程库也实际就是去实现一个【用户态的调度器】。

*协程切换比线程切换快的原因：*

1. 协程切换完全在【用户空间】进行，线程切换涉及特权模式切换，需要在【内核空间】完成。
2. 协程切换相比线程切换做的事情更少

### 2.2.3 进程状态

- 创建状态(new) ：进程正在被创建，尚未到就绪状态。

- 就绪状态(ready) ：进程已处于准备运行状态，一旦得到处理器资源即可运行。

- 运行状态(running) ：进程正在处理器上运行。

- 阻塞状态(waiting) ：正在运行中的进程因发生某等待事件而无法执行，主动进入阻塞状态，让出CPU资源。进程调度不会考虑阻塞进程。

- 结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

  <img src="D:/Typora/picture/image-20210907124303344.png" alt="image-20210907124303344" style="zoom:80%;" />

### 2.2.4 进程控制

*原语：*

执行期间不允许中断，采用“关中断指令”和“开中断指令”实现的。(这两个指令是特权指令)

<img src="D:/Typora/picture/image-20220329001830478.png" alt="image-20220329001830478" style="zoom:50%;" />

进程状态转换需要同时改变【PCB信息】和相应的【PCB队列】。为了保证这两步同时成功，需要使用原语。

进程控制会导致进程状态的转换。无论哪个原语,要做的无非三类事情: 

- 更新PCB中的信息(如修改【进程状态标志】、【将运行环境保存到PCB】、【从PCB恢复运行环境】)    
- 将PCB插入合适的队列。
- 分配/回收资源。

### 2.2.5 进程通信(七种)

https://www.jianshu.com/p/c1015f5ffa74

每个进程都有独立的【用户地址空间】，任何一个进程的【全局变量】在另一个进程中都看不到，所以进程之间要交换数据必须通过【内核】，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区读取数据，内核提供的这种机制称为【进程间通信（IPC，InterProcess Communication）】

#### 管道/匿名管道(pipe)

调用`int pipe(int pipefd[2]);`，传入一个长度为2的int数组用来接收【文件描述符】，返回值0表示成功，-1表示失败。

例如：在fork函数执行前创建管道，fork执行后父子进程可以共享这个【文件描述】符，可以调用read和write函数传入文件描述符，对管道进行读写。

管道默认是【阻塞】的：如果管道中没有数据，read阻塞，如果管道满了，write阻塞。

*特点：*

1. 管道是【半双工】的，数据只能向一个方向流动。
2. 没有名字，只能用于【父子进程或者兄弟进程】之间。
3. 管道对于管道两端的进程而言，就是一个【文件】，可以进行读操作和写操作，没有文件节点，并且只存在于内存中。
4. 管道的【缓冲区大小有限】（管道只存在于内存中，在管道创建时，为缓冲区分配一个页面大小）。
5. 管道所传送的是【无格式字节流】，管道的读写进程需要约定好数据的格式。

*实质：*

- 管道的实质是一个【内核缓冲区】。
- 管道的数据结构一个【循环队列】，维护读指针和写指针，一个数据只能读取一次。

```c
#include <unistd.h>
int pipe(int pipefd[2]);
/*
    功能：创建一个匿名管道，用来进程间通信。
    参数：int pipefd[2] 这个数组是一个传出参数。
        pipefd[0] 对应的是管道的读端
        pipefd[1] 对应的是管道的写端
    返回值：
        成功 0
        失败 -1

管道默认是阻塞的：如果管道中没有数据，read阻塞，如果管道满了，write阻塞
*/
```

```c
#include <unistd.h>
#include <sys/types.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

//创建管道，父子进程间通信
int main(){

    //管道应在fork之前创建
    int pipefd[2];
    int ret = pipe(pipefd);//创建一个管道，传入int数组，接受文件描述符。
    
    if(ret == -1){//如果创建失败
        perror("pipe");
        exit(0);
    }

    pid_t pid = fork();//fork 出一个子进程。

    if(pid == 0){//pid为0,表示子进程代码
        printf("child process, pid : %d \n",getpid());
        //子进程关闭读端
        close(pipefd[0]);

        while(1){
            char * str = "床前明月光，疑是地上霜";
            write(pipefd[1],str,strlen(str));
            sleep(1);
        }
    }else if(pid > 0){
        printf("parent process, pid : %d \n",getpid());

        //父进程关闭写端
        close(pipefd[1]);

        //从读端读取数据
        char buf[1024] = {0};
        while(1){
        
            int len = read(pipefd[0],buf,sizeof(buf));

            printf("parent recv : %s \n",buf);

            memset(buf,0,sizeof(buf));  //清空缓冲区
            sleep(1);
        }
    }
}
```

#### 有名管道(FIFO)

在文件系统中存在一个【文件节点】，文件类型是【管道文件】，没有亲缘关系的进程，只要可以访问该路径，就能够通过有名管道进行通信。

管道文件只有【inode号】，【不占磁盘空间】，【内容只存放在内存中】，和【套接字】、【字符设备文件】、【块设备文件】一样。

*什么是inode号：*

- 【硬盘的最小存储单位】叫做【扇区】，多个扇区组成【块】，是【文件存取的最小单位】。文件数据都储存在【块】中，而储存文件的【元信息】的区域叫做inode，也就是【索引节点】。
- inode包括：【文件字节数】、文件【拥有者的User ID】、【文件的Group ID】、【文件的读、写、执行权限】等信息。

*具体过程：*

- 调用`int mkfifo(const char *pathname, mode_t mode);`创建管道文件，传入【文件路径名】和【文件权限】，返回一个int结果，0表示成功，1表示失败。
- `mkfifo`:用来创建【管道文件】的节点，还没有在内核中创建管道；只有通过 open 函数打开这个文件时，才会在内个空间创建管道。

*FIFO与pipe管道区别：*

1. FIFO 在文件系统中存在一个【文件节点】，不相关的进程只要可以访问该文件路径，就能进行通信。
3. 当使用 FIFO 的【进程退出】后，FIFO 文件将继续保存在文件系统中，之后可以直接使用。

```c
#include <sys/types.h>
#include <sys/stat.h>
int mkfifo(const char *pathname, mode_t mode);
/*
功能： 创建管道文件。
参数：
    - pathname: 管道名称的路径
        - mode: 文件的权限 和 open 的 mode 是一样的
            是一个八进制的数
            返回值：成功返回0，失败返回-1，并设置错误号
*/
```

#### 信号(Signal)

信号是软件层次上对【中断机制】的一种模拟，是一种【异步通信】方式。

一个进程【产生信号】传给操作系统，【操作系统】将信号传给对应的接收进程，【接收进程】根据信号内容选择对应的【中断处理程序】执行。

*命令举例：*

- `kill -l`命令：可以查看系统中都有哪些信号；
- `kill 信号 进程pid`命令：进行信号通信，举例：`kill 9 进程pid`通过信号通信杀死一个进程，实际上是kill命令进程调用了【kill函数】。

*信号可以有两个来源：*

- 【硬件来源】：比如【输入Ctrl+C】会给进程发送信号SIGINT(2号)、硬件异常如【无效的存储访问】等。
- 【软件终止】：使用【kill命令】,调用【kill函数】或【raise函数】、【alarm函数】等。

*信号的特点：*

- 使用简单，优先级比较高。
- 但是不能够传递大量信息，并且满足某个特定条件时才发送。

*发送信号函数：*

- `int kill(pid_t pid, int sig);`：给任何的进程或者进程组pid, 发送任何的信号 sig。
- `int raise(int sig);`：只能给当前进程发送信号。
- `unsigned int alarm(unsigned int seconds);`：设置一个定时器，倒计时结束后向当前进程发送SIGALARM（14号）信号，默认终止进程。

*信号处理函数：*

- `signal(int signum , void(*handler)(int));`：传入一个【信号值】和一个【方法指针】，设置这个信号对应的处理函数。
- `int sigaction(int signum, const struct sigaction *act,struct sigaction *oldact);`

*僵尸进程：*

- 子进程结束时，会给父进程传递一个【17号SIGCHLD信号】，默认处理方式是【忽略】这个信号。
- 可以通过signal函数或者sigaction函数，修改这个信号处理函数，信号触发时调用wait回收进程。
- 为了防止在信号注册完之前子进程就结束，在fork子进程之前先阻塞这个信号，注册完信号后再打开SIGCHLD信号。

```c
int kill(pid_t pid, int sig);
/*
    - 功能：给任何的进程或者进程组pid, 发送任何的信号 sig
    - 参数：
        - pid ：
            > 0 : 将信号发送给指定的进程
            = 0 : 将信号发送给当前的进程组
            = -1 : 将信号发送给每一个有权限接收这个信号的进程
            < -1 : 这个pid=某个进程组的ID取反 （-12345）
        - sig : 需要发送的信号的编号或者是宏值，0表示不发送任何信号

    例如：kill(getppid(), 9); 杀死父进程
    kill(getpid(),9); 可以自杀
*/
int raise(int sig);
/*
    - 功能：给当前进程发送信号
    等价于kill(getpid(), sig);   
*/
unsigned int alarm(unsigned int seconds);
/*
    - 功能：设置定时器（闹钟）。函数调用，开始倒计时，当倒计时为0的时候，函数会给当前的进程发送一个信号：SIGALARM（14号）
    - 参数：
        seconds: 倒计时的时长，单位：秒。如果参数为0，定时器无效（不进行倒计时，不发信号）。
                取消一个定时器，通过alarm(0)。
*/
typedef void (*sighandler_t)(int);//回调函数形式 void func(int x)
sighandler_t signal(int signum, sighandler_t handler);
/*
    - 功能：设置某个信号的捕捉行为
    - 参数：
        - signum: 要捕捉的信号
        - handler: 捕捉到信号要如何处理
            - SIG_IGN ： 忽略信号
            - SIG_DFL ： 使用信号默认的行为
            - 回调函数 :  这个函数是内核调用，程序员只负责写，捕捉到信号后如何去处理信号。
            回调函数：
                - 需要程序员实现，提前准备好的，函数的类型根据实际需求，看函数指针的定义
                - 不是程序员调用，而是当信号产生，由内核调用
                - 函数指针是实现回调的手段，函数实现之后，将函数名放到函数指针的位置就可以了。

    - 返回值：
        成功，返回上一次注册的信号处理函数的地址。第一次调用返回NULL
        失败，返回SIG_ERR，设置错误号
*/
int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);
/*
    - 功能：检查或者改变信号的处理。信号捕捉
    - 参数：
        - signum : 需要捕捉的信号的编号或者宏值（信号的名称）
        - act ：捕捉到信号之后的处理动作
        - oldact : 上一次对信号捕捉相关的设置，一般不使用，传递NULL
    - 返回值：
        成功 0
        失败 -1
*/
```


#### 消息队列(Message Queue)

消息队列是存放在【内核】中的【消息链表】，具有【特定的格式】，每个消息队列由【消息队列标识符】标识。

消息队列存放在内核中，只有在【内核重启】或者【显示地删除一个消息队列】时，该消息队列才会被真正的删除。

*与管道对比：*

1. 消息队列允许【多个进程】读写消息，读写消息时不需要另一进程在等待。

2. 消息不一定要以先进先出的次序读取,也可以按【消息类型】读取。

3. 消息队列克服了信号【承载信息量少】，管道【只能承载无格式字节流】以及【缓冲区大小受限】等缺点。


*函数：*

1. `int msgget(key_t key,int flag)`：相当于open，
   - key : 和消息队列关联的key值；可以有两种来源。
   - flag ： 消息队列的访问权限 
   - 如果成功，返回消息队列ID ； 如果失败，返回-1。
2. `int msgctl(int msgqid,int cmd,struct msqid_ds *buf)`：相当于close，
   - msgqid：消息队列ID
   - cmd：IPC_STAT：读取消息队列的属性，并将其保存在buf指向的缓冲区中。
   - cmd：IPC_SET：设置消息队列的属性。这个值取自buf参数。
   - cmd：IPC_RMID：从系统中删除消息队列。
   - buf：消息队列缓冲区。
   - 成功，返回0 ； 失败：返回-1
3. `int msgsnd(int msqid,const void*msgp, size_t size,int flag)`：相当于write，
   - msqid：消息队列ID
   - msgp：指向消息的【指针】，常用结构体 msgbuf，有两个属性：【消息类型】和【消息正文】
   - size：发送的消息正文的字节数
   - flag：IPC_NOWAIT表示消息没有发送完成函数也会立即返回；0表示发送完成函数才返回。
   - 成功返回0 ； 失败返回-1
4. `int msgrcv(int msgid, void* msgp, size_t size, long msgtype， int flag)`：相当于read，
   - msqid：消息队列ID
   - msgp：接受消息的缓冲区
   - size：要接受的消息的字节数
   - msgtype：0表示接受队列中第一个消息；大于0表示接受第一个类型为msgtype的消息；小于0表示接受类型值小于等于msgtype绝对值的消息
   - flag：0表示若无消息会一直阻塞；IPC_NOWAIT表示若没有消息立即返回ENOMSG。
   - 成功返回接受到的消息的长度；失败返回-1。


#### 共享内存(share memory)

多个进程可以直接读写同一块内存空间，数据无需在用户空间和内核空间进行拷贝，是【效率最高】的进程通信方式。

内核专门留出了一块内存区用于【多进程交换信息】，可以由需要访问的进程将其映射到自己的【私有地址空间】。

多个进程共享一段内存，需要依靠某种【同步机制（如信号量）】来实现进程同步。

*特点：*

- 共享内存创建后，一直存在于内核中，直到被删除或系统关闭。
- 和管道不同，读取后，内容仍然在其共享内存中。

*命令：*

- 查看 IPC 对象	ipcs -m
- 删除 IPC 对象    ipcrm -m id
- 注意：-m表示共享内存；-q表示消息队列；-s表示信号量

*相关函数：*

- shmget：创建一个新的共享内存段，返回共享内存的引用的ID。
- shmat：将共享内存映射到用户的地址空间，如果成功返回共享内存首地址。
- fgets：write操作，需要传入共享内存起始地址，
- shmdt：将进程里的地址映射删除
- shmctl：删除共享内存对象
- ftok：根据指定的路径名，和int值，生成一个共享内存的key，实现了没有亲缘进程之间的通信。

```c
#include <sys/ipc.h>
#include <sys/shm.h>

int shmget(key_t key, size_t size, int shmflg);
/*
- 功能：创建一个新的共享内存段，或者获取一个既有的共享内存段的标识。
    新创建的内存段中的数据都会被初始化为0
- 参数：
    - key : key_t类型是一个整形，通过这个找到或者创建一个共享内存。
            一般使用16进制表示，非0值
    - size: 共享内存的大小
    - shmflg: 属性
        - 访问权限
        - 附加属性：创建/判断共享内存是不是存在
            - 创建：IPC_CREAT
            - 判断共享内存是否存在： IPC_EXCL , 需要和IPC_CREAT一起使用
                IPC_CREAT | IPC_EXCL | 0664
    - 返回值：
        失败：-1 并设置错误号
        成功：>0 返回共享内存的引用的ID，后面操作共享内存都是通过这个值。
*/

void *shmat(int shmid, const void *shmaddr, int shmflg);
/*
- 功能：将共享内存映射到用户的地址空间
- 参数：
    - shmid : 共享内存的标识（ID）,由shmget返回值获取
    - shmaddr: 申请的共享内存的起始地址，指定NULL，内核指定
    - shmflg : 对共享内存的操作
        - 读 ： SHM_RDONLY, 必须要有读权限
        - 读写： 0
- 返回值：
    成功：返回共享内存的首（起始）地址。  失败(void *) -1
*/

int shmdt(const void *shmaddr);
/*
- 功能：将进程里的地址映射删除
- 参数：
    shmaddr：共享内存的首地址
- 返回值：成功 0， 失败 -1
*/

int shmctl(int shmid, int cmd, struct shmid_ds *buf);
/*
- 功能：对共享内存进行操作。删除共享内存，共享内存要删除才会消失，创建共享内存的进行被销毁了对共享内存是没有任何影响。
- 参数：
    - shmid: 共享内存的ID
    - cmd : 要做的操作
        - IPC_STAT : 获取共享内存的当前的状态  【实现了 ipcs -m 命令】
        - IPC_SET : 设置共享内存的状态
        - IPC_RMID: 标记共享内存被销毁	【实现了 ipcrm -m 命令】
    - buf：需要设置或者获取的共享内存的属性信息
        - IPC_STAT : buf存储数据
        - IPC_SET : buf中需要初始化数据，设置到内核中
        - IPC_RMID : 没有用，NULL
*/

key_t ftok(const char *pathname, int proj_id);
/*
- 功能：根据指定的路径名，和int值，生成一个共享内存的key
- 参数：
    - pathname:指定一个存在的路径
        /home/nowcoder/Linux/a.txt
        / 
    - proj_id: int类型的值，但是这系统调用只会使用其中的1个字节
                范围 ： 0-255  一般指定一个字符 'a'
*/
```

#### 信号量(semaphore)

信号量的作用主要在于实现【进程间同步】，信号量是一个【计数器】，用于控制多进程对共享数据的访问，可以允许多个访问者同时访问资源。

*为了获得共享资源，进程需要执行下列操作：*

1. 创建信号量：要求指定【初始值】，也就是指定可以同时访问资源的进程数量。
2. 获取资源：P操作：将信号量-1，并判断信号量的值，如果小于0，进入阻塞；如果大于等于0，执行后续代码。
3. 释放资源：V操作：将信号量的值加1，并判断信号量的值，如果小于等于0，唤醒一个正在阻塞中的进程。·

*信号量与普通整型变量的区别：*

- 信号量是非负整型变量，除了初始化之外，它只能通过两个标准原子操作：wait(semap) , signal(semap)来进行访问,操作也被称为PV原语。

*信号量与互斥量之间的区别：*

1. 互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是【互斥和同步之间的区别】。
   - 【互斥】：是指某一资源同时只允许一个访问者对其进行访问，互斥无法限制访问者对资源的访问顺序。
   
   - 【同步】：大多数情况下是在互斥的基础上，通过其它机制实现访问者对资源的有序访问；同步也可以允许多个访问者同时访问资源。
   
2. 互斥量值只能为0/1，信号量值可以为非负整数。
   - 一个互斥量只能用于一个资源的互斥访问，它不能实现多个资源的多线程互斥问题；信号量可以实现多个同类资源的多线程互斥和同步。
   - 当信号量为单值信号量是，也可以完成一个资源的互斥访问。


#### 套接字(socket)

套接字可以看成两个不同的【主机进程】之间进行通信的端点，使得客户端/服务端的通信既可以在本地进行，也可以跨网络进行。

### 2.2.6 线程同步(四种)

总结：

- 临界区不是内核对象，只能用于进程内部的线程同步，是用户方式的同步。
- 互斥量、信号量是内核对象可以用于不同进程之间的线程同步（跨进程同步）。
- 互斥其实是信号量的一种特殊形式。

#### 临界区

实现多线程【串行化】访问公共资源或一段代码，保证在某一时刻只有一个线程能访问数据，实现简单，速度快。

只能用来同步【同一进程内的线程】，是【用户方式】的同步。

临界区一般使用【锁】的方式来实现，比如：互斥锁和读写锁。

#### 互斥量

采用【互斥对象】机制，只有拥有互斥对象的线程能访问某一个公共资源。互斥对象只有一个，可以保证某公共资源在同一时间只有一个线程可以访问。

互斥对象是【内核对象】，可以在不同进程的线程之间实现同步。

#### 信号量

信号量也是【内核对象】。它允许多个线程在同时访问某一资源，但是需要限制在可以同时访问的【最大线程数目】。

信号量可以使用【非负整数】表示，通过【PV操作】获取和释放资源，如果临界资源的数量为1，将退化为锁。

缺点：信号量机制必须有公共内存，不能用于分布式操作系统，这是最大的弱点。

#### 事件

事件机制，则允许一个线程在处理完一个任务后，主动唤醒正在阻塞的线程。

可以实现【不同进程】中的线程同步操作。

#### 管程

针对信号量编写程序困难、易出错的问题，管程把信号量的控制代码，封装成几个函数，易于调用，不容易出错。

管程引入了【条件变量】以及相关的操作wait() 和 signal() 来实现同步操作。

管程重要特性：

- 一个进程只有通过调用管程内的函数才能进入管程访问共享数据。
- 每次仅允许一个进程在管程内执行某段程序。

### 2.2.7 进程调度

周转时间 = 作业完成时刻 — 作业到达时刻；

带权周转时间 = 周转时间/服务时间；

平均周转时间 = 作业周转总时间/作业个数；

平均带权周转时间 = 带权周转总时间/作业个数；

#### 2.2.7.1 批处理系统

早期批处理系统【没有太多的用户操作】，调度算法目标是保证【吞吐量】和【周转时间】。

##### 先来先服务(FCFS)

- 非抢占式算法，先到的进程先得到服务。公平简单，不会导致饥饿。
- 缺点：对长作业有利，对短作业不利（带权周转时间很大）。

##### 短作业优先(SJF)

- 非抢占式算法，需要服务时间最短的进程先得到服务，可能导致长作业饥饿。
- 追求最少的【平均等待时间】，最少的【平均周转时间】，最少【平均带权周转时间】
- 缺点：短作业有利，长作业不利。 

##### 最短剩余时间优先(SRNT)

- 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。


##### 最高相应比优先(HRRN)

- 非抢占式的算法，综合考虑【等待时间】和【要求服务】的时间。
- 调度时计算所有就绪进程的响应比，响应比最高的进程上处理机。

- 响应比 = (等待时间+要求服务时间)/要求服务时间
- 等待时间越长，响应比越高，避免了长作业饥饿。

#### 2.2.7.2 交互式系统

交互式系统有【大量的用户交互操作】，在该系统中调度算法的目标是【快速地进行响应】。

##### 时间片轮转

规则：将【所有就绪进程】按【先进先出】的原则排成一个队列，每次调度时，把 CPU 时间分配给【队首进程】，该进程可以执行一个时间片。当时间片用完时，则剥夺处理机（由计时器发出时钟中断），并将它送往就绪队列的末尾，然后继续把 CPU 时间分配给队首的进程。

抢占式算法，由时钟中断通知CPU时间片已到，不会饥饿。

优点：公平、响应快，每个进程在一定时间间隔内都可以得到响应。

缺点：频繁的进程切换有一定的开销，不区分任务的紧急程度。

效率和时间片的大小有很大关系：

- 如果时间片太小，会导致进程切换得太频繁，在进程切换上就会浪费过多时间。
- 如果时间片过长，可能导致响应速度变慢。

##### 优先级调度

规则：为每个进程分配一个【优先级】，调度时选择优先级高的进程，具有相同优先级的进程以【先进先出】方式执行。

根据优先级是否可以改变分为【静态优先级】和【动态优先级】。

优点：可以用优先级区分进程的紧急程度，重要程度，适用于实时操作系统。

缺点：优先级低的线程可能导致饥饿。

通常：
- 【系统进程】优先级高于用户进程
- 【前台进程】优先级高于后台进程
- 【IO繁忙型进程】优先级高于CPU繁忙型进程

使用动态优先级时，如何改变进程优先级：从提升公平和资源利用率考虑：
- 如果一个进程在队列中【等待时间】较长，可以适当提高优先级
- 如果某进程【占用处理机时间】较长，可以适当降低优先级
- 如果一个进程【频繁进行IO操作】，适当提高优先级

##### 多级反馈队列

考虑到有些进程需要连续执行很多个时间片，设置多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。

可以看成是【时间片轮转调度算法】和【优先级调度算法】的结合。

*规则：*

1. 设置多个队列，各级队列是【先进先出】(FCFS)队列，【优先级从高到低】，【时间片从低到高】。
2. 每次调度选择优先级最高的队列的队首进程运行，如果时间片用完进程还没执行完，则进入下一级队列队尾。
3. 新进程到达时先进入第一级队列，如果正在运行的进程优先级较低，新进程到达时，会抢占处理机，被抢占的进程重新进入原队列队尾。

*优点：*

- 对各类型进程相对【公平】
- 每个新到达的进程都可以得到【快速响应】
- 【短进程】只用较少的时间就可完成
- 可【灵活地调整】对各类进程的【优先级】,比如CPU密集型进程、I/O密集型进程(拓展:可以将因I/O而阻塞的进程重新放回原队列,这样I/O型进程就可以保持较高优先级)

### 2.2.8 进程组成

进程主要由三个部分组成，其中【PCB】是给操作系统用的，【程序段】、【数据段】是供进程使用的。

<img src="D:/Typora/picture/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNjA4MTM3,size_16,color_FFFFFF,t_70.png" alt="img" style="zoom:80%;" />

#### 进程控制块PCB

PCB 是进程存在的【唯一标志】，当进程被创建时，操作系统为其创建PCB，当进程结束时，回收其PCB。

PCB 是操作系统用于描述和管理进程的一个【数据结构】，记录了操作系统用于描述和管理进程的全部信息，操作系统管理进程都是通过PCB完成的。

*PCB组成：*

<img src="D:/Typora/picture/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNjA4MTM3,size_16,color_FFFFFF,t_70-16527874720264.png" alt="img" style="zoom:80%;" />

### 2.2.9 进程创建和撤销

进程允许创建和控制另一个进程，前者称为父进程，后者称为子进程，子进程又可以创建孙进程，如此下去进而形成一个进程的家族树。

子进程就可以从父进程那里继承所有的资源，当子进程撤销时，便将从父进程处获得的所有资源归还，此外，撤销父进程时，必须撤销所有的子进程。

*创建子进程：*

- 申请空白的PCB
- 初始化【进程描述信息】
- 为进程分配【资源】以及【地址空间】
- 将其插入就绪队列中

*撤销进程：*

- 查找需要撤销的进程的 PCB 
- 如果进程处于运行状态，会终止进程
- 终止子孙进程 - 归还资源
- 将它从所在的队列中移除

### 2.2.10 fork 和 vfork

调用fork函数可以拷贝当前进程创建一个子进程，

*区别：*

1. fork():子进程拷贝父进程的数据段，代码段，通过【拷贝页表】实现，两个进程有自己的私有地址空间，一个进程更改数据时，会发生【写时复制】。

   vfork():子进程与父进程共享数据段，无需拷贝页表。

2. fork():父子进程的执行次序不确定

   vfork()：保证子进程先运行，在它调用exec()或_exit()函数之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。

## 2.3 死锁

### 2.3.1 死锁产生的4个条件

- 互斥条件
  - 资源处于非共享模式，同一时间只能被一个进程占用。
- 占有并等待
  - 一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。

- 不剥夺条件
  - 进程获得的资源未使用完成，其它进程不能强行夺走，只能等待主动释放。
- 循环等待条件
  - 有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

### 2.3.2 解决死锁的方法(四种)

鸵鸟策略

- 发生死锁时，不作处理。

死锁检测与死锁恢复

- 死锁发生时，检测死锁并且恢复程序运行。

死锁预防

- 通过限制并发进程对资源的请求，使得产生死锁的必要条件同一时刻不会都满足。

死锁避免

- 程序运行时，通过安全状态检测，避免死锁发生。

### 2.3.3 鸵鸟策略

发生死锁时不作处理，当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，都是使用这种策略解决死锁问题。

### 2.3.4 死锁检测与死锁恢复

不试图阻止死锁发生，而是当检测到死锁发生时，采取措施进行恢复。

#### 死锁检测

每种类型一个资源的死锁检测：

- 通过检测【资源分配图(有向图)】中，有向图是否有环。

每种类型多个资源的死锁检测：

- 找到所需资源可以得到满足的进程，执行完并释放所有资源。
- 不断重复这个过程。
- 如果全部进程都能执行，则不存在死锁；如果有的进程不能执行，则存在死锁。

#### 死锁恢复

- 利用【抢占】恢复
- 利用【回滚】恢复
- 通过【杀死进程】恢复

如何决定处理哪个进程？

- 考虑【进程优先级】，【执行时间】，【还需多长时间】执行完，进程【占用资源多少】等条件决定。

### 2.3.5 死锁预防

通过限制进程获取资源，使得死锁产生的四个必要条件在同一时刻不会同时满足。

- 破坏互斥条件
  - 把只能互斥使用的资源改造为允许共享使用。
- 破坏占有和等待条件
  - 可以规定所有进程在开始执行前请求所需要的全部资源。
  - 特点：实现简单，但是资源利用率极低，可能导致某些进程饥饿。
- 破坏不可抢占条件
  - 方案一：某个进程所需的资源得不到满足时，主动释放自己保持的资源，以后再重新申请 
  - 方案二：操作系统协助，将资源剥夺给优先级高的资源
  - 缺点：实现复杂，可能造成获得资源前一阶段的工作白做，而且反复申请资源增加系统开销，可能导致进程饥饿
- 破坏环路等待
  - 给资源统一编号或者分层，进程按照一定的顺序来请求资源。
  - 缺点：不方便添加新设备，需要重新分配编号；进程实际使用资源的顺序可能和编号顺序不一致，需要提前申请不必要的资源导致浪费。

### 2.3.6 死锁避免

在程序运行时避免发生死锁。

检测安全状态：

- 安全序列：就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。
- 如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了【不安全状态】，有可能会发生死锁。

通过银行家算法：和每种类型多个资源检测死锁相似。

### 2.3.7 活锁和饥饿锁

活锁：多个线程都在运行，互相改变对方的结束条件，使得这些线程永远无法结束。

饥饿锁：某个线程一直等不到它所需要的资源，从而无法向前推进。

## 2.4 内存管理

### 2.4.1 操作系统内存管理作用

内存的【分配与回收】（malloc 函数：申请内存，free 函数：释放内存）

【地址转换】：也就是将逻辑地址转换成相应的物理地址

内存【空间的扩充】(实现虚拟性)

【内存保护】功能

### 2.4.2 几种内存管理机制

分块管理

- 是连续内存管理的一种，把内存分为几个【大小相等且固定的块】，每次为进程分配一个，如果进程很小的话，会浪费大量的空间。已经淘汰。

分页管理

- 把内存分为若干个很小的内存块，以【内存块为单位】为进程分配内存，提高内存利用率，【减少碎片】，页式管理通过【页表】对应逻辑地址和物理地址。

分段管理

- 把内存分为几个大小不定的有实际意义的段，通过管理【段表】来把逻辑地址转为物理地址。

段页式管理

- 结合了段式管理和页面管理的优点，把主存先分为若干个段，每个段又分为若干个页。

### 2.4.3 分页管理

#### 概念

将【内存空间】分为一个个大小相等的【内存块】，内存块号从0开始。

将进程的【逻辑地址空间】也分为与【内存块】大小相等的一个个部分，每个部分称为一个【页】，页号也是从0开始。

操作系统以【内存块】为单位为各个进程分配内存空间。进程的每个【页面】分别放入一个【内存块】中。

#### 页表

用来查询每个【页号】对应的【内存块号】。

注：页表通常存在PCB（进程控制块）中。

- 一个进程对应一张页表。
- 页表记录【进程页面】和【实际存放的内存块】之间的映射关系。
- 进程的每个页面对应一个【页表项】。
- 每个页表项由【页号】和【块号】组成，每个页表项的长度是相同的，页号是隐含的。

#### 页表项

每个页表项长度是相同的，页号是隐含的。

进程的页表通常存放在连续的内存块中，方便计算内存地址：页表起始地址X+页表项长度*M号

建议【页表项长度】可以【整除页面大小】，一个页面中存放页表项不会有碎片，方便计算。

#### 基本地址变换机构

【基本地址变换机构】可以借助【进程的页表】将【逻辑地址】转换为【物理地址】。

【页表寄存器(PTR)】：保存【页表】在内存中的【起始地址F】和【页表长度M】。

进程未执行的时候，F和M放在PCB中，进程被调度时，操作系统内核将其放到PTR中。



在【页式管理】的系统中,只要确定了每个页面的大小,逻辑地址结构就确定了。因此,页式管理中地址是【一维】的。

即,只要给出一个逻辑地址,系统就可以自动地算出页号、页内偏移量两个部分。

##### 基本过程

1. 根据逻辑地址计算【页号P】、【页内偏移量W】。逻辑地址：[页号P,页内偏移量W]。

2. 判断页号是否【越界】。P>=M：说明越界。

3. 【查询页表】，找到页号对应的内存块号b。

4. 根据内存块号b，结合页内偏移量W得到【物理地址E】。物理地址：\[内存块号b,页内偏移量W\]

5. 访问内存单元。

   <img src="D:/Typora/picture/image-20220330220558249.png" alt="image-20220330220558249" style="zoom: 40%;" />

### 2.4.4 分段管理

#### 概念

与“分页”最大的区别就是：离散分配时所分配地址空间的基本单位不同。

【进程的地址空间】:按照程序自身的【逻辑关系】划分为若干个段,每个段都有一个段名。

内存分配规则:以【段为单位】进行分配,每个段在内存中占据连续空间,但各段之间可以不相邻。



【逻辑地址结构】：由【段号(段名)】和【段内地址(段内偏移量)】所组成。

- 段号的位数决定了每个进程最多可以分几个段。
- 段内地址位数决定了每个段的最大长度是多少。

#### 段表

根据【逻辑段号】找到对应的物理内存中的位置。

1. 每个段对应一个【段表项】,其中记录了该段在内存中的【起始位置】和【段的长度】(地址转换时需要检查段内地址是否超过段长)。
2. 各个段表项的长度是相同的，段号可以是隐含的。

#### 地址变换基本过程

<img src="D:/Typora/picture/image-20220331001838681.png" alt="image-20220331001838681" style="zoom:40%;" />

### 2.4.5 分页和分段对比

共同点：

- 都是离散分配方式，提高了内存利用率，减少了内存碎片。

不同点：

1. 页是信息的【物理单位】。主要目的是实现【离散分配】,提高内存利用率。分页是【系统管理】上的需要,对用户是不可见的。

   段是信息的【逻辑单位】。主要目的是根据用户需求，将程序按照【逻辑模块】分为不同的段。分段对用户是可见的,需要显式地给出段名。

2. 页的【大小固定】且由系统决定。段的长度不固定,决定于用户编写的程序。

3. 分页管理【地址空间】是【一维】的。分段管理【地址空间】是二维的,程序员在标识一个地址时,既要给出【段名】,也要给出【段内地址】。

4. 分段容易按照逻辑实现信息的【共享和保护】。

### 2.4.6 快表

#### 局部性原理

【时间局部性】:如果执行了程序中的某条【指令】,那么不久后这条指令很有可能再次执行;如果某个【数据】被访问过,不久之后该数据很可能再次被访问。(因为存在大量的循环) 

【空间局部性】:如果程序访问了某个【存储单元】,在不久之后,其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的）

#### 快表

地址变换的过程中,每次要访问一个逻辑地址,都需要查询内存中的页表。由于局部性原理,可能连续很多次查到的都是同一个页表项。

利用这个特性减少访问页表的次数：快表。

快表：

- 又称【联想寄存器(TLB)】 ,是一种访问速度比内存快很多的【高速缓冲存储器】,用来存放当前访问的若干【页表项】。(与此对应,内存中的页表常称为慢表)
- 引入快表之前，需要先查询页表，得到内存块号，然后访问实际内存，需要两次访存。
- 引入快表之后，如果快表命中可以直接得到内存块号，无需查询页表，只需一次访存，大大提高效率。
- 查询快表的速度比查询页表的速度快很多，因此只要快表命中，就可以节省很多时间。 因为局部性原理，一般来说快表的命中率可以达到 90% 以上。

#### 基本过程

1. 根据逻辑地址计算出【页号】、【页内偏移量】，检查页号是否【合法性】，将页号与快表中的所有页号进行比较。

2. 如果快表命中，直接从中得到对应的内存块号，计算出物理地址，然后访问内存，访问逻辑地址仅需一次访存。

3. 如果快表未命中，则需要访问内存中的页表，得到对应的内存块号，计算出物理地址，访问内存，访问某个逻辑地址需要两次访存。

   （注意：在找到页表项后，要将其存入快表。但若快表已满，则必须按照一定的算法对旧的页表项进行替换）

### 2.4.7 多级页表

单级页表存在的问题：

- 问题一：页表必须连续存放，因此当页表很大时，需要占用很多个连续的内存块。 
- 问题二：没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。

多级页表实现了【页表的离散分配】，是典型的【时间换空间】场景。

<img src="D:/Typora/picture/image-20220330232027250.png" alt="image-20220330232027250" style="zoom:80%;" />

### 2.4.8 虚拟地址

我们在写程序的时候使用的都是虚拟地址，比如 C 语言的指针，这个虚拟地址由操作系统决定，而物理地址指的是真实内存地址。

现代处理器通常使用【虚拟寻址】，用【内存管理单元MMU】把虚拟地址翻译成物理地址才能访问到真正的物理地址。

如果不使用虚拟地址，程序直接操作物理地址：

1. 用户程序直接访问底层的物理地址，可能会【破坏操作系统】，造成操作系统崩溃。 
2. 【多个程序同时运行】会有难度，多个程序可能会对同一段内存进行操作，发生崩溃。

使用虚拟地址：

1. 程序可以使用一系列连续的虚拟地址来访问物理内存中【不连续】的内存地址。
2. 程序可以使用一系列虚拟地址来访问【大于可用物理内存】的内存地址。数据或代码页可以根据需要在物理内存与磁盘之间移动。
3. 不同进程使用的虚拟地址彼此【隔离】。一个进程中无法直接访问另一进程或操作系统使用的物理内存。

### 2.4.9 虚拟内存

#### 为什么使用虚拟内存

引入虚拟内存之前，每个作业运行时都要将全部内容装入内存：

1. 【作业很大时】，不能全部装入内存，无法运行。
2. 当【大量作业要求运行】时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降。 
3. 【驻留性】：一旦作业被装入内存，就会一直驻留在内存中，直至运行结束，事实上，在一个时间段内，只需要访问作业的一小部分数据，浪费了内存空间。

基于【局部性原理】提出【高速缓冲技术】的思想：

- 将近期会频繁访问到的数据放到更高速的存储器中，暂时用不到的数据放在更低速存储器中。

#### 什么是虚拟内存

在【程序装入时】，只将程序中很快会用到的部分装入内存，暂时用不到的部分留在外存，让程序开始执行。

在程序执行过程中，当所访问的信息不在内存时，由操作系统负责从外存【调入内存】。

若内存空间不够，由操作系统负责将内存中暂时用不到的信息【换出到外存】。

在操作系统的管理下，在用户看来似乎有一个【比实际内存大得多的可用内存】，这就是【虚拟内存】。

#### 虚拟内存三个主要特征 

- 多次性：无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存。

- 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。

- 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。


#### 虚拟内存的技术实现

- 请求分页式存储管理
- 请求分段式存储管理
- 请求段页式存储管理

### 2.4.10 请求分页储存管理

#### 请求分页与分页区别

- 【请求调页功能】：在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存。
- 【页面置换功能】：若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。
- 页面调入调出时，需要修改页表项。

#### 页表机制

- 为了实现【请求调页】，操作系统需要知道每个页面【是否调入内存】；如果还没调入，也需要知道该页面对应的【外存地址】。
- 为了实现【页面置换】，根据每个页面【访问次数】和【是否修改】。

请求分页储存管理中：页表新增了四个字段。

<img src="D:/Typora/picture/image-20220331193729394.png" alt="image-20220331193729394" style="zoom:80%;" />

#### 缺页中断机构

【缺页中断】是因为当前执行的指令要访问的页面不在内存中，属于【内中断】。

一条指令在执行期间，可能产生多次缺页中断。

*过程：*

1. 每当要访问的页面不在内存时，便产生一个【缺页中断】，然后由操作系统的【缺页中断处理程序】处理中断。
2. 缺页的进程进入【阻塞】，放入阻塞队列，调页完成后再将其唤醒，放回就绪队列。
3. 如果内存中【有空闲块】，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项。

4. 如果内存中【没有空闲块】，则由【页面置换算法】选择一个页面淘汰，若该页面在内存期间被修改过，则要将其写回外存。

<img src="D:/Typora/picture/image-20220331194405827.png" alt="image-20220331194405827" style="zoom:80%;" />

#### 地址转换过程

<img src="D:/Typora/picture/image-20220331194900400.png" alt="image-20220331194900400" style="zoom:40%;" />

### 2.4.11 页面置换算法

#### 最佳页面置换

被换出的页面将是最长时间内不再被访问的，不可实现。

#### 先到先出算法

把在内存中停留时间最长的页面置换出去。

#### LRU 算法

【最近最久未使用】页面置换算法，每一个页面有一个访问字段，来记录一个页面最近一次访问到现在所经历的时间 T，需要淘汰一个页面时，把最久没有使用的页面淘汰掉就可以了。

#### LFU 算法

【最近最少使用】算法，把使用次数最少的页面淘汰掉。

#### 时钟算法

先进先出置换算法实现简单，但算法性能差；LRU性能好，但是，算法开销大。

- 时钟置换算法是一种【性能和开销较均衡】的算法，将内存中的页面都通过指针链接成一个【循环队列】，每个页面设置【访问位】和【修改位】。
- 选择一个页面淘汰时，循环检查每个页面状态，优先置换出【最近未访问过】且【没有被修改过】的页面。

## 2.5 其他面试题

### 2.5.1 程序从开始到运行

1. 编译：由【编译程序】将【用户源代码】编译成若干个【目标模块】；把高级语言翻译成机器语言。
2. 链接：由【连接程序】将编译后形成的一组【目标模块】，以及所需【库函数】链接在一起，形成一个完整的【装入模块】。
3. 装入：由【装入程序】将装入模块【装入内存】运行。

<img src="D:/Typora/picture/image-20220329221823602.png" alt="image-20220329221823602" style="zoom: 40%;" />

### 2.5.2 静态链接和动态链接

静态链接：

- 静态链接：就是在编译连接的过程中把【要链接的内容】拷贝到生成的可执行文件中。
- 优点：在程序执行的时候【不需要依赖库】，可执行程序中已经具备了所有程序运行所需要的东西，在执行的时候【运行速度快】。
- 缺点：【浪费空间】，因为每个可执行程序中对所有需要的目标文件都要有一份副本；【更新比较困难】，库函数的代码被修改时，需要重新进行编译链接形成可执行程序。

动态链接：

- 动态链接就是在编译链接的时候不直接拷贝可执行代码，而是记录一系列【符号和参数】，在程序运行或加载时，操作系统负责将需要的【动态库】加载到内存中，程序访问内存中共享的动态库。
- 优点：【占用空间少】，多个程序可以共享同一段代码；【更新比较方便】，更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。
- 缺点：每次执行程序都需要进行链接，所以性能会有一定损失。(性能损失大约在5%以下,是值得的。)

### 2.5.3 程序结束方式

正常退出(自愿的)

错误退出(自愿的)

- 比如程序出现异常，比如文件未找到。

严重错误退出(非自愿的)

- 通常是由于程序中的错误所导致的。例如，除数是0。

被其他进程杀死(非自愿的)

### 2.5.4 守护进程、僵尸进程和孤儿进程

#### 守护进程

在后台运行的，通常【独立于控制终端】并且周期性地【执行某种任务】或【等待处理某些发生的事件】。

Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等。

#### 孤儿进程

如果一个父进程退出，而它的子进程还在运行，那么这些子进程将成为【孤儿进程】。

孤儿进程的父进程将变为init进程（注：任何一个进程都必须有父进程），并由init进程对它们完成【状态收集工作】。

#### 僵尸进程

如果子进程先退出，父进程还没退出，那么子进程必须等到父进程【捕获到了子进程的退出状态】才真正结束，否则这个时候子进程就成为【僵尸进程】。

设置僵尸进程的目的：

- 维护子进程的信息，以便父进程在以后某个时候获取。

  这些信息包括【进程ID】，【进程的终止状态】，以及该【进程使用的CPU时间】等。

# 3. MySQL

## 3.1 基础

### 3.1.1 架构

<img src="D:/Typora/picture/0d2070e8f84c4801adbfa03bda1f98d9.png" alt="img" style="zoom: 25%;" />

大体来说，MySQL 可以分为 【Server层】和【存储引擎层】两部分。

Server层包括：【连接器】、【查询缓存】、【分析器】、【优化器】、【执行器】等，涵盖了 MySQL 的【大多数核心服务功能】，以及所有的【内置函数】（如：日期、时间、数学和加密函数等），【所有跨存储引擎的功能】都在这一层实现，比如：存储过程、触发器、视图等等。

存储引擎层：负责数据的存储和提取。其架构是插件式的，支持 InnoDB、MyISAM 等多个存储引擎。不同存储引擎的表数据存取方式不同，支持的功能也不同。

#### 连接器

连接器负责跟客户端【建立连接】、【获取权限】、【维持和管理连接】。

如果用户名密码认证通过，连接器会到【权限表】里面查询拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。

客户端如果太长时间没动静，连接器就会【自动将它断开】。由参数 wait_timeout 控制的，默认值是 8 小时。

【长连接】和【短链接】：

- 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。
- 短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。

- 建立连接的过程通常比较复杂，建议尽量使用长连接。


长链接问题：

- MySQL 在执行过程中临时使用的内存是管理在【连接对象】里面的。这些资源会在连接断开的时候才释放。所以如果长连接长时间不断开，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。

如何解决：

- 【定期断开长连接】。使用一段时间，或者程序里面判断执行过一个要占用大量内存的查询后，断开连接，之后要查询再重连。
- 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会【将连接恢复到刚刚创建时的状态】。

#### 查询缓存

MySQL 接收一个查询请求后，会先查看查询缓存，之前【执行过的语句】及其【结果】可能会以【key-value】对的形式，被直接缓存在内存中。

key 是查询的语句，value 是查询的结果；查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。

查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。

MySQL 8.0 版本已经将查询缓存的整块功能删掉了。

#### 分析器

对 SQL 语句做解析，具体包括【词法分析】和【语法分析】

- 词法分析：识别SQL语句中的【操作关键字】，【表名】，【列名】等信息。

- 语法分析：语法分析在词法分析之后进行，根据语法规则，判断 SQL 语句是否满足 MySQL 语法。


#### 优化器

确定语句执行方案。

优化器是在表里面有多个索引的时候，决定使用哪个【索引】；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

#### 执行器

负责执行SQL语句。

首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。

### 3.1.2 查询语句如何执行

服务端收到一条SQL语句后，在 MySQL8.0 版本以前，会先【查询缓存】，以这条 sql 语句为 key 在内存中查询是否有对应的结果，如果有，验证当前用户是否具备查询权限，如果权限验证通过，直接返回结果集给客户端，此次查询结束。

另一方面，通过【分析器】对SQL语句进行【词法分析】，提取 sql 语句的【关键词】，查询语句中也就是select关键词，提取需要查询的【表名】，【列】，【查询条件】。

然后【分析器】进行语法分析，判断这个 sql 语句是否有语法错误。

接下来就是【优化器】进行确定执行方案，选择索引，如果有多表联合查询，确定查询顺序。

【执行器】负责执行语句，执行之前进行权限校验，如果没有权限就会返回错误信息，如果有权限就会【调用数据库引擎接口】，返回引擎的执行结果。

### 3.1.3 更新语句如何执行

【分析器】进行【词法分析】和【语法分析】。

【优化器】选择执行方案。

【执行器】执行语句前进行权限校验，后面执行过程：
1. 【执行器】先调用存储引擎接口取出要修改的行数据。【存储引擎】搜索这一行数据，如果数据页已经在内存中，直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回给执行器。
2. 【执行器】拿到引擎给的行数据后，【修改数据】，再【调用引擎接口写入】这行新数据。
3. 【存储引擎】将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 日志里面，此时 redo log 处于 prepare 状态。
4. 然后【执行器】记录这个更新操作的 binlog 日志。
5. 【执行器】调用引擎的【提交事务接口】，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

redo log 日志会有两个状态 prepare 和 commit，这就是【两阶段提交机制】。MySQL的两阶段提交机制是为了在崩溃恢复时，保证两个日志数据的一致性。

### 3.1.4 三范式

第一范式：确保每列保持【原子性】，数据表中的所有字段值都是不可分解的原子值。

第二范式：一个表必须有一个【主键】；非主键列必须【完全依赖】于主键，而不能只依赖于主键的一部分。

第三范式：非主键列必须【直接依赖】于主键，不能存在传递依赖。

### 3.1.5 InnoDB 和 MyISAM

InnoDB

- InnoDB 是 MySQL 5.1 版本后的默认存储引擎，支持【事务】、【行级锁】和【外键】等操作。

MyISAM

- MyISAM 是 MySQL5.1 版本前的默认存储引擎，MyISAM 的并发性比较差，不支持事务和外键等操作，默认的锁的粒度为表级锁。

InnoDB 和 MyISAM的区别：

1. InnoDB支持【行级锁】和表级锁，MyISAM不支持行级锁，并发写的时候要锁住整张表，并发度比较差。
2. InnoDB 提供【事务】支持，MyISAM 不提供。

3. InnoDB 支持【外键】，MyISAM 不支持。
4. InnoDB 支持数据库【异常崩溃后的安全恢复】，MyISAM 不支持，这个恢复的过程依赖于 innoDB 存储引擎的 redo log 日志。
5. InnoDB 支持 【MVCC】，MyISAM不支持。

6. InnoDB 使用了【聚簇索引】存储数据，需要访问的数据可以放入内存，访问速度较快。

## 3.2 日志

### 3.2.1 redo log(重做日志)

redo log（重做日志）是 InnoDB 存储引擎独有的。

redo log作用：是为了保证数据库发生【异常重启】时，提交的数据可以恢复，保证了数据的【持久性】和【完整性】。

redo log 是【物理日志】，记录的是【在哪个数据页上做了什么修改】。

#### 写入机制

过程：

1. 事务执行过程中，将redo log写到 redo log buffer 中。
2. 事务提交后，日志会先写到文件系统的page cache中，然后再刷新到磁盘中。

InnoDB 提供了 innodb_flush_log_at_trx_commit 参数控制刷盘策略：

- 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 。
- 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘。
- 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

什么时候写盘：

- InnoDB 有一个【后台线程】，【每隔 1 秒】，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。
- redo log buffer 占用的空间【即将达到 innodb_log_buffer_size 一半】的时候，【后台线程】也会主动进行写盘操作。
- 另一种是，【并行的事务提交并执行刷盘操作的时候】，顺带将这个事务的 redo log buffer 持久化到磁盘。

每秒一次后台轮询刷盘，再加上崩溃时 redo log 不需要 commit 也能完成，所以 InnoDB 认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。

#### 日志文件组

硬盘上存储的 redo log 日志文件的是一个由多个文件组成的【日志文件组】，每个的redo日志文件大小都是一样的。

采用的是【环形数组】数据结构，有两个重要的属性：

- `write pos`：是当前写记录的位置。
- `checkpoint`：是当前要擦除的位置。

如果 write pos 追上 checkpoint ，表示日志文件组满了，MySQL 得停下来，执行刷盘操作，清空一些记录。

<img src="D:/Typora/picture/image-20220710154309103.png" alt="image-20220710154309103" style="zoom:80%;" />

#### WAL 机制

主要得益于两个方面：

- redo log 和 binlog 都是【顺序写】，磁盘的顺序写比随机写速度要快。
- redo log 和 binlog 都支持【组提交】机制，将多个事务的刷盘操作合并成一个，可以大幅度降低磁盘的 IOPS 消耗。

### 3.2.2 binlog(归档日志)

binlog 是 MySQL 的【Server层】实现的，所有引擎都可以使用。主要作用：【数据备份】和【主从复制】。

binlog 是【逻辑日志】，记录的是这个语句的【原始逻辑】，比如”给 ID=2 这一行的 c 字段加1“。

binlog 是【追加写】的，一个文件写完了会切换到下一个，不会覆盖以前的日志。

#### binlog三种格式

##### statement格式

记录的是SQL语句。

优点：节省空间，对于多行的操作也只有一条SQL语句。

缺点：有些 statement 格式的 binlog 可能会导致主备不一致

##### row格式

记录的是操作的数据修改前后的值。

优点：可以通过 binlog 日志得到SQL执行前的数据。

缺点：很占空间，比如用一个 delete 语句删掉 10 万行数据，用 statement 的话只需要记录一个 SQL 语句，如果用 row 格式的 binlog，就要把这 10 万条都记录下来。

##### mixed格式

两种格式的结合，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致；如果有可能，就用 row 格式，否则就用 statement 格式。

#### 写入机制

事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。

每个线程有自己 binlog cache 内存，但是共用同一份 binlog 文件。

参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

write 和 fsync 的时机，是由参数 sync_binlog 控制的：

- sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync。
- sync_binlog=1 的时候，表示每次提交事务都会执行 fsync。
- sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

### 3.2.3 undo log(回滚日志)

undo log 主要有两个作用：

- 当【事务回滚】时用于将数据恢复到修改前的样子。
- 另一个作用是【MVCC】，实现了版本链，当一个事务读取记录时，若该记录不可见，则可以通过 undo log 获取之前版本的数据，以此实现快照读。

undo log 是【逻辑日志】，比如一条 insert 语句对应的日志就是一条 delete 语句。

## 3.3 索引

### 3.3.1 概述

索引是一种用于【快速查询和检索数据】的【数据结构】。常见的索引结构有: B 树， B+树和 Hash。

数据是存储在磁盘上的，查询数据时，如果没有索引，会加载所有的数据到内存，依次进行检索，读取磁盘次数较多；有了索引，就不需要加载所有数据，因为B+树的高度一般在2-4层，只需要读取2-4次磁盘，查询速度大大提升。

### 3.3.2 索引优缺点

优点：

- 使用索引可以大大加快数据的【检索速度】, 这也是创建索引的最主要的原因。 
- 通过创建【唯一性索引】，可以保证数据库表中每一行数据的唯一性。

缺点：

- 创建索引和【维护索引】需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。
- 索引需要使用物理文件存储，也会【耗费一定空间】。

### 3.3.3 什么时候建立索引？

1. 经常用于【查询的字段】。
2. 经常用于【连接的字段】建立索引，可以加快连接的速度。
3. 经常需要【排序】的字段建立索引，因为索引已经排好序，无需额外的排序操作。

### 3.3.4 什么情况不建索引？

1. 【查询条件中用不到】的字段不适合建立索引
2. 表中【记录较少】时，不适合建立索引
3. 需要频繁进行【修改】的字段
4. 需要参与【列计算】的字段不适合建索引
5. 【区分度不高】的字段不适合建立索引，如性别等

### 3.3.5 索引底层数据结构

#### Hash表

哈希表是键值对的集合，可以通过键(key)快速取出对应的值(value)，因此哈希表可以快速检索数据（接近 O（1））。

哈希冲突：通常使用【拉链法】解决。

缺点：

- 不支持【范围查询】，范围查询只能将满足条件的所有key通过哈希算法查找value。
- 数据量很大时，【哈希冲突严重】，需要遍历链表查找，查找效率会降低。

#### B树 & B+树

有何异同？

- B 树的所有节点既存放键(key) 也存放数据(data)，而 B+树只有叶子节点存放key和数据，其他内节点只存放 key 和下一级索引。
- B 树的叶子节点都是独立的；B+ 树的叶子节点有一条【引用链】指向与它相邻的叶子节点。

#### 为什么使用B+树

- B+ 树只有叶子节点才存储数据，非叶子节点只存储 key 值和下一级索引，所以 B+ 树的【高度更低】，查询叶子结点的 IO 次数更少。
- 对于数据库中比较频繁的【范围查询】，B+树所有数据存放在叶子节点中，并且每一页有下一页的索引，B+树只需将按顺序扫描叶子结点即可；B树非叶子节点也存放了数据，所以范围查询中需要进行中序遍历扫描，B+树效率更高。
- B+树的查询【效率更加稳定】，任何关键字的查找必须走一条从根结点到叶子结点的路。

### 3.3.6 索引类型

#### 主键索引

主键列使用的就是主键索引。主键字段唯一且不能为空。

#### 唯一索引

索引列中的值必须是唯一的，但是允许为空值。

#### 普通索引

普通字段创建的索引，一张表中允许有多个普通索引，目的是提高根据这个字段查询的效率。

#### 联合索引

表中的多个字段组合上创建的索引，使用联合索引时需遵循【最左前缀原则】。

#### 全文索引

1. 全文索引可以实现根据【关键字】匹配查询，效率比模糊查询快，但是全文索引可能存在【精度问题】。
2. 只有字段的数据类型为 char、varchar、text 及其系列，才可以创建全文索引。

### 3.3.7 什么是聚簇索引

【聚集索引】是【索引结构】和【数据】一起存放的索引。

InnoDB 引擎是使用【聚集索引】存储数据的，.ibd 文件就包含了该表的索引和数据，所有数据存放在B+树索引的叶子节点中，并且叶子节点的存储是逻辑上连续的，使用双向链表连接相邻节点，数据是有序存放的，对于索引字段的【范围查询】和【排序】的效率很高。

聚集索引选择策略：

- 对于 InnoDB 来说，聚集索引一般是表中的【主键索引】
- 如果表中没有显示指定主键，则会选择表中的第一个不允许为 NULL 的【唯一索引】。
- 如果没有主键也没有合适的唯一索引，则会生成一个【隐藏主键】字段作为聚集索引，这个隐藏的字段长度为6个字节，并且是自增的。

#### 聚集索引的优点

- 【查询速度】快，定位到叶子节点，就相当于定位到了数据，避免了二次查询。

- 【范围查询】效率较高，只需将一个或周围逻辑相邻的数据页加载到内存中，顺序查找叶子结点即可。


#### 聚集索引的缺点

1. 依赖于【有序的数据】：数据在叶子结点的存放是根据索引字段值排序的，如果插入的数据索引字段不是递增的，需要进行排序，【可能发生页分裂】。
2. 【更新代价大】：如果对索引列的数据被修改时，那么对应的索引也将会被修改，要重新排序；所以对于主键索引来说，【主键一般都是不可被修改的】。

#### 非聚集索引

非聚集索引即索引结构和数据分开存放的索引。

### 3.3.8 什么是覆盖索引？

对于 innodb 表的二级索引，如果【索引能覆盖到查询的列】，那么就可以避免对【主键索引】的【二次查询】。

覆盖索引可以减少树的搜索次数，显著提升查询性能，是一个常用的性能优化手段。

### 3.3.9 联合索引

使用表中的多个字段创建索引，就是【联合索引】，也叫【组合索引】或【复合索引】。

#### 最左前缀匹配原则

多字段创建联合索引时，索引排序规则是优先按照最左边字段排序，左边字段值相同时在按照后面字段排序，所以查询条件需要包括多个字段的左前缀才能使用索引，因为这样才能保证要查询的数据在索引结构中是相邻并且排序的。

#### 索引下推

索引下推是 MySQL 5.6 版本中提供的一项索引优化功能，可以在【二级索引】遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数。

### 3.3.10 索引失效的情况

1. 索引列参与【运算操作】或【函数运算】时，索引会失效，因为不能保证索引列运算后排序顺序不发生变化。
2. 【模糊查询】时，如果头部使用了模糊查询，索引会失效。
3. 查询条件中有【or】时，只有两个条件都建立了索引才能使用索引。
4. MySQL 内部【优化器】会对 SQL 语句进行优化，如果优化器估计使用全表扫描要比使用索引快，则不使用索引。

### 3.3.11 前缀索引

当索引是很长的字符串时，这个索引将会很占内存，而且会很慢，这时候就可以使用前缀索引了。

前缀索引就是只将字符串的一部分前缀建立索引。

前缀长度可以根据【索引的选择性】判断，目的就是要尽量降低索引的重复率。

### 3.3.12 索引的设计原则

1. 针对【数据量较大】，且【查询操作频繁】的表建立索引。
2. 针对常作为【查询条件(where)】，【排序条件(order by)】，【分组(group by)】、【表的连接条件】的字段建立索引。
3. 尽量选择【区分度高】的列作为索引。
4. 如果字段时很长的字符串，可以建立【前缀索引】。
5. 尽量建立联合索引，使用【覆盖索引】优化查询过程，提高效率。
6. 【控制索引数量】，数量越多维护索引代价就越大。
7. 如果索引列不能储存null值，在创建表时使用【not null约束】，有利于优化器选择索引。

## 3.4 锁

### 3.4.1 全局锁

【全局锁】就是对整个【数据库实例】加锁，需要显示的加锁和解锁。

命令是 Flush tables with read lock (FTWRL)，加锁后数据库处于【只读状态】的时候，后续的【DML语句】和【DDL语句】会被阻塞。

典型的使用场景是【全库的数据备份】，对整个库进行锁定，获得一致性视图。

风险：

- 如果你在主库上备份，那么在备份期间都不能执行更新，发生【业务停摆】。
- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致【主从延迟】。

另外，拿到一致性视图也可以通过事务，在【可重复读】级别下开启一个事务。

mysqldump 命令中 使用参数 –single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。需要所有表都使用 innoDB 引擎。

### 3.4.2 表级锁

#### 表锁 

分为【表锁排它锁】和【表锁共享锁】。没有行级锁时，使用表锁【控制并发】问题，并发【效率较低】。

表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

#### 元数据锁（MDL）

目的是：维护表结构的一致性。

在 MySQL 5.5 版本中引入了 MDL，不需要显式使用。

- 当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。

- 事务中的 MDL 锁，在语句执行开始时申请，整个事务提交后再释放。
- 申请MDL锁的操作会形成一个队列，队列中【写锁】获取优先级高于【读锁】。一旦出现写锁等待，不但当前操作会被阻塞，同时还会阻塞后续写锁和读锁的获取。

风险：

- 出现写锁堵塞，后续所有对表的增删改查操作都会阻塞。
- 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。

解决：

- 避免长事务操作。或者执行DDL语句时，kill或暂停长事务。
- 设置写锁等待超时后自动释放。

#### 意向锁

目的是：避免表锁与行锁的冲突。

意向锁分为【意向共享锁】和【意向排他锁】，加行锁时，会自动加对应的意向锁，意向锁之间不会互斥。

【意向共享锁】会与【表锁排它锁】互斥；【意向排它锁】会与【表锁排它锁】和【表锁共享锁】互斥。

### 3.4.3 行锁

innoDB 引擎实现了行锁，并发控制中锁粒度最小，并发效率最高。行锁分为【记录锁】、【间隙锁】和【临建锁】。

innoDB 引擎是通过索引组织数据的，行锁是通过对索引上的【索引项加锁】实现的，而不是对记录的加锁。

只有执行计划真正【使用了索引】，InnoDB才使用【行级锁】；否则，InnoDB将使用【表锁】。



【两阶段锁协议】：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。

出现死锁的两种方案：

1. 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
2. 另一种策略是，出现资源等待时，发起死锁检测，如果发现死锁，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

建议使用第二种策略：

如何避免死锁检测的占用大量CUP资源：

- 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。
- 在数据库服务端，控制并发度，基本思路就是，对于相同行的更新，在进入引擎之前排队。
- 考虑通过将一行改成逻辑上的多行来减少锁冲突，参考java中的LongAdder。

#### 记录锁

锁定的是单个行记录，防止其他事务对此行进行 update 和 delete 。

记录锁分为【共享锁】和【排它锁】，共享锁和排它锁以及排它锁和排它锁互斥。

#### 间隙锁

间隙锁锁住的是数据之间的间隙，目的是防止其他事务在这个间隙中插入数据。

间隙锁可以共存，一个事务加间隙锁不会阻止另一个事务加间隙锁，两个事务同时在一个间隙加间隙锁时，就可能出现死锁的问题。

#### 临建锁

记录锁和间隙锁的组合，同时锁住数据，并锁住数据前面的间隙。

## 3.5 事务

### 3.5.1 什么是事务

事务是逻辑上的一组操作，要么都执行，要么都不执行。

### 3.5.2 事务的特性(ACID)

【原子性】：事务是最小的执行单位，不允许分割。原子性确保一个事务中多个操作要么全部完成，要么全部失败。

【一致性】：一个事务在执行之后，数据库必须从一个一致性状态进入另一个一致性状态。

【隔离性】：并发访问数据库时，一个用户的事务不被其他事务所干扰，每个事务都有各自完整的数据空间。

【持久性】：一个事务被提交之后，它对数据库中数据的改变必须被永久保存下来，即使数据库发生故障也不应该对其有任何影响。

### 3.5.3 并发事务带来的问题

脏读（Dirty read）: 一个事务读到了另一个事务还没有提交的数据。

不可重复读（Unrepeatableread）: 指在一个事务内多次读同一行数据的结果不同。

幻读（Phantom read）: 一个事务执行过程中，由于另一个事物在表中插入了数据，导致当前事务后一次查询看到了前一次查询之前没看到的行。

### 3.5.4 四种隔离级别

READ-UNCOMMITTED(读未提交)：最低的隔离级别，一个事务可以读取另一个未提交事务产生的数据，可能会导致脏读、幻读或不可重复读。

READ-COMMITTED(读已提交)：一个事务只能读取到其他已提交事务产生的数据，可以阻止脏读，幻读或不可重复读仍有可能发生。

REPEATABLE-READ(可重复读)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，幻读仍有可能发生。

SERIALIZABLE(串行化)：最高的隔离级别，所有的事务串行化顺序执行，事务之间就不会产生干扰，可以防止脏读、不可重复读以及幻读。

### 3.5.5 MVCC

MVCC(Multiversion concurrency control) 即多版本并发控制，是一种并发控制的方法。

实现了快照读：对同一份数据保留了多个版本，在查询的时候，如果当前版本不可见，则依次查询之前的版本，找到允许访问的版本并返回，通过【read view】和【版本链】实现。

作用：高并发场景下，【不用加锁】，【提升并发性】能，MVCC 比行级锁【开销更小】。

#### MVCC 实现原理

MVCC 的实现依赖于版本链，版本链是通过表的【三个隐藏字段】和【undo log日志】实现。

- DB_TRX_ID ：产生这条记录的事务id，事务id是自增的。 
- DB_ROLL_PRT ：回滚指针，指向当前行记录的上一个版本，通过这个指针连接不同版本构成这条记录的版本链。
- DB_ROLL_ID ：隐藏主键，innodb使用【聚集索引】管理数据，如果一个表没有主键，并且没有满足聚集索引条件的唯一索引，则会生成这个隐藏id，作为【聚集索引】的字段。

使用事务更新行记录的时候，就会在版本链生成新的版本数据，执行过程如下：

1. 用排他锁锁住该行。 
2. 记录更新语句对应的 undo log 日志。
3. 生成新版本，回滚指针指向 undo log 日志中这条记录，可以通过这条日志记录得到前一个版本的状态。

执行快照读时根据生成的 readview 判断版本链中哪一个版本可见，然后返回可见的版本：

readview结构：

- 【当前事务id】
- readview创建时【活跃事务列表】
- 【高水位】\(up_limit_id)：readview创建时出现过的最大的事务ID+1
- 【低水位】\(low_limit_id)：活跃事务列表中最小的事务ID

#### 可见性判断

- 如果一条记录的事务id等于readview当前事务id，说明这条记录是本事务产生的，可见。
- 如果一条记录的事务id小于低水位，说明readview生成之前这个事务已经提交，可见。
- 如果一条记录的事务id大于等于高水位，说明这个事务是生成readview之后才申请的，不可见。
- 如果一条记录的事务id在高水位和低水位之间，判断这个事务id是否在活跃事务列表中。
  - 如果在，表示readview生成时这条记录未提交，不可见。
  - 如果不在，表示readview生成时这条记录已经提交，可见。

#### RC 和 RR差异

- 读已提交隔离级别下，每次 select 查询前都生成一个 Read View ，查询时已经提交的事务结果就是可见的。

- 可重复读隔离级别下，只在事务开始后的第一次 select 查询前生成一个 Read View ，后续查询都使用这个readview，readview生成之后提交的事务结果是不可见的。


#### MVCC+间隙锁 防止幻读

幻读原因：一个事务执行过程中，另一个事务通过insert语句新增了数据，导致当前事务两次查询同一范围的数据量不同。

1. 在快照读的情况下，会通过 mvcc 来避免幻读

   RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，并使用至事务提交。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见。

2. 在当前读的情况下，会通过【间隙锁】来避免幻读

   InnoDB 使用【间隙锁】，当执行【当前读】读取一个范围的记录时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。

## 3.6 主从复制

### 3.6.1 主从复制优点

1. 主库出现问题，可以快速【切换到从库】提供服务。
2. 实现【读写分离】，降低主库的访问压力。
3. 可以在【从库中执行备份】，以避免备份期间影响主库服务。

### 3.6.2 过程

复制分成三步：

1. 主库 binlog 线程 ： 负责在主库事务提交时，把数据变更记录在二进制日志文件 BinLog 中。
2. 备库 I/O 线程 ：负责从主库读取 BinLog 日志，并写入从库的 Relay log 日志中。
3. 备库 SQL 线程 ：负责解析 Relay Log 日志，并执行其中的 SQL 语句。

## 3.7 其他

### 3.7.1 大表怎么优化

当MySQL单表记录数过大时，数据库的性能会明显下降，一些常见的优化措施如下：

- 【限定数据的范围】。比如：用户在查询历史信息的时候，可以控制在一个月的时间范围内。
- 【读写分离】：建立主从集群，主库负责写，从库负责读。 
- 通过【分库分表】的方式对数据库表进行拆分，主要有【垂直拆分】和【水平拆分】两种方式。

### 3.7.2 分库分表

当单表的数据量过多时，优化索引、添加从库等可能对数据库性能提升效果不明显，此时就要考虑对其进行切分了。

切分的目的就在于减少一个表单的数据量，【减少数据库的负担】，【缩短查询的时间】。

数据切分可以分为两种方式：【垂直划分】和【水平划分】。

#### 垂直切分

垂直划分数据库是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。例如：将原来的电商数据库垂直切分成商品数据库、用户数据库等。

优点：行记录变小，【数据页】可以存放更多记录，在查询时减少I/O次数。

缺点：

- 主键出现冗余，需要管理冗余列。
- 会引起表连接JOIN操作，可以通过在业务服务器上进行join来减少数据库压力。 
- 依然存在单表数据量过大的问题。

#### 水平切分

水平切分是将同一个表中的记录拆分到多个结构相同的表中。比如根据年份来拆分不同的数据库。

优点：单库（表）的数据量得以减少，提高性能；切分出的表结构相同，程序改动较少。

缺点：

- 分片事务一致性难以解决
- 跨节点 join 性能差，逻辑复杂
- 数据分片在扩容时需要迁移

### 3.7.3 having和where区别？

- 二者作用的对象不同，where 子句作用于【表和视图】，having 作用于【组】。
- where 在数据分组前进行过滤，having 在数据分组后进行过滤。

### 3.7.4 乐观锁和悲观锁

【乐观锁】和【悲观锁】是并发控制中常见的技术手段。

【悲观锁】：假定会发生并发冲突，在查询完数据的时候就把事务锁起来，直到提交事务时释放锁。这对于长事务来讲，可能会严重影响系统的并发处理能力。

- 实现方式：使用数据库中的锁机制。

【乐观锁】：假设不会发生并发冲突，只在提交操作时使用【CAS机制】检查是否违反【数据完整性】。乐观锁适用于【读多写少】的应用场景，这样可以提高吞吐量。

- 实现方式：一般会使用版本号机制或 CAS 算法实现。

### 3.7.5 唯一索引和普通索引

对于查询操作，唯一索引只要找到对应的一条数据即可，而普通索引还要判断是否有多条数据满足条件，这个性能上差距可以忽略，因为多数情况下是在内存中同一个数据页中查找的。



对于更新操作，普通索引可以使用 change buffer ，比如：

- 插入一条数据时，如果该数据页不在内存中，如果使用的是【唯一索引】，需要将数据页加载到内存中，验证该插入操作是否满足唯一索引的限制
- 如果是【普通索引】，不用这步验证操作，可以直接将修改结果写到 change buffer 中，等到需要查询该数据页并将数据页加载到内存中时，才对其进行修改。

change buffer 减少了更新操作中的随机磁盘读操作，可以明显提升更新操作性能。

而对于查询操作比较多的业务，写操作后会紧接着该数据的读操作，随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。

### 3.7.6 脏页刷新策略

如果一个SQL语句执行过程中要刷脏页，就会影响这条语句的性能。

什么情况会引发数据库的 flush 过程：

- redo log 缓冲区写满。
- 内存不够用需要淘汰一些数据页时，如果淘汰的是“脏页”，就要先将脏页写到磁盘。
- MySQL 认为系统“空闲”的时候。
- MySQL 正常关闭的情况

前两种情况会对性能产生影响，所以脏页刷新策略要尽量避免这种情况，要着重考虑【脏页比例】和【redo log写入速度】这两个方面。



MySQL有一个【连坐机制】，一个刷脏页时，如果邻居数据页也是脏页，会连同这个邻居一起刷新。这样是为了减少 随机IO 的次数。

innodb_flush_neighbors 可以控制这个“连坐”机制，1表示开启，0表示关闭；MySQL 8.0 中，默认是 0 。

### 3.7.7 order by 如何工作

MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer ，参数 sort_buffer_size 可以控制 sort buffer 大小。

如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，使用磁盘临时文件辅助排序。

另外如果查到的数据集本身就满足了排序规则，就不用额外排序操作，可以通过建立【联合索引】尽量达到条件。

两种排序方式：

- 【全字段排序】
  - 会将要查询的所有字段都放入sort buffer中进行排序，排序完成后结果直接返回给客户端。
- 【rowID排序】
  - 只将主键字段和要排序字段放入sort buffer中进行排序，排序完成后还要根据主键字段回表查找得到要查询的字段值，再返回给客户端。

如果内存足够优先使用全字段排序，内存不足时使用rowID排序，rowID排序会多一次回表查询的操作。

# 4. redis

## 4.1 概述

### 4.1.1 redis是什么

Redis 就是一个使用【C 语言】开发的数据库，并且数据是存在【内存】中的，所以读写速度非常快，因此 Redis 被广泛应用于【缓存】方向。

另外，Redis 除了做缓存之外，也经常用来做【分布式锁】，也可以作为【消息队列】。

Redis 提供了【多种数据类型】来支持不同的业务场景。Redis 还支持【事务】、【持久化】、【Lua 脚本】、多种【集群】方案。

### 4.1.2 分布式缓存

分布式缓存的话，使用的比较多的主要是 Memcached 和 Redis，目前一般都是直接用 redis 作为缓存。

分布式缓存主要解决的是【单机缓存的容量受服务器限制】并且【无法保存通用信息】的问题。

### 4.1.3 Redis 和 Memcached

#### 共同点

1. 都是基于【内存】的数据库，一般都用来当做缓存使用。
2. 都有【过期策略】。
3. 两者的【性能】都非常高。

#### 区别

1. Redis 支持更【丰富的数据类型】；Memcached 只支持最简单的 k/v 数据类型。 Redis 还提供 list，set，zset，hash 等数据结构的存储。
2. Redis 支持数据的【持久化】，可以通过 RDB 和 AOF 原理将内存中的数据保持在磁盘中，Memecache不支持持久化。
3. Redis 有【灾难恢复机制】。因为可以把缓存中的数据持久化到磁盘上。 
4. Redis 在服务器【内存使用完】之后，可以将不用的数据放到【磁盘】上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。
5. Memcached 没有原生的【集群模式】，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 支持原生的 cluster 模式的。
6. 网络模型方面：Memcached 是【多线程】的【非阻塞IO】的网络模型；Redis 使用【单线程】的【多路IO复用】模型。（Redis 6.0 引入了多线程 IO ）
7. Redis 支持【发布订阅】模型、【Lua 脚本】、【事务】功能，而 Memcached 不支持。
8. Memcached 过期数据的删除策略只用了【惰性删除】，而 Redis 同时使用了【惰性删除】与【定期删除】。

### 4.1.4 单线程还是多线程

*Redis 到底是单线程还是多线程？*

- 核心业务部分的【命令处理】和【网络模型】是单线程。
- 整个 Redis 是多线程。

*在 Redis 版本迭代过程中，在两个重要的时间节点上引入了多线程的支持：*

- Redis v4.0：引入多线程异步处理一些【比较耗时的任务】，例如异步删除命令 unlink
- Redis v6.0：在核心【网络模型】中引入多线程，进一步提高对于多核 CPU 的利用率

### 4.1.5 单线程为什么这么快

- Redis 的大部分操作在【内存】上完成。

- 采用了高效的数据结构，Redis 使用了一个【全局哈希表】来保存所有键值对，通过 key 找到 value 的时间复杂度接近O(1),

  并且集合类型的数据结构也采用了【哈希】和【跳表】这些查询效率较高的数据结构。

- 网络IO部分，采用了【IO多路复用】机制，单线程可以同时监听多个客户端的 socket 。

## 4.2 数据结构

### 4.2.1 底层数据结构

#### 4.2.1.1 简单动态字符串

c语言中字符串问题：

- 获取字符串的长度需要通过运算
- 非二进制安全，c语言中字符串结束通过特殊字符'/0'判断，所以字符串中不能包含这个特殊字符
- 不可修改，c语言中字符串存放在常量池中

简单动态字符串：c语言中的结构体实现。属性：长度，申请总字节数，头类型标识，char数组存放数据。

优点：

1. 结构体中存储了字符串长度，获取长度的时间复杂度为O(1)。
3. 支持【动态扩容】，并且需要扩容时会执行【内存预分配】，减少内存分配次数。
   - 如果新字符串小于1M，则新空间为扩展后字符串长度的两倍+1；
   - 如果新字符串大于1M，则新空间为扩展后字符串长度+1M+1。
4. 二进制安全

<img src="D:/Typora/picture/image-20220528152607906.png" alt="image-20220528152607906" style="zoom:80%;" />

#### 4.2.1.2 IntSet

- 基于【整数数组】实现的，并且元素【唯一】且【有序排列】，【长度可变】。
- 支持【多种编码方式】，比如16位、32位、64位整数，inset中插入一个数字如果超过当前编码方式的最大值，自动升级编码方式，可以节省内存空间。
- 查找或添加元素时，使用【二分法】，时间复杂度log(n)。

<img src="D:/Typora/picture/image-20220528153746243.png" alt="image-20220528153746243" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528154109415.png" alt="image-20220528154109415" style="zoom:80%;" />

#### 4.2.1.3 dict

Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）。

Dict 中有两个哈希表指针，rehash 时使用另一个。

<img src="D:/Typora/picture/image-20220528155338532.png" alt="image-20220528155338532" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528155242393.png" alt="image-20220528155242393" style="zoom:80%;" />

##### **rehash**

Dict结构体中有 两个哈希表指针，一个长整型表示rehash的进度。

每次新增数据时，会检查【负载因子】（LoadFactor = used/size） ，以下两种情况会触发【哈希扩容】：

- 哈希表的 LoadFactor >= 1，并且服务器没有执行 BGSAVE 或者 BGREWRITEAOF 等后台进程。
- 哈希表的 LoadFactor > 5 。

每次删除元素时，也会对负载因子做检查，当LoadFactor < 0.1 时，会做哈【希表收缩】。



不管是扩容还是收缩，必定会创建新的哈希表，导致哈希表的 size 和 sizemask 变化，而 key 的查询与 sizemask 有关。因此必须对哈希表中的每一个key重新计算索引，插入新的哈希表，这个过程称为【rehash】。

1. 【计算新 hash 表的 realeSize】，值取决于当前要做的是扩容还是收缩：

   - 如果是扩容，则新size为第一个大于等于 dict.ht[0].used + 1的2^n^

   - 如果是收缩，则新size为第一个大于等于 dict.ht[0].used 的2^n^ （不得小于4）

2. 按照新的 realeSize 【申请内存空间】，【创建 dictht】，并赋值给 dict.ht[1]

3. 设置【dict.rehashidx = 0】，表示开始 rehash。

4. 每次执行新增、查询、修改、删除操作时，都检查一下 dict.rehashidx 是否大于-1，如果是则将 dict.ht[0].table[rehashidx] 的 entry 链表 rehash 到 dict.ht[1]，并且将rehashidx++。直至dict.ht[0]的所有数据都rehash到dict.ht[1]。

5. rehash 结束后，将 dict.ht[1] 赋值给 dict.ht[0]，给 dict.ht[1] 初始化为空哈希表，释放原来的 dict.ht[0] 的内存，将 rehashidx 赋值为-1，代表 rehash 结束。

6. 在 rehash 过程中，新增操作，则直接写入ht[1]，查询、修改和删除则会在dict.ht[0]和dict.ht[1]依次查找并执行。这样可以确保ht[0]的数据只减不增，随着rehash最终为空。

#### 4.2.1.4 ZipList

*ZipList特点：*

1. ZipList 是一种特殊的【双端链表】，在内存中是【连续存放】的。在任意一端进行【压入/弹出】操作的时间复杂度为 O(1)。
2. 列表的节点之间不是通过指针连接，而是记录上一节点和本节点【长度来寻址】，内存占用较低。
3. 如果列表数据过多，导致链表过长，可能影响【查询性能】。
4. 增或删较大数据时有可能发生【连锁更新】问题。

*ZipList结构：*

<img src="D:/Typora/picture/image-20220528165518681.png" alt="image-20220528165518681" style="zoom:80%;" />

- zlbytes:整个压缩列表占用的【内存字节数】。

- zltail:【表尾节点】距离【起始地址】的偏移量，找到尾节点的时间复杂度为O(1)。

- zllen:压缩列表的【节点数量】。 最大值为 UINT16_MAX（65534），如果超过这个值，此处会记录为65535，但节点的真实数量需要遍历整个压缩列表才能计算得出。

- entry:压缩列表包含的各个节点，节点的长度由节点保存的内容决定。

- zlend: 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。


*entry结构：*

为了节省内存，没有记录前后节点的指针(一个指针需要8个字节)。而是在每个节点记录当前节点和前一个节点的长度。

<img src="D:/Typora/picture/image-20220528170001472.png" alt="image-20220528170001472" style="zoom:80%;" />

- uprevious_entry_length：前一节点的长度，占1个或5个字节。

  - 如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值。

  - 如果前一节点的长度大于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe，后四个字节才是真实长度数据。

- encoding：编码属性，记录content的【数据类型】（字符串还是整数）以及【长度】，占用1个、2个或5个字节。

- contents：负责保存节点的数据，可以是【字符串】或【整数】。

*ZipList的连锁更新问题:*

- 每个Entry都包含previous_entry_length来记录上一个节点的大小,插入一个节点后可能导致后面一系列节点的 previous_entry_length 值需要从一个字节扩容到5个字节。
- 如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值，否则采用5个字节。

#### 4.2.1.5 QuickList

是一个【双向链表】结构，每一个entry中保存一个ZipList的指针。

*特点：*

1. 节点采用ZipList，解决了传统链表的【内存占用】问题。

2. 控制了ZipList大小，解决【连续内存空间申请效率】问题。

3. 中间节点可以【压缩】，进一步节省了内存。

<img src="D:/Typora/picture/image-20220528170838005.png" alt="image-20220528170838005" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528170859285.png" alt="image-20220528170859285" style="zoom:80%;" />

#### 4.2.1.6 SkipList

*特点：*

1. 跳表首先是一个【双向链表】，每个节点都包含 score 和 element 值；节点按照score值排序，score值一样则按照element字典排序。
2. 每个节点都可以包含多层指针，层数是1到32之间的随机数；不同层指针到下一个节点的跨度不同，层级越高，跨度越大。
3. 增删改查效率与红黑树基本一致，实现却更简单。

<img src="D:/Typora/picture/image-20220528171359052.png" alt="image-20220528171359052" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528171433620.png" alt="image-20220528171433620" style="zoom: 80%;" />

#### 4.2.1.7 RedisObject

Redis中的【任意数据类型】的【键】和【值】都会被封装为一个RedisObject，也叫做Redis对象，源码如下：

16个字节：1/2+1/2+3+4+8。

<img src="D:/Typora/picture/image-20220528172511587.png" alt="image-20220528172511587" style="zoom:80%;" />

#### 4.2.1.8 redisDB

Redis本身是一个典型的key-value内存存储数据库，因此所有的key、value都保存在之前学习过的Dict结构中。

在redisDB结构体中，有两个Dict：一个用来记录【key-value地址】；另一个用来记录【key-TTL存活时间】。

还有一个 watched-keys 的Dict，保存事务执行前使用 watch 监控的 key。

<img src="D:/Typora/picture/image-20220528224752372.png" alt="image-20220528224752372" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528224819396.png" alt="image-20220528224819396" style="zoom:80%;" />

### 4.2.2 常见数据类型

<img src="D:/Typora/picture/image-20220528172731676.png" alt="image-20220528172731676" style="zoom:80%;" />

#### 4.2.2.1 String

*三种编码方式：*

- 其基本编码方式是【RAW】，基于简单动态字符串（SDS）实现，存储上限为512mb。
- 如果存储的SDS长度小于44字节，则会采用【EMBSTR】编码，此时object head与SDS是一段连续空间。申请内存时只需要调用一次内存分配函数，效率更高。
- 如果存储的字符串是整数值，并且大小不超过Long类型最大值，则会采用【INT】编码：直接将数据保存在RedisObject的ptr指针位置（刚好8字节），不再需要SDS。

<img src="D:/Typora/picture/image-20220528173927219.png" alt="image-20220528173927219" style="zoom:80%;" />

#### 4.2.2.2 List

List结构类似一个【双端链表】，可以从首、尾操作列表中的元素：

- 在3.2版本之前，当【元素数量小于512】并且【元素大小小于64字节】时采用【ZipList】编码，超过则采用【LinkedList】编码。
- 在3.2版本之后，统一采用【QuickList】来实现List。

#### 4.2.2.3 Set

Set是Redis中的【单列集合】，满足下列特点：

- 不保证有序性
- 保证元素唯一
- 求交集、并集、差集

*编码方式：*

- 当存储的所有数据都是【整数】，并且元素【数量不超过set-max-intset-entries】时，Set会采用【IntSet】编码，以【节省内存】。

- 否则，为了【查询效率】和【唯一性】，set采用【HT】编码（Dict）。Dict中的key用来存储元素，value统一为null。

  <img src="D:/Typora/picture/image-20220528175250761.png" alt="image-20220528175250761" style="zoom:80%;" />

#### 4.2.2.4 ZSet

ZSet也就是SortedSet，其中每一个元素都需要指定一个【member值】和【score值】：

- 可以根据score值排序
- member必须唯一
- 可以根据member查询分数

*编码方式：*

当元素数量较少时，采用【ZipList】结构来节省内存，需要同时满足两个条件：

- 元素数量小于zset_max_ziplist_entries，默认值128。

- 每个元素都小于zset_max_ziplist_value字节，默认值64。

ziplist本身没有排序功能，也没有键值对的概念，需要有zset自己实现：

- ZipList是连续内存，因此score和element是紧挨在一起的两个entry，element在前，score在后。

- score越小越接近队首，score越大越接近队尾，按照score值升序排列。



元素数量较多时，采用【SkipList + HT（Dict）】

- SkipList：可以排序，并且可以同时存储score和ele值（member）。
- HT（Dict）：可以键值存储，并且可以根据key找value。

<img src="D:/Typora/picture/image-20220528175703020.png" alt="image-20220528175703020" style="zoom:80%;" />

#### 4.2.2.5 Hash

Hash结构与Redis中的Zset非常类似：

- 都是键值存储
- 都需求根据键获取值
- 键必须唯一

Hash底层采用的编码与Zset也基本一致，只需要把排序有关的SkipList去掉即可

*编码方式：*

- 数据量较少时采用【ZipList】编码，用以节省内存。
  - ZipList中相邻的两个entry 分别保存 field 和 value。

- 当数据量较大时，Hash结构会转为【HT】编码，也就是Dict，触发条件有两个：
  - ZipList中的元素数量超过了hash-max-ziplist-entries（默认512）
  - ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节）



## 4.3 持久化机制

### 4.3.1 AOF

AOF 里记录的是 Redis 收到的每一条【命令】。

AOF默认是关闭的，需要修改配置文件，手动开启。

AOF 日志是【写后日志】：先执行命令，把数据写入内存，然后才记录AOF日志。

- 好处：执行成功后才写入日志，避免写入错误日志，写入日志之前不用做语法检查，节省时间。

#### 三种写回策略

【Always，同步写回】：每个写命令执行完，立马同步地将日志写回磁盘。

【Everysec，每秒写回】：每个写命令执行完，只是先把日志写到 AOF 文件的page cache中，每隔一秒把缓冲区中的内容写入磁盘。

【No，操作系统控制的写回】：每个写命令执行完，只是先把日志写到 AOF 文件的page cache中，操作系统负责将缓冲区内容写回磁盘。

<img src="D:/Typora/picture/image-20210725151654046.png" alt="image-20210725151654046" style="zoom:80%;" />

#### 重写机制

*AOF 文件过大带来性能问题：*

- 如果文件太大，之后再往里面追加命令记录的话，效率也会变低。
- 故障恢复时，AOF 中记录的命令要一个个被重新执行，如果日志文件太大，整个恢复过程就会非常缓慢。

*重写机制原理：*

- 创建一个新的 AOF 文件。
- 读取数据库中的所有键值对，每一个键值对用一条命令记录它的写入。

*AOF 重写会阻塞吗?*

- AOF 日志由主线程写回，重写过程是由后台【子进程 bgrewriteaof】来完成的，这也是为了避免阻塞主线程，导致数据库性能下降 。

### 4.3.2 RDB

RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做【Redis数据快照】。

RDB 是二进制日志，记录的是【内存某一时刻的状态】，当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。

#### 执行时机

RDB默认就是开启的，redis停机时，会执行RDB，默认情况就是支持持久化的。RDB持久化在四种情况下会执行：

- 执行save命令
- 执行bgsave命令
- Redis停机时
- 触发RDB条件时

#### RDB原理

bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据，生成RDB快照，将内存中数据写到二进制文件中。

*fork采用的是 copy-on-write 技术：*

- 当主进程执行读操作时，访问共享内存。
- 当主进程执行写操作时，则会拷贝对应的内存块，并修改自身的页表，这部分数据与子进程分离，然后更新主进程数据。

*频繁快照开销：*

- 频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的【磁盘带宽】，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
- bgsave 子进程需要通过 fork 操作，fork 这个创建过程本身会【阻塞主线程】，而且主线程的内存越大，阻塞时间越长。

*RDB的缺点：*

- RDB执行间隔时间长，如果出现故障可能【丢失较多数据】。
- fork子进程的过程会【阻塞主线程】，数据量越大阻塞时间会越长，子进程记录日志也会有较大的【磁盘消耗】。

#### AOF和RDB选择

- 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择。
- 如果允许分钟级别的数据丢失，可以只使用 RDB。
- 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。

#### AOF和RDB对比

- 可靠性方面：AOF 默认每s刷盘，数据【可靠性】较高；RDB可靠性较差，出现故障时，可能会丢失分钟级别的数据。
- 文件恢复方面：AOF 记录的是【命令】，【文件较大】，恢复数据时【执行速度较慢】；RDB 是【二进制日志】，记录的是内存状态，【文件较小】，恢复数据时【执行速度较快】。
- 性能方面：AOF 日志默认情况下由【主线程】控制进行刷盘操作，性能相对较差；RDB 由fork出的【子进程】记录日志，主线程没有刷盘操作，性能更好。
- 系统资源占用方面：RDB占用较高，子进程可能占用大量CPU和内存资源；AOF占用较低，主要是磁盘IO资源。

## 4.4 缓存应用问题

### 4.4.1 缓存穿透

【缓存穿透】是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，导致大量请求都会访问到数据库。

*原因：*

- 业务层误删了这条数据。
- 恶意攻击。

*解决方案：(常见的有两种)*

1. 如果发生缓存穿透，【缓存空值】或缺省值，避免了请求到达数据库。
   - 优点：实现简单，维护方便。
   - 缺点：额外的内存消耗，可能造成短期的数据不一致。
2. 使用【布隆过滤器】判断数据是否存在。
   - 优点：内存占用较少，没有多余key。
   - 缺点：实现复杂，存在误判可能。
3. 【增强id的复杂度】，避免被猜测id规律
4. 做好数据的【基础格式校验】
5. 加强【用户权限校验】

### 4.4.2 缓存击穿

【缓存击穿】问题也叫热点Key问题，就是一个【被高并发访问】并且【缓存重建业务较复杂的key】突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。

*解决方案：*

- 【互斥锁】：如果缓存未命中，访问MySQL之前加互斥锁，然后主动更新缓存。
  - 优点：可以保证一数据致性，实现简单。
  - 缺点：线程需要等待，性能受影响。
- 【逻辑过期】：热点key不设置过期时间，而是设置一个逻辑过期时间，程序判断是否过期。
  - 优点：线程无需等待，性能较好。
  - 缺点：不保证一致性，实现复杂。

### 4.4.3 缓存雪崩

【缓存雪崩】是指缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。

*原因：*

- 同一时段大量的缓存key同时失效
- Redis服务宕机

*解决方案：*

- 给不同的Key的【过期时间添加随机值】，避免大量key同时过期。
- 利用【Redis集群】提高服务的可用性。
- 给缓存业务添加【降级限流策略】。
- 给业务添加【多级缓存】。

### 4.4.4 数据一致性

#### 缓存更新策略

*三种策略：*

- 内存淘汰
- 超时剔除
- 主动更新

*业务场景：*

- 低一致性需求：使用内存淘汰机制。
- 高一致性需求：主动更新，并以超时剔除作为兜底方案。

<img src="D:/Typora/picture/image-20220529153139611.png" alt="image-20220529153139611" style="zoom: 50%;" />

#### 主动更新策略

Cache Aside Pattern（旁路缓存模式）

Read/Write Through Pattern（读写穿透）

Write Behind Pattern（异步缓存写入）

#### 读写缓存优缺点

- 优点：【缓存中一直会有数据】，如果更新操作后会立即再次访问，可以直接命中缓存，能够【降低读请求对于数据库的压力】。
- 缺点：如果更新后的数据，之后很少再被访问到，会导致【缓存利用率不高】；会有【线程安全问题】，需要加锁。

#### 如何保证同时成功

事务：

- 单体系统，将缓存与数据库操作放在一个事务。
- 分布式系统，利用TCC等分布式事务方案。

使用消息队列重试：

- 把第二步操作放入到消息队列中，消费者从消息队列取出消息，再更新缓存或数据库。
- 成功后把消息从消息队列删除，否则进行重试，以此达到数据库和缓存的最终一致。

### 4.4.5 读写缓存策略

#### 旁路缓存

Cache Aside Pattern（旁路缓存模式）：由缓存的调用者，在更新缓存的同时更新数据库。

- 缺陷1：首次请求数据一定不在 cache 的问题
  - 可以将热点数据可以提前放入cache 中。
- 缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率。
  - 数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，加一个锁/分布式锁来解决线程安全问题。
  - 可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

#### 读写穿透

Read/Write Through Pattern（读写穿透）：缓存与数据库整合为一个服务，在服务内部保证数据一致性。调用者只需调用服务，无需关心缓存一致性问题。

#### 异步缓存写入

Write Behind Pattern（异步缓存写入）：调用者只操作缓存，由异步线程负责将缓存数据持久化到数据库，保证最终一致。

平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如【消息队列】中消息的异步写入磁盘、【MySQL】 的 InnoDB Buffer Pool 机制都用到了这种策略。

- 缺点：一致性较差，比如 cache 数据还没异步更新 DB 就挂掉了，那更新到 cache 中这部分数据也就丢失了。
- 优点：写性能非常高，适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

## 4.5 内存管理

### 4.5.1 过期策略

Redis本身是一个典型的key-value内存存储数据库，因此所有的key、value都保存在之前学习过的Dict结构中。

在redisDB结构体中，有两个Dict：一个用来记录key-value；另一个用来记录key-TTL。

<img src="D:/Typora/picture/image-20220528224752372.png" alt="image-20220528224752372" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528224819396.png" alt="image-20220528224819396" style="zoom:80%;" />

**惰性删除：**在TTL到期后不会立刻删除，而是在访问一个key的时候，检查该 key 的是否过期，如果已经过期才执行删除。

**周期删除：**通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。具体来说有两种模式：

- Redis服务初始化函数【initServer()】中设置定时任务，按照 server.hz 的频率来执行过期key清理，为【SLOW模式】。
- Redis的每个事件循环中会首先调用【beforeSleep()】函数，执行过期key清理，为【FAST模式】。

【SLOW模式】规则：

- 执行频率受server.hz影响，默认为10，即每秒执行10次，执行清理耗时不超过一次执行周期的25%，默认25ms。
- 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期
- 如果没达到时间上限（25ms）并且过期key比例大于10%，再进行一次抽样，否则结束

【FAST模式】规则（过期key比例小于10%不执行）：

- 执行频率受 beforeSleep() 调用频率影响，但两次FAST模式间隔不低于2ms，执行清理耗时不超过1ms。
- 逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期
- 如果没达到时间上限（1ms）并且过期key比例大于10%，再进行一次抽样，否则结束

### 4.5.2 淘汰策略

**内存淘汰**：就是当Redis内存使用达到设置的上限时，主动挑选部分key删除以释放更多内存的流程。

Redis会在处理客户端命令的方法processCommand()中尝试做内存淘汰。

<img src="D:/Typora/picture/image-20220528225709688.png" alt="image-20220528225709688" style="zoom:80%;" />

*Redis支持8种不同策略来选择要删除的key：*

- no_eviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。
- volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰
- allkeys-random：对全体key ，随机进行淘汰。也就是直接从db->dict中随机挑选
- volatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db->expires中随机挑选。
- allkeys-lru： 对全体key，基于LRU算法进行淘汰
- volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰
- allkeys-lfu： 对全体key，基于LFU算法进行淘汰
- volatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰

*比较容易混淆的有两个：*

- LRU（Least Recently Used），最少最近使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。
- LFU（Least Frequently Used），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。

*LRU和LFU需要借助结构体redisObject中的属性：*

<img src="D:/Typora/picture/image-20220528225814231.png" alt="image-20220528225814231" style="zoom:80%;" />

*执行流程：*

1. 判断内存是否充足，如果不充足，判断是否是NO_EVICTION策略，

2. 如果不是，判断是否是AllKeys，然后选择一个Dict，从中淘汰数据，

3. 判断是否是Random，如果是随机淘汰一个即可，

4. 如果不是，先准备一个eviction_pool淘汰池。

5. 轮询 DB ，从中随机挑选一定数量的key，根据淘汰策略计算key对应的idleTime属性，淘汰池中的key按idleTime属性排序，idleTime越大越优先淘汰。

   判断这些key是否可以加入淘汰池，只有idleTime大于淘汰池中最小idleTime的key可以放进去，然后将key放入淘汰池。

7. 重复过程5，直到DB轮询完毕。然后从淘汰池中，选择一个idleTime最大的key删除。

<img src="D:/Typora/picture/image-20220528225911418.png" alt="image-20220528225911418" style="zoom:80%;" />

## 4.6 分布式锁

### 4.6.1 基本使用

分布式锁：满足【分布式系统】或【集群模式】下多进程可见并且互斥的锁。

*获取和释放锁：*

- 利用setnx命令获取锁，del命令释放锁。
- 为了防止解锁后出现异常导致锁无法释放，需要设置过期时间。
- 防止加锁后没有来得及释放锁就异常，需要实现加锁和设置过期时间的【原子性】，使用set命令，加上ex选项和nx选项。

*释放的锁不是自己的：*

- value 设置成自己的标识(比如key中增加当前线程id)，解锁时先检查锁是否是自己的。
- 保证判断锁和释放锁的原子性：使用lua脚本。

存在问题：【不可重入】，【不可重试】，【超时释放】，【主从延迟】。

### 4.6.2 redisson原理

Redisson是一个在Redis的基础上实现的【Java驻内存数据网格】。提供了一系列【分布式服务】，比如：分布式锁。

使用hash结构的锁，【key为锁名称】，【field为线程标识】，【value为重入次数】。

加锁和释放锁都使用【lua脚本】实现【原子性】。

#### 可重入原理

加锁时，判断当前锁是否是自己的，如果是，重入次数+1。

释放锁时，重入次数-1，如果重入次数为0，才会删除锁。

加锁和释放锁都使用lua脚本实现原子性。

#### 锁重试原理

可以指定一段时间获取锁，如果在时间内得到锁则返回true，如果超过时间还没获取锁则返回false。

第一次尝试获取锁失败后，如果还有剩余时间，不会立即返回false。会订阅这个锁对应的一个频道，另一个线程释放锁后，会在频道中发送消息，如果在指定时间内收到消息，则尝试重新获得锁。

<img src="D:/Typora/picture/image-20220529175635940.png" alt="image-20220529175635940" style="zoom: 67%;" />

#### 锁超时问题

利用 watchDog 延续锁时间，也就是获取锁成功后，开启一个定时任务，不断的重置过期时间，保证了业务代码执行完之前锁不会过期。

业务执行完成后，释放锁，并且取消定时任务。

#### 主从延迟问题

使用【multiLock】。

多个独立的Redis节点，必须在所有节点都获取重入锁，才算获取锁成功

## 4.7 集群模式

### 4.7.1 主从集群

#### 全量同步

- 第一阶段：
  - 从库给主库发送【psync 命令】，表示要进行数据同步，命令中包含主库的 replicationID和复制进度offset。

  - 主库收到命令后，判断是否是第一次同步(replicationID和自己ID是否相同)，如果是，返回主库的replicationID和当前复制进度offset。从库收到命令后会记录这两个参数。

- 第二阶段：
  - 主库执行 bgsave 命令，生成 RDB 文件，将文件发给从库。
  - 从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。避免之前数据的影响。
- 第三阶段：
  - master将生成RDB期间执行的命令记录在repl_baklog，并持续将log中的命令发送给slave。
  - slave执行接收到的命令，保持与master之间的同步

#### 增量同步

全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做【增量同步】。

*过程：*

- 从库如果重启，向主库发送【psync命令】，命令中带有【主库ID】和【复制进度offset】。
- 主库收到命令后，判断其中的ID和自己ID是否相同，根据从库的offset从repl_baklog中读取offset后面的数据，发给从库。

repl_baklog 文件是一个【固定大小】的【环形数组】，写满后会覆盖最早的数据。如果slave断开时间过久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步。

#### 主从优化

- 在 master 中配置 repl-diskless-sync yes 启用【无磁盘复制】，直接在内存中创建RDB文件，避免全量同步时的磁盘IO。
- Redis单节点上的【内存占用不要太大】，减少 RDB 导致的过多磁盘IO。
- 适当【提高 repl_baklog 的大小】，发现 slave 宕机时尽快实现故障恢复，尽可能避免全量同步。
- 限制一个master上的【slave节点数量】，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力。

### 4.7.2 哨兵

#### 哨兵三个作用

- 监控：
  - 哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。
  - 如果主库或从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”。
  - 主库标记为客观下线后，开始切换主库的流程。
- 选主：
  - 主库下线后在从库中选择一个称为新的主库。
- 通知：
  - 选出新的主库后，把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。
  - 同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。

#### 哨兵集群

- 通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。
- 避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。

#### 哨兵集群建立

哨兵之间建立集群：

- 发布订阅机制：哨兵通过主库发布的消息得知其他哨兵信息。

哨兵得到从库信息：

- INFO命令：哨兵向主库发送INFO命令，获取从库信息。

哨兵与客户端：

- 哨兵自身的pub/sub功能，从而使客户端得到哨兵信息。

#### 如何判断主库下线

Sentinel基于【心跳机制】监测服务状态，每隔1秒向集群的每个实例发送ping命令：

- 如果一个sentinel节点发现某实例未在规定时间响应，则认为该实例【主观下线】。

- 一个哨兵只要自身判断主库【主观下线】后，就会给其他实例发起投票。接着，其他实例会根据自己和主库的连接情况，回复赞成或反对。
- 如果获得指定票数后，就可以标记主库为【客观下线】。
  - 配置文件中的 quorum 配置项设定的。

#### 如何选举新主库

按照 "筛选"+"打分" 的流程：

- 【筛选】
  - 判断每个从库的网络连接状况和是否掉线，如果节点总是和主库断连或者从库已经掉线，则排除这个节点。

- 【打分】：三轮判断。
  - 第一轮：选择【优先级】最高的从库作为新主库。(用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级)
  - 第二轮：如果优先级一样，则判断slave节点的【offset值】，越大说明数据越新，优先级越高。
  - 第三轮：如果第二轮结束后还有多个节点优先级一样，最后是判断slave节点的【id大小】，越小优先级越高。

#### 哪个哨兵执行主库切换

- 一个哨兵判断主库客观下线后，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。
  - 这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。
- 想成为 Leader 的哨兵，要满足两个条件：
  - 第一，拿到半数以上的赞成票。
  - 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

### 4.7.3 切片集群

*如果数据量过多如何解决：*

- 增大单个实例内存
  - 问题：硬件成本问题，执行RDB文件fork过程阻塞问题。
- 设置切片集群

*设置切片集群目的：*

- 解决海量数据存储问题
- 解决高并发写的问题

*分片集群特征：*

1. 集群中有多个master，每个master保存不同数据。

2. 每个master都可以有多个slave节点，主库下线后可以自动切换到从库。

3. master之间通过ping监测彼此健康状态。

4. 客户端请求可以访问集群任意节点，最终都会被转发到正确节点。


#### 数据和实例的关系

在 Redis Cluster 方案中，一个切片集群共有 16384(2^14^) 个哈希槽，这些插槽分配到不同的实例，每个键值对都会根据它的 key，被映射到一个哈希槽中。

数据key不是与节点绑定，而是与哈希槽绑定。

*具体的映射过程分为两大步：*

- 首先根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。
- 然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

#### 客户端如何定位数据

*过程：*

- 集群创建之后，每个 Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，这样每个实例就存在所有【哈希槽的映射关系】了。
- 客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。
- 当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。

*在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：*

- 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽。
- 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。

*哈希槽分布发生变化后：*

- 实例之间通过相互传递消息，获得最新的哈希槽分配信息。
- Redis Cluster 提供了一种重定向机制,当客户端向一个redis实例发送请求时，如果对应的哈希槽已经转移到其他实例，这个实例就会给客户端返回一个 MOVED 命令响应结果，结果中含有新实例的访问地址，客户端收到MOVED命令后，向新的实例发送请求，并更新本地哈希槽信息。

## 4.8 事务

### 4.8.1 开始事务

MULTI 命令的执行标记着事务的开始：

这个命令唯一做的就是， 将客户端的 REDIS_MULTI 选项打开， 让客户端从非事务状态【切换到事务状态】。

### 4.8.2 事务状态

*命令在执行上区别：*

- 【非事务状态】下的命令以【单个命令为单位】执行，前一个命令和后一个命令的客户端可能不是同一个。
- 【事务状态】则是以一个事务为单位，执行事务队列中的所有命令：事务执行过程汇总，服务器不会中断事务，也不会执行其他客户端的其他命令。

*命令入队：*

- 【非事务状态下】时，所有发送给服务器端的命令都会立即被服务器执行。
- 【事务状态】， 服务器在收到来自客户端的命令时，不会立即执行命令，而是将这些命令全部放进一个事务队列里， 然后返回 QUEUED ，表示命令已入队。
- 入队时，检查语法有没有错误，如果有错，将客户端的 REDIS_MULTI 选项关闭，返回错误信息给客户端。

### 4.8.3 执行事务

事务状态时：遇到 【EXEC】、【DISCARD】、【MULTI】和【WATCH】 这四个命令不会进队列，直接被服务器执行。

- 【EXEC】：
  - 以先进先出的顺序执行事务队列中的命令，结果保存到【回复队列】中，返回给客户端。
  - 客户端返回到【非事务状态】。
- 【DISCARD】：
  - 清空事务队列，取消事务，返回OK。
  - 客户端返回到【非事务状态】。
- 【MULTI】：简单返回错误信息，事务继续。
- 【WATCH】：简单返回错误信息，事务继续。(watch只能在非事务状态执行)。

### 4.8.4 watch命令

WATCH 命令用于在事务开始之前监视任意数量的键。

- 在 redisDb 结构体中，保存了一个 watched_keys 字典，保存监视的key；字典的键是这个数据库被监视的key，而字典的值则是一个链表，保存了所有监视这个键的客户端。

- 这些被监视的key修改后，会执行回调函数，将监视的客户端 REDIS_DIRTY_CAS 选项打开。


当调用 EXEC 命令时，服务器会检查客户端的 REDIS_DIRTY_CAS 选项，如果已经打开，取消事务。

## 4.9 IO模型

Linux系统为了提高IO效率，会在【用户空间】和【内核空间】都加入缓冲区。

- 写数据时，要把【用户缓冲数据】拷贝到【内核缓冲区】，然后写入设备。
- 读数据时，要从设备读取数据到【内核缓冲区】，然后拷贝到【用户缓冲区】。

*IO过程：*

- 用户进程发起系统调用，CPU进入内核态，操作系统读取数据的过程可以分为两个阶段：
- 第一阶段等待数据准备完成，也就是【等待数据写到内核缓冲区】。
- 第二阶段将【内核缓冲区】数据拷贝到对应的【用户缓冲区】中。

### 4.9.1 阻塞IO

用户发起系统调用后，用户进程阻塞，操作系统【等待数据准备就绪】，然后【将数据拷贝到用户进程空间】，之后用户进程恢复运行。

### 4.9.2 非阻塞IO

用户发起系统调用后，操作系统检查数据是否准备完成(也就是数据是否写到了内核缓冲区)，如果没有准备完成，直接【返回异常】给用户进程；如果数据准备完成，用户进程进入阻塞，等待操作系统将数据复制到用户空间。

如果数据没有准备完成，用户进程通常需要不断循环发起系统调用直到数据准备完成。

### 4.9.3 IO多路复用

文件描述符（File Descriptor）：简称FD，是一个从 0 开始的无符号整数，用来关联Linux中的一个文件。在Linux中，一切皆文件，包括网络套接字（Socket）。

IO多路复用：是利用单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。

*过程：*

- 用户进程调用函数，指定要监听的多个socket以及对应事件，内核负责监听，任意一个或多个socket数据准备就绪则返回对应事件，此过程中用户进程阻塞。

- 用户进程找到就绪的socket，依次调用recvfrom，内核将数据拷贝到用户空间，用户进程处理数据。

*Linux系统中，IO多路复用有三种常见方式：*

- select
- poll
- epoll

#### select模式

*过程：*

- 用户进程【调用select()函数】，传入一个或多个1024比特位的数组，每一个比特位代表一个FD，指定【要监听事件以及对应的FD集合】，会将数组【拷贝到内核空间】。
- 内核监听FD集合，没有FD就绪则休眠，数据就绪则被唤醒。会将【1024比特位的数组】拷贝回用户空间，其中【指定了所有数据准备就绪的FD】，并【返回准备就绪的FD数量】。
- 用户判断n是否大于0，【遍历fd_set】，找到数据准备就绪的fd，【调用函数将数据复制到用户空间】，处理数据。

*问题：*

- fd_set监听的【fd数量】不能超过1024。
- 【每次调用select函数】都需要将整个fd_set从用户空间【拷贝】到内核空间，select结束还要再次拷贝回用户空间。
- select函数调用后，用户无法得知具体是哪个fd就绪，需要【遍历整个fd_set】。

<img src="D:/Typora/picture/image-20220528204629121.png" alt="image-20220528204629121" style="zoom:80%;" />

#### poll模式

poll模式对select模式做了简单改进，但性能提升不明显。

*过程：*

1. 【创建pollfd数组】，指定要监听的FD以及对应事件。

2. 【调用poll函数】，将pollfd数组拷贝到内核空间，转链表存储，数量无上限。

3. 内核【遍历fd】，判断是否就绪，如果数据准备就绪，修改pollfd中实际发生的事件类型；

   【数据就绪】或【等待时间超时】后，【拷贝pollfd数组】到用户空间，返回就绪fd数量n。(拷贝的是所有的fd)

4. 用户进程【判断n是否大于0】，如果大于0则遍历pollfd数组，找到就绪的fd。

*与select对比：*

- select模式中的fd_set大小固定为1024，而pollfd在内核中采用链表，理论上无上限。 
- 但是监听FD越多，每次遍历消耗时间也越久，性能反而会下降。
- poll模式很少使用。

<img src="D:/Typora/picture/image-20220528210056776.png" alt="image-20220528210056776" style="zoom:80%;" />



#### epoll模式

*过程：*

1. 调用`epoll_create()`函数，在【内核空间创建eventpoll】，eventpoll中包含两个数据结构，红黑树和链表。
2. 调用`epoll_ctl()`函数，将一个fd【添加到epoll的红黑树】中，并设置【回调函数】，触发事件时调用回调函数，将【对应的fd加入链表中】。
3. 调用`epoll_wait()`函数，判断链表中是否有数据，如果有，直接返回【fd数量】并拷贝【准备就绪的fd】；如果没有会进入睡眠，直到链表中有数据或者超时。

<img src="D:/Typora/picture/image-20220528211507429.png" alt="image-20220528211507429" style="zoom:80%;" />

#### 总结

*select模式存在的三个问题：*

- fd_set监听的【fd数量】不能超过1024。
- 【每次调用select函数】都需要将整个fd_set从用户空间【拷贝】到内核空间，select结束还要再次拷贝回用户空间。
- select函数调用后，用户无法得知具体是哪个fd就绪，需要【遍历整个fd_set】。

*poll模式的问题：*

- poll利用链表解决了select中监听FD上限的问题，但依然要遍历所有FD，如果监听较多，性能会下降。

*epoll模式中如何解决这些问题的？*

- 基于epoll实例中的【红黑树】保存要监听的FD，理论上【无上限】，而且增删改查【效率比较高】。
- 每个FD只需要执行一次epoll_ctl添加到红黑树，多次调用epoll_wait【无需重复拷贝FD】到内核空间。
- FD事件发生后会调用【回调函数】，将FD加入链表中，内核不用遍历所有FD判断事件是否准备就绪，【性能不会随监听fd数量增多而下降】。
- 内核会将【就绪的FD直接拷贝】到用户空间的指定位置，用户进程【无需遍历所有FD】就能知道就绪的FD有哪些。

#### 事件通知模式

当FD有数据可读时，我们调用epoll_wait（或者select、poll）可以得到通知。但是事件通知的模式有两种：

- LevelTriggered：简称LT。当FD中有数据可读时，会【重复通知多次】，直至数据处理完成。epoll默认模式。

- EdgeTriggered：简称ET。当FD中有数据可读时，不管数据是否处理完成，【只会通知一次】。

*对比：*

- LT：事件通知频率较高，会有重复通知，会【影响性能】；另外，可能会出现【惊群现象】。
- ET：仅通知一次，效率高，避免了LT可能出现的惊群现象，可以基于【手动将fd加入到就绪链表中】或者【非阻塞IO循环读取】解决数据读取不完整问题。

#### epoll-web服务

<img src="D:/Typora/picture/image-20220528213431451.png" alt="image-20220528213431451" style="zoom: 64%;" />

### 4.9.4 信号驱动IO

信号驱动IO是【与内核建立SIGIO的信号关联】并【设置信号回调函数】，当内核有FD就绪时，给用户递交SIGIO信号。

*过程：*

- 阶段一：

  - 用户进程调用sigaction()函数，注册【信号处理函数】，内核开始监听FD；
  
    这期间用户进程不用阻塞。
  
  - 当内核数据就绪后，将信号递交给用户进程。
  
- 阶段二：

  - 用户进程收到信号，执行回调函数，回调函数中可以发起系统调用，将数据从内核将数据拷贝到用户空间。

    

*缺点：*

- 当有大量IO操作时，信号较多，SIGIO处理函数不能及时处理可能导致【信号队列溢出】。
- 而且内核空间与用户空间的【频繁信号交互】性能也较低。

<img src="D:/Typora/picture/image-20220528213849801.png" alt="image-20220528213849801" style="zoom:80%;" />

### 4.9.5 异步IO

异步IO的整个过程都是非阻塞的，用户进程调用完异步API后就可以去做其它事情，内核等待数据就绪并拷贝到用户空间后才会递交信号，通知用户进程。

*过程：*

1. 用户进程调用aio_read，创建【信号回调函数】；内核负责等待数据就绪，并将数据拷贝到用户缓冲区。

   这期间用户进程无需阻塞

3. 数据拷贝到用户缓冲区后，内核递交信号触发【回调函数】对数据进行处理。

<img src="D:/Typora/picture/image-20220528214321076.png" alt="image-20220528214321076" style="zoom:80%;" />

*同步和异步：*

- IO操作是同步还是异步，关键看数据在【内核空间】与【用户空间】的拷贝过程（数据读写的IO操作），也就是阶段二是同步还是异步。

### 4.9.6 redis网络模型

Redis 6.0版本中引入了多线程，目的是为了【提高IO读写效率】。

- 由于性能瓶颈在于网络IO过程，所以在【读取客户端数据并解析客户端命令】、【写响应结果】时采用了多线程。
- 核心的【命令执行】、【IO多路复用和事件派发模块】依然是由主线程执行。

<img src="D:/Typora/picture/image-20220528223840228.png" alt="image-20220528223840228" style="zoom:64%;" />

源码：

<img src="D:/Typora/picture/image-20220528224246750.png" alt="image-20220528224246750" style="zoom:65%;" />

<img src="D:/Typora/picture/image-20220528224142515.png" alt="image-20220528224142515" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528224418215.png" alt="image-20220528224418215" style="zoom:80%;" />

<img src="D:/Typora/picture/image-20220528224449163.png" alt="image-20220528224449163" style="zoom:80%;" />

## 4.10 性能优化

### 4.10.1 bigkey

BigKey通常以Key的大小和Key中成员的数量来综合判定，例如：

- Key本身的【数据量过大】：一个String类型的Key，它的值为5 MB。
- Key中的【成员数过多】：一个ZSET类型的Key，它的成员数量为10,000个。
- Key中【成员的数据量过大】：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB。

推荐值：

- 单个key的value小于10KB
- 对于集合类型的key，建议元素数量小于1000

#### 危害

1. 【网络阻塞】：对BigKey执行读请求时，可能会占用大量的【宽带资源】，导致Redis实例，乃至所在物理机变慢。
2. 【Redis阻塞】：对元素较多的集合类型数据等做运算比较耗时，可能使【主线程被阻塞】。
3. 【CPU压力】：对BigKey的数据【序列化】和反序列化会导致CPU的使用率飙升，影响Redis实例和本机其它应用(写入redis和读取的时候要做序列化和反序列化)。
4. 【集群中数据倾斜】：BigKey所在的Redis实例【内存使用率】远超其他实例，无法使数据分片的内存资源达到均衡。


#### 如何发现bigkey

redis-cli --bigkeys

- 利用redis-cli提供的--bigkeys参数，可以遍历分析所有key，并返回Key的整体统计信息与每个数据的Top1的big key

第三方工具

- 利用第三方工具，如`Redis-Rdb-Tools`分析RDB快照文件，全面分析内存使用情况。

scan扫描

- 自己编程，利用scan扫描Redis中的所有key，利用strlen、hlen等命令判断key的长度（此处不建议使用MEMORY USAGE）

网络监控

- 自定义工具，监控进出Redis的网络数据，超出预警值时主动告警

#### 如何删除BigKey

- Redis 4.0 之前，如果是集合类型，则遍历BigKey的元素，先逐个删除子元素，最后删除BigKey。

- Redis 4.0 以后，Redis在4.0后提供了异步删除的命令：unlink。

### 4.11.2 String占用内存过多

举例：`set 1101000051 3301000051`插入一个String类型，会占用64字节内存。

- 存储的字符串是整数值，并且大小在LONG_MAX范围内，则会采用 INT 编码，内存占用如下：

<img src="D:/Typora/picture/image-20220529210045686.png" alt="image-20220529210045686" style="zoom: 50%;" />

解决：使用压缩列表。

- 调整Hash结构相关的两个阈值：
  - hash-max-ziplist-entries：最大元素个数。（默认512）
  - hash-max-ziplist-value：单个元素的最大长度。（默认64字节）
- 当元素数量和单个元素大小都不超过阈值时，使用ZipList编码；否则，使用 HT（Dict）编码。

### 4.12.3 大量key同时过期

1. 给 key 设置随机过期时间。
2. 开启 lazy-free（惰性删除/延迟释放）。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

### 4.12.4 批处理

一条命令执行时间 = 1次往返的网络传输耗时 + 1次Redis执行命令耗时，其中网络传输时间通常是【毫秒】级别，redis执行命令时间一般是【微秒】级别。

如果有大量命令一条一条的执行，网络传输会占用大量时间。

批处理：一次将大量命令传送到服务端，避免了多次网络传输。

#### mxxx 命令

使用redis的命令一次插入大量数据，例如：

- mset
- hmset

注意：不要一次插入太多数据，否则占用大量网络带宽，导致网络阻塞。

redis原生命令具有原子性。

局限性：要使用redis原生命令，只能在一个key中插入大量数据时使用。

#### pipeline

可以一次将大量命令加入到pipeline中，通过网络一次传送到服务端。

注意：Pipeline的多个命令之间不具备原子性

<img src="D:/Typora/picture/image-20220529215855973.png" alt="image-20220529215855973" style="zoom:80%;" />

# 5. JVM

## 5.1 概念

### 5.1.1 定义

`Java Virtual Machine`，JAVA程序的【运行环境】（JAVA二进制字节码的运行环境）

### 5.1.2 好处

- 一次编写，到处运行。
- 自动内存管理，垃圾回收机制。
- 数组下标越界检查。

### 5.1.3 JVM JRE JDK的区别

<img src="D:/Typora/picture/20200608150422.png" alt="img" style="zoom: 50%;" />

## 5.2 内存结构

### 5.2.1 程序计数器

*程序计数器主要有两个作用：*

- 【字节码解释器】通过改变【程序计数器】来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
- 在多线程的情况下，线程切换时，程序计数器用于记录当前线程执行的位置。

*特点：*

- 线程私有
- 不会存在内存溢出

### 5.2.2 虚拟机栈

每个【线程运行】需要的内存空间，称为【虚拟机栈】，是【线程私有】的。

每个栈由多个【栈帧】组成，栈帧对应着每次调用方法时所占用的内存。

每个栈帧中都拥有：【局部变量表】、【操作数栈】、【动态链接】、【方法返回地址】。

Java 方法有两种返回方式，一种是 return 语句【正常返回】，一种是【抛出异常】。两种返回都会导致栈帧弹出。

#### 局部变量表 

主要用于存放局部变量。

#### 操作数栈 

用于存放方法执行过程中产生的【中间计算结果】，以及计算过程中产生的【临时变量】。

#### 动态链接 

每一个栈帧内部都包含一个指向【运行时常量池中该栈帧所属方法】的引用。包含这个引用的目的就是为了支持当前方法的代码能够实现【动态链接】。比如动态调用指令：invokedynamic。

所有的【变量】和【方法引用】都作为【符号引用】保存在 Class 文件的常量池里。

描述一个方法调用时，就是通过常量池中指向该方法的【符号引用】来表示的，【动态链接】的作用：为了将调用方法的【符号引用】转换为【直接引用】。

#### 两种错误

- StackOverFlowError： 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出。
- OutOfMemoryError： 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出。

#### 线程运行诊断

案例1：CPU占用过高

- Linux环境下运行某些程序的时候，可能导致CPU的占用过高，这时需要定位占用CPU过高的线程

  1. `top`命令，查看哪个【进程】占用CPU过高

  2. `ps H -eo pid, tid（线程id）, %cpu | grep 进程id` ：通过【进程id】，ps命令查看哪个【线程】占用CPU过高。

  3. `jstack 进程id` ：可以根据进程 id 找到有问题的线程，进一步定位到问题代码的源码行数

案例2：检查死锁

- `jstack 进程id`命令可以看到。

### 5.2.3 本地方法栈

本地方法执行时使用的内存空间叫本地方法栈。JAVA有时候没法直接和操作系统底层交互，需要用到本地方法。

比如：一些带有【native关键字】的方法就是需要JAVA去调用本地的C或者C++方法。

也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。

### 5.2.4 堆

Java 虚拟机所管理的内存中【最大】的一块，唯一目的就是【存放对象实例】，通过【new关键字】创建的对象都会被放在堆内存。

堆内存在【虚拟机启动时创建】，【所有线程共享】，有【线程安全】问题，有【垃圾回收机制】。

JDK 1.7 开始默认开启【逃逸分析】，如果某些方法中的对象不会逃逸出这个方法，对象可以直接在栈上分配内存。



JDK 8以前，堆内存通常分为三部分：

1. 新生代(Young Generation)
2. 老生代(Old Generation)
3. 永久代(Permanent Generation)

JDK 8 版本之后 PermGen(永久) 已被【Metaspace(元空间)】取代，元空间使用的是【直接内存】



堆内存溢出问题

- `java.lang.OutofMemoryError ：java heap space`：堆内存溢出。

#### 堆内存诊断

- `jps`命令
  - 查看当前系统中有哪些 java 进程 。
- `jamp -heap 进程id` 
  - 查看某一时刻一个Java进程中堆内存占用情况。
- `jconsole`命令
  - 图形界面的，多功能的监测工具，可以进行连续监测，除了检测堆内存使用情况，还能看到CPU使用率，线程等情况，也能检测死锁情况。
- `jvisualvm`命令
  - 可视化的虚拟机，图形化界面，可以查看堆中具体的对象信息，也可以查看线程，CPU使用率等信息。

### 5.2.5 方法区

方法区在【虚拟机被启动时创建】，是所有【线程共享】的内存区域，jvm内部会保证方法区的线程安全。

当虚拟机要使用一个类时，它需要读取并解析【Class文件】获取相关信息，再将信息存入到方法区。

方法区会存储已被虚拟机加载的【类信息】、【字段信息】、【方法信息】、【常量池】、即时编译器编译后的【代码缓存】等数据。

#### 结构

JVM1.6：永久代实现，使用的是堆内存。

JVM1.8：元空间实现，使用的是直接内存。String Table在堆中。

对比：

- 永久代：
  - 类和方法信息难以确定，不容易指定永久代大小，太小容易导致永久代溢出，太大容易导致老年代溢出。
  - 在永久代GC效率低。
- 元空间：
  - 元空间使用的是直接内存，内存溢出概率比较小。

#### 参数设置

永久代和元空间都可以设置【方法区初始大小】和【方法区最大大小】。

元空间默认使用【系统内存】，且不会设置内存的上限，所以我们要手动设置。

### 5.2.6 运行时常量池

常量池表：

- Class 文件中包含 【常量池表】
- 虚拟机指令根据这张常量表找到要执行的【类名】、【方法名】、【参数类型】、【字面量信息】。

运行时常量池：

- 【常量池表】会在类加载阶段存放到方法区的【运行时常量池】中

- 受到方法区内存的限制，无法再申请到内存时会抛出 OutOfMemoryError 错误。


### 5.2.7 字符串常量池

专门存放字符串的一块区域，主要是为了避免字符串的重复创建，可以【提升性能】和【减少内存消耗】。

#### 存放位置：

- JDK1.7 之前，【字符串常量池】存放在【永久代】。
- JDK1.7 【字符串常量池】和【静态变量】存放在【堆】中。

*JDK 1.7 为什么将字符串常量池移动到堆中：*

- 主要是因为永久代的 GC 回收效率太低，只有在 Full GC 的时候才会被执行 GC。
- Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时执行垃圾回收。

#### StringTable调优

因为StringTable是由HashTable实现的，所以可以适当【增加HashTable桶的个数】，来减少字符串放入串池所需要的时间

- -XX:StringTableSize=xxxx

考虑是否需要将字符串对象入池

- intern方法

#### intern方法

JDK1.8：

- 如果串池中没有该字符串对象，则将这个对象【移动到串池】中，返回这个对象。
- 如果有，则放入失败，返回串池中对象。
- 如果成功，是同一个对象，如果失败，则不是同一个对象。

JDK1.6：

- 如果串池中没有该字符串对象，会将这个对象【复制一份放入到串池】中，返回串池中对象。
- 如果有，则放入失败，返回串池中对象。
- 无论成功与否，都【不是同一个对象】

### 5.2.8 直接内存

`Direct Memory` ：是操作系统内存。

- 常见于`NIO`操作时，用于数据缓冲区。
- 直接内存是【操作系统】和【Java代码】都可以访问的一块区域，无需将数据从系统内存复制到Java堆内存，从而提高了IO效率。
- 分配回收【成本较高】，但读写【性能高】，不受 JVM 内存回收管理。

#### 释放原理

直接内存的回收不是通过JVM的垃圾回收来释放的，底层通过【Unsafe类】来完成直接内存的【分配】和【回收】

- 分配直接内存：`unsafe.allocateMemory()`方法。返回【内存地址】long类型。
- 回收直接内存：`unsafe.freeMemory()`方法。方法参数值为【内存地址】。

回收过程：

- ByteBuffer的实现内部使用了Cleaner（虚引用）来检测ByteBuffer。
- 一旦ByteBuffer被垃圾回收，虚引用进入引用队列，后面会调用虚引用的clean()方法，释放直接内存。

## 5.3 Java对象

### 5.3.1 对象创建

#### 1.类加载检查

虚拟机遇到一条 new 指令时，首先检查能否在【常量池】中定位到这个类的【符号引用】。

并且检查这个【符号引用】代表的【类】是否已被【加载】、【解析】和【初始化】。

如果没有，那必须先执行相应的类加载过程。

#### 2.分配内存

【类加载完成后】就可以确定对象所需内存大小，分配内存就是在【Java堆】中划分出一块内存。

分配方式有 【指针碰撞】 和 【空闲列表】 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。



*内存分配的两种方式：*

- 指针碰撞 ：
  - 适用场合 ：堆内存规整（没有内存碎片）的情况下。
  - 原理 ：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个【分界指针】，在分界指针处分配一块内存，并将分界指针右移即可。
  - 使用该分配方式的 GC 收集器：Serial, ParNew
- 空闲列表 ：
  - 适用场合：堆内存不规整的情况下。
  - 原理：虚拟机会维护一个列表，记录了【可用的内存块】，分配内存时，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。
  - 使用该分配方式的 GC 收集器：CMS

*内存分配线程安全问题：*

堆内存是所有线程共享的，创建对象需要考虑线程安全问题，通常来讲，虚拟机采用两种方式来保证线程安全：

- CAS+失败重试：不加锁而是【假设没有冲突】而去完成操作，如果因为冲突失败就重试，直到成功为止。
- TLAB 线程本地分配缓存：为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，TLAB内存不够时，再采用上述的 CAS 进行内存分配。

#### 3.初始化零值

内存分配完成后，将除了对象头之外的部分初始化为零值。

保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，默认就是0值。

#### 4.设置对象头

普通对象的对象头结构包括：

1. Mark Word：对象信息【哈希码】【分代年龄4位，最大15】【锁信息1+2】
2. Klass Word：指针，指向对应的Class对象
3. 如果对象是数组：还有【array length数组长度】

#### 5.执行 init 方法

执行init方法初始化对象，init方法是将【成员变量赋值操作】、【实例代码块】和【构造方法】中代码结合产生的一个方法。

### 5.3.2 对象的内存布局

在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：【对象头】、【实例数据】和【对齐填充】。

【对齐填充】部分仅仅起占位作用。 虚拟机的自动内存管理系统要求【对象起始地址必须是8字节的整数倍】。

### 5.3.3 对象的访问定位

建立对象就是为了使用对象，我们的 Java 程序通过栈上的 【引用 reference】来操作堆上的具体对象。

对象的访问方式由虚拟机实现而定，目前主流的访问方式有：【使用句柄】、【直接指针】

#### 句柄

堆中将会划分出一块内存来作为【句柄池】，【句柄】中包含了【对象实例数据】与【对象类型数据】的地址。

【引用 reference】中存储的就是【对象的句柄地址】。

<img src="D:/Typora/picture/image-20220530190841235.png" alt="image-20220530190841235" style="zoom:80%;" />

#### 直接指针

【引用 reference】中存储的直接就是对象的地址，对象中存储着【对象类型数据】的地址。

<img src="D:/Typora/picture/image-20220530190904875.png" alt="image-20220530190904875" style="zoom:80%;" />

#### 对比

- 使用【句柄】来访问的最大好处是【引用】中存储的是【稳定的句柄地址】，在对象被移动时只会改变句柄中的实例数据指针,而【引用】本身不需要修改。
- 使用【直接指针】访问方式最大的好处就是【速度快】，它节省了一次指针定位的时间开销。

## 5.4 垃圾回收

### 5.4.1 判断对象可回收

#### 引用计数法

- 对象被引用的次数作为对象的引用计数：当对象的引用次数为 0 时，可以被垃圾回收机制回收。 

- 弊端：循环引用情况，内存得不到释放。

- java不会使用。

#### 可达性分析

JVM中的【垃圾回收器】通过【可达性分析】来探索所有存活的对象。

原理：扫描堆中的对象，看能否沿着【GC Root对象】为起点的引用链找到该对象，如果找不到，则表示可以回收。

可以作为GC Root的对象：

- System Class：由【启动类加载器】加载的系统类，核心类对象。
- Native Stack：java 虚拟机【调用本地方法】时引用的【java 对象】。
- Busy Monitor：正在【加锁】的对象。
- Thread：当前【活动线程】中局部变量引用的对象。
- 方法区中类的【静态属性】和【常量】引用的对象。

对象可以被回收，就代表一定会被回收吗？

- 如果对象重写了finalize()方法，可达性分析标记为不可达对象后，不会立即回收，而是放入引用队列中，后台线程扫描引用队列中对象，执行finalize()方法后才会回收。

#### 判断可回收的类

同时满足下面 3 个条件：

- 该类【所有的实例】都已经被回收，也就是 Java 堆中不存在该类的任何实例。
- 加载该类的【ClassLoader】已经被回收。
- 该类对应的【java.lang.Class 对象】没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

满足这些条件代表“被允许”回收，不一定会被回收，要看其他参数配置。

### 5.4.2 四种引用

#### 强引用

最常见的使用【引用变量】指向一个对象，就是强引用。

【GC ROOT对象】通过强引用链能到达的对象，都不会被回收。


#### 软引用

只被【软引用】指向的对象，在垃圾回收后，如果内存仍然不足，才会被回收掉。

如果要回收【软引用】对象本身，需要配合使用【引用队列】。

#### 弱引用

只被【弱引用】指向的对象，在垃圾回收时，无论内存是否充足，都会被回收。

如果要回收【弱引用】对象本身，需要配合使用【引用队列】。

#### 虚引用

必须配合引用队列使用。

当【虚引用对象】所【引用的对象】被回收以后，虚引用对象就会被【放入引用队列】中，后台线程处理引用队列时，调用【虚引用的方法】。

虚引用的一个体现是释放直接内存所分配的内存：

- 当虚引用引用的对象ByteBuffer被垃圾回收以后，【虚引用对象】就会被放入【引用队列】中。
- 然后调用【虚引用对象】的clean()方法来释放直接内存。

#### 终结器引用

- Object类的finalize方法。
- 确认这个对象可回收时，会先将该对象放入引用队列中，后台线程处理引用队列时，调用该对象的finalize方法。调用以后，该对象才会被垃圾回收。
- 处理引用队列线程优先度很低，对象可能长时间得不到销毁，不推荐使用。

#### 引用队列

- 软引用和弱引用【可以配合】引用队列
  - 在【软引用】和【弱引用】所引用的对象被回收以后，会将这些引用放入引用队列中，方便一起回收这些软/弱引用对象。
- 虚引用和终结器引用【必须配合】引用队列
  - 虚引用和终结器引用在使用时会关联一个引用队列

### 5.4.3 垃圾回收算法

#### 标记清除算法

分两步执行：

- 先采用【标记算法】确定可回收对象
- 然后垃圾收集器根据标识【清除相应的内容】，只是记录这段内存的起始地址，下次分配对象会直接覆盖。

优点：速度快

缺点：容易产生大量的内存碎片，一旦导致无法分配对象，那就会导致jvm启动gc，应用程序会暂停，导致应用的响应速度变慢。

#### 标记整理算法

执行过程：

- 先采用【标记算法】确定可回收对象。
- 然后【整理】剩余的对象，让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。

优点：避免【内存碎片问题】。

缺点：整理需要耗时，效率较低

#### 复制算法

将内存分为两块相同的区域：From和To，To区域空闲。

垃圾回收步骤：

- 垃圾回收时，将From中存活的对象复制到To区域中，并在复制过程中进行整理。
- 清空From区，然后交换From和To。

优点：不会产生内存碎片，执行效率比【标记整理算法】高。

缺点：占用双倍的内存空间

#### 分代回收算法

*分代建立在两个分代假说之上：*

- 弱分代假说：绝大多说对象都是朝生夕死的。
- 强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡。

*原理：*

- 将堆内存分为【新生代】和【老年代】两部分。
- 新建对象分配在【新生代】中，每次垃圾回收后存活下来的对象，寿命+1，寿命到达阈值后晋升到【老年代】中。
- 如果新生代满了，会触发minorGC；如果新生代和老年代都满了，会触发full GC。

*可以根据各个年代的特点选择合适的垃圾收集算法：*

- 在新生代中，每次收集都会有大量对象死去，可以选择【复制算法】，只需要复制少量存活对象，并且浪费内存也是比较少的。
- 老年代的对象存活几率是比较高的，复制算法会浪费大量内存，一般选择【标记-清除】或【标记-整理】算法。

*相关VM参数：*

<img src="D:/Typora/picture/image-20220215131319054.png" alt="image-20220215131319054" style="zoom:80%;" />

### 5.4.4 垃圾回收器

#### 1. Serial 收集器

最基本的、发展历史最悠久的收集器。

负责【新生代】垃圾回收，采用【复制】算法，是【单线程】工作的收集器，且垃圾回收时【暂停所有工作线程】。

优点：简单而高效。

- 对于内存资源受限的环境，serial收集器是所有收集器中【内存消耗最小】的。
- 对于单核处理器或处理器核心数较少的环境，serial收集器由于没有线程交互的开销，可以获得【最高的单线程收集效率】。

#### 2. ParNew 收集器

Serial 收集器的多线程版本，除了使用【多线程】，其余行为和 Serial 收集器完全一样。

负责【新生代】垃圾回收，采用【复制】算法，使用【多线程】进行垃圾收集，垃圾回收时也会【暂停所有工作线程】。

可以配合CMS收集器一起使用，【CMS收集器】激活后，默认的新生代收集器就是ParNew收集器。

#### 3. Parallel Scavenge收集器

负责【新生代】垃圾回收，采用【复制】算法，可以【多线程】并发收集。

目标是达到一个【可控制的吞吐量】，可以开启【GC自适应调节】策略。

吞吐量：

- 【处理器用于运行用户代码的时间】与【处理器消耗总时间】的比值。

GC的自适应调节策略：

- 虚拟机会根据系统的运行状况【收集性能监控信息】，动态设置【新生代大小】、【伊甸园占比】、【晋升老年代年龄】等参数
- 以提供【最优的停顿时间】和【最高的吞吐量】

#### 4. serial Old 收集器

serial收集器的老年代版本。采用【标记-整理】算法，【单线程】收集器。

在CMS收集器并发收集失败后，开启的备用方案。

#### 5. Parallel Old 收集器

Parallel Scavenge 收集器的老年代版本，采用【标记-整理】算法，可以【多线程】并发收集。

在注重【吞吐量】以及【CPU 资源】的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。

#### 6. CMS 收集器

老年代收集器，目标是获取【最短停顿时间】，基于【标记-清除】算法，基本实现了【垃圾收集线程】与【用户线程】并发执行。

整个过程分为4步：

- 【初始标记】：只是标记GC Roots直接相连的对象，【暂停所有用户线程】，速度很快。
- 【并发标记】：进行可达性分析，找出存活对象，【可以和用户线程并发执行】。
- 【重新标记】：修正并发标记期间因【用户程序继续运行】而导致【标记产生变动】的那一部分对象的标记记录。【暂停所有用户线程】。
- 【并发清除】：对标记的对象进行清除回收，【可以和用户线程并发执行】。

应用场景：

- 适用于注重服务的【响应速度】，希望系统停顿时间最短，给用户带来更好的体验等场景下。如web程序、b/s服务

优点：

- 并发收集、低停顿。

缺点：

- 对【CPU 资源敏感】。
- 无法处理【浮动垃圾】。
- 采用【标记-清除】算法，会产生内存碎片。

### 5.4.5 Garbage First 收集器

JDK 9以后默认使用，取代了CMS 收集器，把连续的Java堆划分为多个大小相等的【独立区域(region)】。

每个region都可以根据需要，扮演新生代的【伊甸园区Eden】，【幸存区Survivor】，或者【老年代】；还有一类【Humongous区域】，用来存放大对象。

整体上是【标记-整理】算法【避免内存碎片问题】，两个区域之间是【复制】算法。

G1 除了【追求低停顿】外，还能建立【可预测的停顿时间模型】；G1 收集器在后台维护了一个【优先列表】，每次根据允许的收集时间，优先选择回收价值最大的 Region，保证了 G1 收集器在【有限时间内】可以【尽可能高的收集效率】。

#### 1. Young GC

当年轻代的【Eden区用尽】时开始【年轻代回收】过程；Young GC 在所有环节都存在，会回收【伊甸园区】和【幸存区】。

年轻代收集阶段是一个【并行(多个垃圾线程)】的【独占式】收集器，会触发【STW】。

- 【伊甸园区】幸存的对象复制到【幸存区】。
- 【幸存区】中对象到年龄的晋升【老年代】，其他的复制到【幸存区】。

#### 2. Young GC + 并发标记

在 Young GC 时会执行【初始标记】：找到GCRoot对象

在老年代占用【堆内存的比例】达到阈值时(默认45%)，进行并发标记：从GC Root对象出发，找到其他对象。

#### 3. 混合回收

会对【伊甸园区】、【幸存区】、【老年区】进行全面的回收

- 最终标记：会STW，并发标记阶段可能产生新的垃圾。
- 筛选回收：会STW，优先回收最有价值的Region。

-XX:MaxGCPauseMills:xxx 用于【指定最长的停顿时间】。

不是所有老年代都会拷贝。

- 因为指定了【最大停顿时间】，为了保证时间不超过设定的停顿时间，会【回收最有价值的老年代】。

#### 4. 后备FullGC

FullGC是【单线程】,【独占式】的垃圾回收过程,在开发和调优的过程中要尽量【避免FullGC】的出现。

FullGC的出现有两种情况:

1. G1的回收都是基于【复制算法】的,将一个region复制到另外空闲的region,如果没有空闲的region的时候,就会进行FullGC。
   1. 当【堆内存过小】的时候可能出现这个问题
   2. 当【停顿时间设置的过小】,而堆内存占用速度又过快的时候可能出现这个问题
2. G1是存在【并发标记】阶段的,在这个阶段【用户线程】和【垃圾回收线程】交替执行,如果用户线程在这个时候没有足够的内存使用,就会触发FullGC。

#### 跨代引用问题

【新生代回收】时的【跨代引用问题】（老年代对象引用新生代）；老年代对象较多，如果遍历整个老年代，效率较低。

- 【卡表】方式，将老年代的区域进行细分，分成多个card，如果老年代中某一个card引用了新生代对象，就将该card标记为【脏卡】。
- 新生代【Remembered Set】中记录【老年代脏卡】的地址，只需要到脏卡中找，不用遍历整个老年代。

#### 重新标记

*在垃圾回收时，收集器处理对象的过程中，会标记对象的状态：*

- 黑色：表示已经被垃圾回收器访问过，并且所有引用都已经扫描过，黑色对象不可能直接指向白色对象。
- 灰色：表示对象已经被垃圾回收器访问过，其中的引用还有的没有被访问过。
- 白色：表示对象尚未被垃圾回收器访问过。

*对象消失问题需要满足两个条件：*

- 赋值器插入了一条或多条从黑色对象到白色对象的新引用。
- 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。

*两种解决方法：*

- 【增量更新】
- 【原始快照(SATB)】

- 无论是对引用关系记录的插入还是删除，虚拟机的记录操作都是通过【写屏障】实现的。
- CMS 是基于【增量更新】的；G1是使用的【原始快照】来实现的。

#### 优化建议

1. 不要显式设置年轻代大小，否则年轻代的大小就被固定,不能由G1动态调节,【期望最大暂停时间参数】被覆盖。
2. 暂停时间目标的设置不要太小,会影响到吞吐量

### 5.4.6 垃圾回收调优

## 5.5 类加载和字节码技术

### 5.5.1 字节码文件结构

【魔术】，【版本】，【常量池信息】，【类信息】，【父类和接口信息】，【成员变量】和【静态变量】，【方法】和【构造方法】。

```java
u4 			   magic	//魔术，文件类型
u2             minor_version;    //版本
u2             major_version;    //版本

u2             constant_pool_count;   //常量池信息 
cp_info        constant_pool[constant_pool_count-1];    //常量池具体信息

u2             access_flags;    //类的访问修饰
u2             this_class;    	//类的全限定类名

u2             super_class;   	//父类的全限定类名
u2             interfaces_count;    //接口数量
u2             interfaces[interfaces_count];   

u2             fields_count;    //成员变量、静态变量数量
field_info     fields[fields_count];   

u2             methods_count;    //方法数量
method_info    methods[methods_count];    

u2             attributes_count;    //构造方法数量
attribute_info attributes[attributes_count];
```

### 5.5.2 字节码指令

#### i++ 和 ++i

i++：先将【局部变量表】数据压入【操作数栈】，再将【局部变量表】数据+1。

++i：先将【局部变量表】数据+1，在压入【操作数栈】。

#### 条件判断

goto指令： 用来进行跳转到指定行号的字节码。

#### 构造方法

类加载：

- 编译器会按【从上至下】的顺序，收集所有 【static 静态代码块】和【静态成员赋值】的代码，合并为一个特殊的方法 clinit()V 。
- clinit()V 方法在类加载时被调用。

new 对象：

- 编译器会按【从上至下】的顺序，收集所有 【实例代码块】和【成员变量】赋值的代码，形成新的构造方法。
- 但【原始构造方法】内的代码总是【在最后】。

#### 方法调用

不同方法在调用时，对应的虚拟机指令有所区别。

- 【私有】、【构造】、【被final修饰的方法】，在调用时都使用【invokespecial指令】【静态绑定】。
- 【普通成员方法】在调用时，使用【invokevirtual指令】【动态绑定】。编译期间无法确定该方法的内容，运行期间才能确定。
- 【静态方法】在调用时使用【invokestatic指令】【静态绑定】。

静态绑定的性能相对高一些，invokevirtual指令需要查找多次才能确定方法的地址。



字节码指令中可以看出，【成员方法调用】要【将对象压入操作数栈】，静态方法调用不需要对象。

#### new 创建对象

- 首先给对象分配堆内存，执行成功会将【堆内存引用】压入操作数栈。
- dup ：复制操作数栈栈顶的内容。
- 一个是要配合 invokespecial 调用该对象的构造方法 “init”:()V （会消耗掉栈顶一个引用）。
- 另一个要配合 astore_1 赋值给局部变量。

#### 多态调用

【普通成员方法】需要在【运行时才能确定】执行哪个方法，所以虚拟机需要调用【invokevirtual指令】。

可以使用 HSDB 工具查看内存中对象信息。

执行【invokevirtual指令】过程：

- 先通过【操作数栈】栈顶的【对象引用】找到对象。
- 分析对象头，找到对象实际的Class。
- 查询Class结构中的【vtable(虚方法表)】。
  - 虚方法表中有【成员方法的地址】，而没有静态方法，final方法，私有方法。
  - 地址可能指向自身class中的方法，也可能指向某个父类class中的方法，取决于哪里重写了这个方法。
  - 类的加载【链接阶段】生成的虚方法表。
- 查询vtable找到方法的具体地址。
- 执行方法的字节码。

#### 异常处理

try{}catch(){}语句。

异常表：Exception table 。

- [from, to) 是【前闭后开】的检测范围，
- 这个范围内的字节码执行出现异常时，通过 type 匹配异常类型，如果一致，进入 target 所指示行号。
- 跳到target后，将异常对象地址赋给局部变量表。

多个catch块存在时:

- 异常表中有多条 【type】【匹配异常类型】，监控同一块代码区域，跳转的target不同。
- 异常出现时，只能进入 Exception table 中【一个分支】，所以局部变量表【slot 2 位置被共用】。

#### finally块

可以看到 ﬁnally 中的代码被【复制了 3 份】，分别放入 【try 流程】，【catch 流程】以及【catch剩余的异常类型流程】

保证了final中代码在正常执行，或出现任何异常时都能执行。

发生其他异常时，最后会有athrow指令抛出异常。

#### Synchronized

【synchronized (lock)】锁住对象时，将对象引用加载到操作数栈，复制，一份用来加锁，一份存入了局部变量表（用来解锁）。

配合异常表，【没有异常时】和【有任意异常发生】时，都会拿出局部变量表中对象引用，解锁。

### 5.5.3 编译器处理

【java 编译器】把 【java 源码】编译为 【class 字节码】的过程中，【自动生成】和【转换】的一些代码，减轻程序员的负担。

#### 默认构造器

调用父类的构造方法。	

#### 自动拆装箱

【基本类型】和其【包装类型】的相互转换过程，称为拆装箱。

在JDK 5以后，它们的转换可以在编译期自动完成。

#### 泛型擦除

JDK 5 开始加入的特性

- java 在【编译期】会执行【泛型擦除】的动作，泛型信息不会保存在字节码文件中，实际的类型都当做了 Object 类型来处理。

- get()函数取值时，有一个类型转换的操作。


#### 可变参数

实际上， 【String… args】 其实是一个 【String[] args】 ，java 编译器会在编译期间进行转换。

未传递参数时，等价代码为传递一个长度为0的数组，而不是null。

#### foreach循环

foreach循环数组，编译器转换成for按下标循环。

foreach循环集合，使用迭代器。【必须实现Iterable接口】。

#### swich 字符串

在编译期间，单个的switch被分为了两个，创建一个int变量x。

- 第一个用来匹配字符串，并给x赋值
  - 字符串的匹配用到了字符串的hashCode，还用到了equals方法。
  - 使用hashCode是为了提高比较效率，使用equals是为了应对hashCode冲突。
- 第二个用来根据x的值来决定输出语句

#### 枚举类

枚举类型两个【静态变量】，【String name】和【int ordinal】。还有一个枚举类型的数组，保存所有枚举值。

name为枚举值，ordinal为标号从0开始。【静态代码块构建】

#### try-with-resources

JDK 7 开始新增了对需要关闭的资源处理的特殊语法。

- 【资源对象】需要实现 【AutoCloseable 接口】 。

- 编译器会帮助生成 finally 语句块关闭资源代码。


#### 方法重写桥梁

方法重写时，子类返回值可以是父类返回值的子类。

其中桥接方法比较特殊，仅对 java 虚拟机可见，反射可以看到。

#### 匿名内部类

匿名内部类：会额外生成一个final的类。

如果匿名内部类中，引用的局部变量【必须用final修饰，会自动加上final，保证数据一致性】，局部变量就是新生成的类中的成员方法，生成有参的构造器。

### 5.5.4 类加载阶段

#### 1.加载

*过程：*

1. 通过【全类名】获取定义此类的【二进制字节流】。
2. 将字节流所代表的【静态存储结构】转换为方法区的【运行时数据结构】。
3. 在【堆内存】中生成一个代表该类的 【Class 对象】，作为方法区中数据的访问入口。

*方法区中保存的是【C++ 的 instanceKlass】，主要属性：*

- 【_java_mirror】指向堆中的class对象，class对象的对象头中也保存了instanceKlass的地址。
- 【_super】 即父类
- 【_ﬁelds】即成员变量
- 【_methods】即方法
- 【_constants】 即常量池
- 【_class_loader】即类加载器
- 【_vtable】虚方法表
- 【_itable】接口方法

如果这个类还有父类没有加载，【先加载父类】。

加载和链接可能是交替运行的。

<img src="D:/Typora/picture/image-20220216112251060.png" alt="image-20220216112251060" style="zoom: 67%;" />

#### 2.连接

##### 验证

验证字节码是否符合 JVM 规范，安全性检查。

##### 准备

为【堆内存】中的【class对象】中的【静态变量】分配空间，设置默认值。

- static变量在JDK 7以前是存储与instanceKlass末尾。但在JDK 7以后就存储在_java_mirror末尾了。
- static变量分配空间在【准备】阶段完成，赋值在【初始化】阶段完成。
- 如果 static 变量是 【ﬁnal 的基本类型】，以及【字符串常量】，那么编译阶段值就确定了，赋值在【准备】阶段完成。

##### 解析

解析阶段是虚拟机将【常量池】内的【符号引用】替换为【直接引用】的过程，也就是得到【类】或者【字段】、【方法】在内存中的【指针或者偏移量】。

#### 3.初始化

初始化阶段是执行【\<clinit>()方法】的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。

虚拟机会保证这个类的【构造方法】的线程安全。

- 【clinit()方法】是由编译器自动收集类中的所有【静态变量的赋值动作】和【静态代码块】中的语句合并产生的。
- 作用：给静态变量赋值。

- 如果没有对应的赋值动作和静态语句块，就不会提炼出的clinit()方法。

##### 初始化时机

类的初始化是懒惰的，初始化的时机：

- main 方法所在的类，总会被首先初始化。
- 首次访问这个类的静态变量或静态方法时。
- 子类初始化，如果父类还没初始化时，会引发父类初始化。
- 子类访问父类的静态变量，只会触发父类的初始化。
- Class.forName()方法。
- new 会导致初始化。

以下情况不会初始化

- 访问类的 static ﬁnal 静态常量（基本类型和字符串）。
- 类对象.class 不会触发初始化【类加载时就会产生_java_mirror 对象】。
- 创建该类对象的数组。
- 类加载器的.loadClass()方法。
- Class.forNam()的参数2为false时。

### 5.5.5 类加载器

“通过一个类的【全限定类名】来获取描述该类的【二进制字节流】” 这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。

实现这个动作的代码被称为【类加载器】（ClassLoader）

对于任意一个类，都必须由加载它的【类加载器】和这个【类本身】一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。

不同的类加载器，如果加载同一个Class文件，会加载两个class对象，【相互隔离，不会产生冲突】。

#### 类加载器分类

| 名称                                      | 加载的类                                | 说明                        |
| :---------------------------------------- | --------------------------------------- | :-------------------------- |
| Bootstrap ClassLoader（启动类加载器）     | JAVA_HOME/jre/lib 目录下的jar包和类     | 无法直接访问(c++代码实现)   |
| Extension ClassLoader(拓展类加载器)       | JAVA_HOME/jre/lib/ext 目录下的jar包和类 | 上级为Bootstrap，显示为null |
| Application ClassLoader(应用程序类加载器) | 当前应用 classpath 下的所有 jar 包和类  | 上级为Extension             |
| 自定义类加载器                            | 自定义                                  | 上级为Application           |

#### 双亲委派模型

类加载会调用 ClassLoader 类的 loadClass() 方法，双亲委派机制就是在这个方法中实现的。具体过程为：

1. 首先判断这个类是否被【当前类加载器】加载过，如果加载过，直接返回。
2. 如果当前类加载器没有加载过，则委托【父类加载器】处理，也就是调用父类加载器的 loadClass() 方法，因此所有的请求最终都应该传送到顶层的【启动类加载器】中。
3. 当父类加载器加载失败时，才由自己来加载，调用 findClass() 方法。


```java
protected Class<?> loadClass(String name, boolean resolve)
    throws ClassNotFoundException{
    
    synchronized (getClassLoadingLock(name)) {
        
        Class<?> c = findLoadedClass(name);// 1.首先查找该类是否已经被该类加载器加载过了
        if (c == null) {//如果没有被加载过
            long t0 = System.nanoTime();
            try {
                if (parent != null) {//2.看是否被它的上级加载器加载过了  ，Extension的上级是Bootstarp，但它显示为null
                    c = parent.loadClass(name, false);
                } else {
                    c = findBootstrapClassOrNull(name);//3.如果当前加载器没有父加载器，看是否被启动类加载器加载过
                }
            } catch (ClassNotFoundException e) {
                // ClassNotFoundException thrown if class not found
                // from the non-null parent class loader
                //捕获【上级没有找到时抛出的】异常，但不做任何处理
            }

            if (c == null) {//4.如果上级没有找到
                long t1 = System.nanoTime();
                c = findClass(name);//5.本级加载器自定义的查找类的方法。【如果没找到会抛异常“ClassNotFind”】

                // 5.记录耗时
                sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                sun.misc.PerfCounter.getFindClasses().increment();
            }
        }
        if (resolve) {
            resolveClass(c);
        }
        return c;
    }
}
```

#### 双亲委派模型好处

- 保证了 Java 程序的稳定运行，可以【避免类的重复加载】。
- 也保证了 Java 的【核心 API 不被篡改】。

#### 线程上下文类加载器

- java中存在很多【服务的提供者接口】（Service Provider Interface，SPI）,这些接口允许第三方为他们提供实现，然后进行载入。

  - 常见的 SPI 有 JDBC 等，接口属于java的核心库，由【Bootstrap加载器】加载。
  - 核心类库中程序加载【服务的实现类】时，当前类加载器无法完成，所以需要调用【线程上下文类加载器】。

- 【线程上下文类加载器】是当前线程使用的类加载器，默认就是【应用程序类加载器】。

  ```java
  // 获取线程上下文类加载器
  ClassLoader cl = Thread.currentThread().getContextClassLoader();
  ```

#### 自定义类加载器

继承 ClassLoad 类，重写 findClass() 方法，上级就是【应用程序类加载器】。

如果要打破双亲委派模型，需要重写 loadClass() 方法。

使用场景：

- 想加载非 classpath 随意路径中的类文件。
- 通过【接口】来使用【不同的实现类】，希望解耦时，常用在框架设计。
- 这些类希望予以隔离，【同名类同时工作】【包名类名相同】，不冲突，常见于 tomcat 容器。

#### 破坏双亲委派模式

- 双亲委派模型的第一次“被破坏”其实发生在【双亲委派模型出现之前】，即JDK1.2面世以前的“远古”时代。
  - 建议用户重写findClass()方法，在类加载器中的loadClass()方法中也会调用该方法。
- 双亲委派模型的第二次“被破坏”是由这个模型【自身的缺陷】导致的。
  - 如果有【基础类型】执行过程中，又要【调用回用户的代码】，此时也会破坏双亲委派模式。
- 双亲委派模型的第三次“被破坏”是由于用户对【程序动态性的追求】而导致的。
  - 这里所说的“动态性”指的是一些非常“热”门的名词：【代码热替换（Hot Swap）】、【模块热部署（Hot Deployment）】等。

## 5.6 运行期优化

### 5.6.1 即使编译器

#### 5.6.1.1 即时编译

解释器：

- 将【字节码】解释为【机器码】，下次即使遇到相同的字节码，仍会执行重复的解释。
- 是将字节码解释为针对所有平台都通用的机器码。

即时编译器：

- 将一些字节码编译为机器码，并存入 Code Cache，下次遇到相同的代码，直接执行机器码，减少了解释器的中间损耗。

对于大部分的【不常用的代码】，无需耗费时间将其编译成机器码，而是采取解释执行的方式运行；另一方面，对于仅占据小部分的【热点代码】，我们则可以将其编译成机器码。

#### 5.6.1.2 方法内联

就是把目标方法的代码原封不动的复制到了发起调用的方法之中，避免发生真实的方法调用。

是编译器最重要的优化手段，除了【消除方法调用的成本】之外，更重要的意义是【为其他优化手段建立良好的基础】。

#### 5.6.1.3 逃逸分析

逃逸分析，就是分析对象的动态作用域，如果能证明一个对象不会逃逸到方法或线程之外，则可以为这个对象实例采取不同程度的优化。

一个对象在方法中被定义后，如果可能被外部方法所引用，称为【方法逃逸】；如果可能被外部线程访问到，称为【线程逃逸】。

优化方案包括：【栈上分配】，【标量替换】、【同步消除】三种。

*栈上分配：*

- 一般应用中，完全不会逃逸的局部对象和不会逃逸出线程的对象所占比例是比较大的，这时候可以在栈上分配内存。
- 对象所占空间会随着栈帧出栈而销毁，不用垃圾回收管理，也就大大减轻了垃圾回收的压力。
- 支持方法逃逸，不支持线程逃逸。

*标量替换：*

- 标量：不可再分割的数据，比如原始数据类型，int、long、reference类型；
- 聚合量：可以继续分解，Java对象就是典型的聚合量。
- 如果逃逸分析能证明一个对象不会发生【方法逃逸】，并且这个对象【可以被拆散】，那么程序执行中就可以不创建这个对象，而是直接创建所需要的【成员变量】来代替。
- 除了可以让这些成员变量在【栈上分配和读写】之外，还可以为后续进一步的优化手段创建条件。可以当做是栈上分配的一种特例。

*同步消除：*

- 如果逃逸分析能证明一个对象不会发生【方法逃逸】，那么也就不会发生线程安全问题，同步操作可以直接消除掉。

#### 5.6.1.4 公共子表达式消除

如果一个表达式之前已经计算过了，并且这之间表达式中所有变量的值都没有发生变化，那么这个表达式这次出现就成为公共子表达式。

这种情况下，不需要重复计算，只需要直接使用前面计算的结果代替。

#### 5.6.1.5 数组边界检查消除

如果数组下标是一个【常量】，编译器就可以判断出是否越界，执行时就不用判断了。

或者很多情况下数组访问发生在循环中，并且使用循环变量进行数组访问。这种情况下，如果编译器只要通过数据流分析就可以判定循环变量的取值范围永远在[0,foo.length)之间，那么在循环中就可以把整个数组的上下界检查消除掉。


### 5.6.2 反射优化

反射调用一个方法时：

- 前15次调用本地方法invoke0

- 16次开始，将【本地方法访问器】替换为一个【运行时动态生成的访问器】，这时反射调用变成【主动调用】，提高效率。

# 6. Java并发编程

## 6.1 基础

### 6.1.1 wait 和 sleep区别

- sleep是【静态方法】，当前线程休眠；wait是Object的【成员方法】，需要拿到对象锁后才能调用，当前线程进入阻塞。
- sleep不会【释放对象锁】，wait释放对象锁
- sleep睡眠指定时间【自动苏醒】，wait可以通过signal方法唤醒，或指定一段时间自动苏醒。

等待时都可以被打断，抛出InterruptedException异常。

## 6.2 synchronized关键字

### 6.2.1 理解

synchronized 关键字解决的是【多个线程】之间访问资源的【同步性】，synchronized关键字可以保证被它修饰的【方法】或者【代码块】在任意时刻只能有一个线程执行。多线程想要同时执行会进入阻塞排队，一个线程执行完后会唤醒阻塞队列。

【重量级锁】是依赖对象内部的【monitor锁】来实现的，而monitor又依赖操作系统的【MutexLock(互斥锁)】来实现的，所以重量级锁也称为【互斥锁】。

早期版本中，synchronized 属于 【重量级锁】，效率低下：

- 依赖于【操作系统的互斥锁】，每次获取和释放锁操作都会带来【用户态】和【内核态】的切换，所以效率较低。

构造方法可以使用 synchronized 关键字修饰么？

- 不能，构造方法本身就属于线程安全的，不存在同步的构造方法一说。

### 6.2.2 获取锁流程

当线程执行到【临界区代码】时，如果使用了 synchronized，会先查询指定的对象【是否绑定了 Monitor 锁】。

- 如果【没有绑定】，则会先去与 Monitor 绑定，并且将 Owner 设为当前线程，count 计数设置为1。
  - 对象头中的 Mark Word 置为 Monitor 指针。
- 如果【已经绑定】，则会去查询该 Monitor 是否已经有了 Owner。
  - 如果没有，则将 Owner 设置为当前线程，获得锁，执行语句。
  - 如果有，则放入 EntryList ，进入阻塞状态(blocked)。

当Monitor的Owner将临界区中代码执行完毕后，Owner便会被清空，唤醒EntryList中处于阻塞状态的线程，竞争是【非公平】的。

### 6.2.3 对象头

<img src="D:/Typora/picture/image-20220216221823921.png" alt="image-20220216221823921" style="zoom:80%;" />

### 6.2.4 优化

JDK1.6 对锁的实现引入了大量的优化，如【偏向锁】、【轻量级锁】、【自旋优化】、【锁消除】、【锁粗化】等技术来减少锁操作的开销。

#### 轻量级锁

*使用场景：*

- 当一个对象被多个线程所访问，但访问的时间是错开的，不存在竞争，此时就可以使用【轻量级锁】来优化。

对使用者是透明的，语法仍然是synchronized。

*执行流程：*

1. 执行到synchronized代码块要获取对象锁时，线程内部创建一个【锁记录（Lock Record）对象】，锁记录内部可以储存【对象的Mark Word】和【对象引用reference】。

2. 尝试用 cas 替换对象的 Mark Word，如果成功则获取锁；此时对象中Mark Word有这个【锁记录的地址】，对象原来的Mark Word在锁记录中，释放锁时会交换回来。

3. 如果CAS失败，有两种情况：

  - 如果是自己的线程已经加锁，那么那么再添加一条 Lock Record 作为重入的计数。
  - 如果是其它线程已经持有了该Object的轻量级锁，那么表示有竞争，将进入锁膨胀阶段。

  <img src="D:/Typora/picture/20200309200902-382362.png" alt="1583755737580" style="zoom: 50%;" />

#### 锁膨胀

如果一个线程在获取对象锁失败，并且此时使用的是轻量级锁，则进入锁膨胀升级为重量级锁。

- 将对象头的Mark Word改为Monitor锁的地址，并且状态改为10。
- 并且该线程放入monitor的EntryList中，进入阻塞状态(blocked)。

另一线程释放对象锁时，发现对象头改为了重量级锁状态，进入重量级锁解锁流程，将monitor锁的owner设为null，count值设为0，唤醒EntryList队列中阻塞线程，进行非公平竞争。

#### 自旋优化

发生【重量级锁竞争】的时候，使用自旋来优化，如果当前线程【自旋成功】(锁被释放)，这时就可以避免线程进入阻塞状态。

- 多次未成功，就会进入堵塞。

自旋会占用 CPU 时间，多核 CPU 自旋才能发挥优势。

在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，比较智能。

Java 7 之后不能控制是否开启自旋功能，默认开启。

#### 偏向锁

在轻量级的锁中，如果【只有一个线程】对同一个对象【多次加锁】时，也需要【创建锁记录】对象，执行CAS操作，耗时。

- java6开始引入了偏向锁，开启偏向状态时，对象头Mark Word后三位为101。
- 在第一次获取对象锁时，将【线程的ID】写入对象的【Mark Word】中。
- 锁重入时，直接判断对象头线程ID是否是自己的就行。

多线程错开获取对象锁时，升级为【轻量级锁】。

多线程获取对象锁发生冲突时，升级为【重量级锁】。

#### 锁消除优化

基于【即时编译器】的【逃逸分析】

程序运行时，如果判断出一个对象【不会被其他线程使用】到，可以认为这个对象是【线程私有】的，不会出现线程安全问题，对同步锁进行消除。

#### 锁粗化优化

编写代码的时候，一般是习惯将【同步块】的【作用范围】限制得尽量小，这样如果存在锁竞争，等待锁的线程也能尽快拿到锁。

这可能会导致一段程序会对同一个对象反复加锁和解锁，带来不必要的性能消耗。

【锁粗化】就是适当扩大同步块的范围，将多次【上锁】【解锁】的请求【合并】为一次同步请求。

### 6.2.5 Reentrantlock对比

相同点：

- 都是可重入锁。

不同点：

- synchronized 是一个【关键字】，同步操作由JVM实现；ReentrantLock 是一个【Java类】，同步操作由Java代码实现。
- synchronized 锁会【自动释放】，Reentrant Lock 需要手动释放。
- ReentrantLock 比 synchronized 增加了一些高级功能：
  - 获取锁的过程【可打断】：lock.lockInterruptibly()方法实现
  - 可以设置【超时时间】。
  - 可以实现【公平锁】
  - 可实现【选择性通知】（一个ReentrantLock锁可以绑定多个条件变量）: 可以创建多个Condition，线程阻塞时可以注册在指定的Condition中，从而可以有选择性的唤醒阻塞线程。

## 6.3 volatile关键字

### 6.3.1 并发编程重要特性

【原子性】: 保证一个或多个操作要么【全部都得到执行并且不会受到任何因素的干扰而中断】，要么都不执行。synchronized 可以保证代码片段的原子性。

【可见性】：当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。

【有序性】：Java 在编译期以及运行期间的优化，可能会使部分代码执行顺序发生改变。volatile 关键字可以通过限制指令重排来保证有序性。

### 6.3.2 volatile和sync区别

1. volatile 关键字是【线程同步】的【轻量级】实现，基于【内存屏障】原理，线程【不会阻塞】。

   synchronized 依赖于操作系统的【MutexLock互斥锁】，获取和释放锁需要从用户态转换到内核态，性能开销较大。

2. volatile 关键字只能修饰【变量】，synchronized 关键字可以修饰【方法】以及【代码块】。

3. volatile 关键字能保证【可见性】和【有序性】，但不能保证数据的【原子性】。synchronized 关键字在代码块内部可以保证【原子性】、【可见性】和【有序性】。

### 6.3.3 原理

内部原理是：【内存屏障】。

- 对volatile修饰变量写操作时，语句后面加入【写屏障】。
- 对volatile修饰变量读操作时，语句前面加入【读屏障】。

*保证可见性：*

- 写屏障：保证在该屏障之前的，对共享变量的改动，都同步到主存当中。
- 读屏障：保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据。

*保证有序性：*

- 写屏障：确保指令重排序时，确保不会将写屏障之前的代码排在写屏障之后。
- 读屏障：确保指令重排序时，不会将读屏障之后的代码排在读屏障之前。

### 6.3.4 happens-before

happens-before 是【可见性】与【有序性】的一套规则总结。

*定义：*

- 如果一个操作 Happens-Before 另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
- 并不意味着一定会按照 Happens-Before 原则制定的顺序来执行。如果重排序之后的执行结果与按照 Happens-Before 关系执行的结果一致，那么这种重排序是允许的。

*具体规则：*

1. 【程序次序规则】：一个线程内，按照代码顺序，前面的操作happens-before后面的操作。
2. 【管程锁定规则】：对一个锁的【unLock操作】happens-before之后对【同一个锁的lock操作】（后面指时间的先后）
3. 【volatile变量规则】：对一个【volatile修饰变量的写操作】happens-before 之后对【这个变量的读操作】（后面指时间的先后）
4. 【线程启动规则】：Thread对象的【start()方法】happens-before【此线程的每个一个动作】
5. 【线程终结规则】：【线程中所有的操作】都 happens-before 【线程的终止检测】，比如其它线程调用 thread.join()、thread.isAlive()方法检测到线程已经结束
6. 【线程中断规则】：对线程【interrupt()方法的调用】happens-before【线程的打断检测比如：isInterrupted()】
7. 【对象终结规则】：一个【对象的初始化完成】happens-before 这个对象的【finalize()方法的开始】
8. 【传递性】：如果操作A happens-before操作B，而操作B又happens-before操作C，则可以得出操作A happens-before操作C

## 6.4 atomic 原子类

### 6.4.1 CAS特点

可以实现【无锁并发】，适用于【线程数少】、【多核CPU】的场景下。

- CAS 是基于【乐观锁】的思想；synchronized 是基于【悲观锁】的思想。
- 线程不会陷入阻塞，这是效率提升的因素之一。
- 但如果竞争激烈，重试频繁发生，反而不如直接加锁效率高。

### 6.4.2 原子类原理

并发包 java.util.concurrent 的原子类都存放在 java.util.concurrent.atomic 包下。

- 底层使用的是【Unsafe 类】提供的【CAS方法】，【比较并交换某个内存地址的值】，CAS机制保证了【比较-交换】的原子性，如果成功返回true，如果失败返回false。
- 并且这个变量使用【volatile】修饰，保证可见性和有序性。

具体流程：

- 保存修改之前的值，计算出修改后的值，调用CAS方法修改这个值，如果这个值在这期间没有变化则修改成功。
- 如果失败，重复这个过程，直到修改成功为止。

### 6.4.3 原子类都有哪些

- 基本类型
- 数组类型
- 引用类型
- 对象的属性修改类型

### 6.4.4 原子累加器

专门用于多线程对一个值的累加操作。

原理：

- 设置多个【累加单元】(但不会超过cpu的核心数)，多个线程在分别在累加单元上做累加。
- 最后将结果汇总。
- 累加时操作的不同的 Cell 变量，因此【减少了CAS重试】失败，从而提高性能。

Cell：

- Contended 注解：防止缓存行的伪共享。
- 有一个volatile关键字修饰的Long类型变量，提供CAS方法修改这个值。

## 6.5 线程池

### 6.4.1 为什么使用线程池

【降低资源消耗】。使用线程池重复利用已创建的线程，降低【线程创建】和【销毁】造成的消耗。

【提高响应速度】。当任务到达时，不需要等到线程创建，直接使用已有的线程执行任务。

【提高线程的可管理性】。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

### 6.5.2 Runnable和Callable

【Runnable 接口】不会【返回结果】或【抛出检查异常】，但是【Callable 接口】可以。

execute()方法和 submit()方法：

- execute()方法传入Runnable，没有返回值，无法判断任务是否成功执行。
- submit()方法传入Callable，返回一个Future对象，通过Future对象可以得到线程执行的结果，可以无期限阻塞获取，也可以指定时间阻塞获取，

### 6.5.3 线程池类型

JUC包下的线程池都是通过 ThreadPoolExecutor 线程池对象实现的，构造函数中可以指定：

- 【核心线程数】，【最大线程数】，【救急线程存活时间】
- 【任务队列】，【线程工厂】，【拒绝策略】

FixedThreadPool：

- Executors.newFixedThreadPool() 方法获取。
- 使用的【核心线程数】和【最大线程数】相等。
- 使用的无界队列，LinkedBlockingQueue。
- 固定数量的线程不断地从队列中取出任务

CachedThreadPool：

- Executors.newCachedThreadPool() 方法获取
- 没有核心线程，最大线程数为Integer.MAX_VALUE，所有创建的线程都是救急线程。
- 阻塞队列使用的是 SynchronousQueue。

  - 没有容量，只有当另一个线程来取的时候才能放进去。
  - 也就是说，若有空闲线程可以复用，则会优先使用可复用的线程。若没有空闲线程，则会创建新的线程处理任务。
- 并发量高时，会不断的创建新线程处理任务，所有线程都是救急线程，并发量低时，线程不断减小。

SingleThread：

- Executors.newSingleThreadExecutor() 方法获取。
- 【核心线程数】和【最大线程数】都为1。
- 使用的无界队列，LinkedBlockingQueue。
- 只有一个线程不断从队列中获取任务执行。

【SingleThread】和【自己创建一个线程】有什么区别：

- 当线程正在执行的任务发生错误时，如果是自己创建的线程，该任务和剩余的任务就无法再继续运行下去。
- 而SingleThread会创建一个新线程，继续执行任务队列中剩余的任务。

### 6.5.4 线程池工作方式

线程池收到一个任务之后：

- 如果【当前线程数量】不到【核心线程数量】最大值，创建一个线程，将任务分配给这个线程来执行。
- 如果核心线程数量已满，尝试将任务放到阻塞队列workQueue中等待被执行。
- 阻塞队列满了，创建救急线程来执行任务。
  - 创建的线程会不断从队列中获取任务执行。
  - 救急线程用完以后，超过生存时间（keepAliveTime）后会被释放。
- 如果线程数量到达最大线程数量，并且阻塞队列已满，使用拒绝策略。

### 6.5.5 拒绝策略

- `AbortPolicy`：抛出 RejectedExecutionException 拒绝异常，默认策略。
- `CallerRunsPolicy`：调用者线程执行任务。
- `DiscardPolicy`：直接丢弃掉本次任务。
- `DiscardOldestPolicy`：丢弃队列中到达时间最早的未处理任务，然后将这次任务加入队列中。

### 6.5.6 关闭线程池

`shutdown()`：线程池的状态变为 SHUTDOWN。线程池不再接受新任务了，但是队列里的任务得执行完毕。

`shutdownNow()`：线程的状态变为 STOP。线程池会终止当前正在运行的任务，停止处理排队的任务，并返回正在等待执行的 List。

### 6.5.7 定时任务

`ScheduledExecutorService：`

- 通过工具类 Executors.newScheduledThreadPool(1)
- 只能传一个参数，相当于核心线程个数和最大线程个数相等。
- 就算只有一个线程，发生异常也不会影响后续任务执行。

方法：

- schedule()：延迟时间后，执行任务。
- scheduleAtFixedRate()：延迟时间后，反复执行任务，可以设置时间间隔。【间隔从任务开始执行算起】
- scheduleWithFixedDelay()：延迟时间后，反复执行任务，可以设置时间间隔。【间隔从一个任务执行结束后算起】

## 6.6 JUC

### 6.6.1 AQS

AQS 是一个用来构建【锁】和【同步器】的框架，使用 AQS 能【简单且高效】地构造出大量应用广泛的【同步器】：

- 比如 ReentrantLock，Semaphore，ReentrantReadWriteLock，CountDownLatch等。

*原理：*

- AQS是一个【抽象父类】，使用了【模板方法设计模式】。

- AQS中维护了一个先进先出的【阻塞队列】，等待线程在这个队列中阻塞，类似于 Monitor锁的 EntryList，并且AQS实现了加锁失败后进入阻塞队列的流程，以及释放锁成功后唤醒队列中线程的流程，需要子类实现加锁和解锁的动作。

  独占锁就是tryAcquire和treRelease方法，共享锁就是tryAcquireShared和tryReleaseShared方法。

- 用【state属性】来表示资源的状态（分独占模式和共享模式），子类需要维护这个变量，来控制如何获取锁和释放锁。

- 定义了【条件变量】来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet。

### 6.6.2 ReentrantLock

#### 可重入原理

- 有一个属性记录加锁的线程，加锁时判断是否是自己线程加了锁。

- 同一个线程, 锁重入, 会对 state 进行自增， 释放锁的时候， state进行自减。

- 当state自减为0的时候，此时线程才会将锁释放成功, 才会进一步去唤醒其他线程来竞争锁。

#### 可打断原理

不可打断模式：即使阻塞时被打断，线程仍会驻留在 AQS 队列中，一直要等到获得锁后方能得知自己被打断了。

可打断模式：阻塞时如果被打断，抛出异常。

#### 公平锁原理

tryAcquire()方法中实现，如果没有线程加锁，不会立即加锁，先判断一下阻塞队列中是否有别的线程等待，如果有直接返回false。

#### 条件变量实现原理

conditionObject对象中也有一个阻塞队列，调用await方法，当前线程进入等待队列，并释放锁。

调用signal 方法时，将这个conditionObject的阻塞队列中所有线程加入AQS维护的阻塞队列尾部，等待被唤醒。

### 6.6.3 AQS其他实现

#### ReentrantReadWriteLock、

实现了多个读操作可以同时进行，类似于MySQL数据库中的读写锁。

state属性的高16位为读锁，低16位为写锁。因为继承了AQS父类，子类只需实现如何通过维护state变量实现【加锁】和【解锁】的动作。

#### Semaphore

用于【控制线程数量】，创建对象时传入【最大线程数量】，实际上就是AQS中【state属性值】，一个线程获得锁后state计数-1，直到减到0后，则不允许其他线程再加锁。

应用：使用 Semaphore 限流，在访问高峰期时，控制可以同时到达的请求线程数量。

#### CountdownLatch

用来进行【线程同步协作】，等待所有线程完成倒计时。 

其中构造参数用来初始化【等待计数值】，【countDown()方法】 用来让计数减一，【await()方法】用来阻塞等待计数归零。

#### CyclicBarrier

循环栅栏，用来进行【线程协作】，等待线程满足某个计数。

- 构造函数传入【计数个数】【Runnable】,线程调用await()时计数-1,并开始等待。
- 计数到达0时，所有线程恢复运行，然后执行CyclicBarrier中的Runable任务。

可以循环使用。

注意：线程池数量要和计数个数相同。

### 6.6.4 CouncurrentHashMap

### 6.6.5 LinkedBlockingQueue

是一个【单向链表】，有头尾【两个哑元节点】。

实现了生产者和消费者可以并发执行，【添加节点】时给【头结点】加锁，【取出节点】时给【尾节点】加锁。

### 6.6.6 其他集合

CocurrentLinkedQueue：

- 设计与 LinkedBlockingQueue 非常像，也是两把【锁】，同一时刻，可以允许两个线程同时（一个生产者与一个消费者）执行。

  - dummy 节点的引入让两把【锁】将来锁住的是不同对象，避免竞争。

  - 只是这【锁】使用了 cas 来实现。


CopyOnWriteArrayList：

- 写入时拷贝的思想，增删改操作会将底层数组拷贝一份，更改操作在新数组上执行，这时不影响其它线程的并发读，读写分离。 

## 6.7 ThreadLocal

ThreadLocal类用来提供线程内部的局部变量。

- 【线程并发】: 在多线程并发的场景下。
- 【传递数据】: 我们可以通过ThreadLocal在同一线程，不同组件中传递公共变量。
- 【线程隔离】: 每个线程的变量都是独立的，不会互相影响。

### 6.7.1 原理

每个thread对象内部有一个ThreadLocalMap对象，是一个map，key为ThreadLocal对象，value为要存储的线程独立的变量。

ThreadLocalMap是ThreadLocal的内部类，没有实现Map接口，用独立的方式实现了Map的功能，其内部是一个Entry数组。

- 初始容量是16，扩容因子为2/3。
- entry继承了弱引用WeakReference，使用完ThreadLocal后，即使当前ThreadLocalMap存在，也不影响ThreadLocal对象的回收。

早期设计：每个ThreadLocal中有一个map，key时thread，value为要存储的值。

*新版设计的好处：*

- 每个Map存储的Entry数量就会变少。因为之前的存储数量由Thread的数量决定，现在是由ThreadLocal的数量决定。在实际运用当中，往往ThreadLocal的数量要少于Thread的数量。
- 当Thread销毁之后，对应的ThreadLocalMap也会随之销毁，能减少内存的使用。

*set()方法：*

- 根据当前线程得到线程中的ThreadLocalMap对象，如果为空创建新的ThreadLocalMap，将ThreadLocal和value封装成entry加入Map中。
- 定位到哈希槽后，可能出现entry存在，但是entry中ThreadLocal已经回收的情况，

*哈希定位：*

- 每个ThreadLocal对象创建时，使用一个全局的静态变量AtomicInteger增加一个固定值，获取ThreadLocal对应的哈希值。
- 这个哈希值与数组长度取模，映射到数组的一个下标。

*哈希冲突：*

- 线性探测法，发生哈希冲突时，依次探测下一个地址，直到有空的地址后插入。

*get()方法：*

- 根据当前线程得到线程中的ThreadLocalMap对象，根据ThreadLocal找到对应的下标，返回entry中的value值。
- 如果对应下标的entry不是当前ThreadLocal，需要依次寻找下一个下标。

## 6.8 代码实现

### 6.8.1 单例模式

#### 双检查锁

```java
public class Singleton {
    private Singleton() {
    }

    private volatile static Singleton INSTANCE = null;

    public static Singleton getInstance() {
        if (INSTANCE == null) {
            synchronized (Singleton.class) {// 首次访问会同步，而之后的使用没有 synchronized
                if (INSTANCE == null) { // t1
                    INSTANCE = new Singleton();
                }
            }
        }
        return INSTANCE;
    }
}
```

#### 静态内部类

```java
public class Singleton{
    private Singleton(){}
    
    private static class SingletonHolder{
        private static final Singleton INSTANCE = new Singleton();
    }
    
    public static Singleton getInstance(){
        return SingletonHolder.INSTANCE;
    }
}
```

### 6.8.2 死锁

```java
public class DeadLock {
    public static void main(String[] args) throws Exception{
        Object lock1 = new Object();
        Object lock2 = new Object();
        new Thread(() -> {
            synchronized (lock1){
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized (lock2){
                    log.debug("线程1执行结束");
                }
            }
        }).start();


        new Thread(() -> {
            synchronized (lock2){
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                synchronized (lock1){
                    log.debug("线程2执行结束");
                }
            }
        }).start();
    }
}
```

### 6.8.3 顺序打印

#### synchronized

```java
public class AltPrinting {
    public static void main(String[] args) {
        Symbol symbol = new Symbol('a',5);
        new Thread(()->{
            symbol.print('a','b');
        }).start();
        new Thread(()->{
            symbol.print('b','c');
        }).start();
        new Thread(()->{
            symbol.print('c','a');
        }).start();
    }
}
@Slf4j
class Symbol{
    char flag;
    int count;
    public Symbol(char flag , int count){
        this.flag = flag;
        this.count = count;
    }

    public void setFlag(char flag) {
        this.flag = flag;
    }
    public synchronized void print(char thistime,char next){
        for(int i = 0 ;i < count ; i ++){
            while(flag != thistime){
                try {
                    this.wait();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            log.debug(""+flag);
            this.flag = next;
            this.notifyAll();
        }
    }
}
```

#### ReentrantLock

```java
public class AltPrinting2 {
    public static void main(String[] args) throws InterruptedException {
        Symbol2 symbol2 = new Symbol2(5);
        Condition A = symbol2.newCondition();
        Condition B = symbol2.newCondition();
        Condition C = symbol2.newCondition();
        new Thread(()->{
            symbol2.printABC("a",A,B);
        }).start();
        new Thread(()->{
            symbol2.printABC("b",B,C);
        }).start();
        new Thread(()->{
            symbol2.printABC("c",C,A);
        }).start();

        Thread.sleep(100);
        symbol2.lock();
        A.signalAll();
        symbol2.unlock();

    }
}

@Slf4j
class Symbol2 extends ReentrantLock {
    int count;
    public Symbol2(int count){
        this.count = count;
    }
    public void printABC(String s , Condition thisCondition , Condition nextCondition){
        for(int i = 0 ;i < count ; i ++){
            lock();
            try{
                thisCondition.await();
                log.debug(s);
                nextCondition.signalAll();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally{
                unlock();
            }
        }
    }

}
```

#### park/unpark

```java
public class AltPrinting3 {
    static Thread a,b,c;
    public static void main(String[] args) {
        Symbol3 symbol3 = new Symbol3(5);

        a = new Thread(()->{
            symbol3.printABC("a",b);
        });
        b = new Thread(()->{
            symbol3.printABC("b",c);
        });
        c = new Thread(()->{
            symbol3.printABC("c",a);
        });
        a.start();
        b.start();
        c.start();
        LockSupport.unpark(a);
    }
}
@Slf4j
class Symbol3{
    int count;
    public Symbol3(int count){
        this.count = count;
    }
    public void printABC(String s , Thread next){
        for(int i = 0 ;i < count ; i ++){
            LockSupport.park();
            log.debug(s);
            LockSupport.unpark(next);
        }
    }
}
```

# 7. Java

## 7.1 基础

### 7.1.1 三大特性

封装
- 对象的【属性私有化】，提供方法访问属性。

继承
- 一个类继承已经存在的类，该类拥有被继承的类的所有【属性】和【方法】，并且可以根据自己的情况拓展属性或方法。
  - 子类拥有父类对象所有的属性和方法，但是父类中的【私有属性和方法子类】无法访问，只是拥有。
  - 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。
  - 子类可以用自己的方式重写父类的方法。
- Java不支持多继承

多态
- 【引用变量】所指向的【具体类型】和【通过该引用变量调用的方法】在编译期并不确定，而是在程序运行期间才确定。
- 两种形式可以实现多态：【继承】（多个子类对同一方法的重写）和【接口】（实现接口并覆盖接口中同一方法）。

### 7.1.2 重载和重写

- 重载是发生在同一个类中，具有【相同的方法名】，但是有【不同的参数】，通常用于实现相同或相似功能。
- 重写是发生在当子类继承父类时，对父类中的一些方法根据自己的需求进行重写操作。

- 重载【方法返回值类型】可以不同。
- 重写方法的【返回类型】若是引用类型，可以是原来的子类。

### 7.1.3 接口和抽象类的区别

相同点：

1. 都不能被实例化
2. 实现类必须实现抽象方法。

不同点：

1. 接口只有方法的定义，不能有方法的实现，但java 1.8中可以定义default方法体，而抽象类可以有方法的定义与实现。
2. 实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。
3. 接口方法默认修饰符是 public，抽象方法可以有 public、protected 和 default 这些修饰符（抽象方法就是为了被重写所以不能使用 private ）。
4. 接口强调特定功能的实现，而抽象类强调所属关系。
5. 从设计层面来说，抽象类是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。


### 7.1.4 内部类

- 【静态内部类】、【局部内部类】、【匿名内部类】和【成员内部类】。

### 7.1.5 final关键字

final关键字可以修饰【类】、【方法】和【属性】。

- final修饰类不能被继承。final 类中的所有成员方法都会被隐式地指定为 final 方法。
- 当final修饰的方法不能被重写。
- 当final修饰的属性一旦赋值不能被更改。

### 7.1.6 三种字符串类

String，StringBuilder和StringBuffer

- String 类中使用 final 关键字修饰【字符数组】来保存字符串，private final char value[]，所以 String 对象是不可变的。
- StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用【字符数组】，但是没有用 final 关键字修饰，这两种对象都是可变的。
- StringBuffer 对方法加了同步锁，是线程安全。StringBuilder 没有对方法加同步锁，是非线程安全的。

### 7.1.7 = 和 equals

=用来判断基本类型值是否相等，引用数据类型的引用地址是否相等。

equals是Object中提供的方法，用来判断两个对象内容是否相同，需要子类重写具体判断逻辑。

### 7.1.8 访问修饰符

- public：任何位置都能访问。
- private：只有本类可以访问。
- 默认：本类和同包类中可以访问，其他位置不能访问。
- protected：本类和同包类可以访问，并且其他位置的子类也可以访问。

可以修饰什么：

- 方法和属性：4个都能用。
- 类和接口：只能使用【public】和【默认】修饰。

怎么获取private修饰的变量：

- private通过反射获取，可以设置setAccessable为true实现

### 7.1.9 深拷贝和浅拷贝

- 浅拷贝：拷贝原对象的所有属性，如果是引用类型直接拷贝内存地址，所以【拷贝后的对象】和【原对象】的引用类型指向的是同一个对象。
- 深拷贝：基本数据类型直接拷贝数值，对引用数据类型，将其所指对象也会重新拷贝一份，新对象对应的属性指向这个拷贝出来的对象。

Object的clone()方法实现的是浅拷贝。

实现深拷贝可以自己重写这个方法。

## 7.2 异常

### 7.2.1 层次结构

Exception和Error都继承了Throwable抽象父类，都是可抛出的。

Exception有一个子类RuntimeException，代表【运行时异常】，也叫【非受检异常】，所有运行时异常都继承自这个子类。

Exception的其他子类代表【编译时异常】，也叫【受检异常】。

### 7.2.2 Exception和Error区别

- Exception :程序本身可以处理的异常，可以通过 catch 来进行捕获。Exception 又可以分为 编译时异常 和 运行时异常。

- Error ：Error 属于程序无法处理的错误，这些异常发生时，Java 虚拟机会中止程序运行。

  比如：Java 虚拟机运行错误（Virtual MachineError）、虚拟机内存不够错误(OutOfMemoryError)、类定义错误（NoClassDefFoundError）等 。

### 7.2.3 运行时异常和编译时异常

编译时异常：编写程序时必须通过catch或者throws处理异常，否则编译不通过。

运行时异常：不用处理异常编译时也能通过。

### 7.2.4 finally块一定会执行吗

不会

- 进入try之前就发生异常，则不会执行。
- 直接退出虚拟机，就不会运行，Sysetm.exit(0)方法。

## 7.3 反射

通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。

反射通常应用于框架中，比如ssm框架大量使用了反射，动态代理的实现也依赖反射。

### 7.3.1 如何获取class对象

- 通过一个类的静态属性：Object.class
- 通过一个对象的class属性。
- 通过Class.forName()方法，根据一个全限定类名找到class。

### 7.3.2 反射机制的优缺点

优点 ： 可以让代码更加灵活、为各种框架提供了便利。

缺点 ：

- 让程序在运行时有了分析操作class对象的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。
- 另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。

## 7.4 集合

### 7.4.1 List

#### ArrayList

ArrayList底层使用的是 Object数组。

以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。

添加第一个元素时，才真正分配容量，数组容量扩为 10。

当插入的元素个数大于当前容量时，就需要进行扩容了， ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右。

#### LinkedList和ArrayList

ArrayList底层使用的是【Object数组】；LinkedList底层使用的是【双向链表】数据结构。

ArrayList:随机增删慢、查询快，元素必须连续存储。

LinkedList:随机增删快，查询慢。

#### Vector

底层也是Object数组，和ArrayList比较相似，不过方法上加了synchronized关键字，是线程安全的。

### 7.4.2 Map

#### HashMap和Hashtable

线程安全：

- HashTable 内部的方法基本都经过synchronized 修饰，线程安全。

是否可以null的key和value：

- HashMap 可以存储 null 的 key 和 value，但 null 作为key只能有一个，null 作为value可以有多个。
- HashTable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。

初始容量大小和每次扩充容量大小的不同

- 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。
- 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的N次方大小。

红黑树：

- HashTable不支持。

#### HashMap和TreeMap

- HashMap是基于hash表，通过hash值进行快速查找的，元素没有顺序。
- TreeMap是基于红黑树实现，key是有序的。



- HashMap：适用于插入，删除，定位元素。

- TreeMap：适用于按一定顺序遍历key。



- HashMap继承AbstractMap类。

- TreeMap继承SortedMap类。

  

- HashMap：要求key明确定义了hashcode() 和equals() ;为了优化HashMap的空间使用，可以调优初始容量和负载因子；

- TreeMap：没有调优选项，因为红黑树总是处于平衡的状态。


### 7.4.3 HashMap

#### 1. 构造方法

- 给【负载因子】和【初始大小】赋值。默认值【0.75】【16】。初始化大小为大于传入值的2的n次方。

- 并未创建Node数组。


#### 2. hash()方法

- 通过key得到hash值。

  - key的hashcode()方法获得key的哈希值。
  - key的哈希值经过一个哈希扰动，得到h。【异或运算】

- h用来计算下标，与Node数组长度取模。

- 作用：让key的哈希值的高16位也参与取模运算。

  ```java
      static final int hash(Object key) {
          int h;
          return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
      }
  ```


#### 3. put()方法：

流程：

- 如果node数组为空，先创建node数组。
- 通过key得到的hash值，与数组长度取模，映射到一个数组下标。
- 如果下标位置为null，创建node，添加到这个位置；如果不为null，将node加入这个链表或者红黑树中，如果有key相同的节点，直接替换value值。
- 如果是向链表中添加了node，判断是否需要树化。
  - 如果链表长度大于8时，需要进行扩容或树化，如果数组长度小于64，进行扩容；如果数组长度大于等于64，将链表转化为红黑树。

- 如果添加了新的node，判断是否需要扩容。

#### 4. resize()方法

如果还没有创建node数组，创建新的node数组。

如果已经有node数组，执行扩容流程。

过程：

- 计算新数组的【长度】和【扩容阈值】。
  - 如果node数组还没有创建，使用默认值。
  - 如果node数组已经创建，长度为旧数组长度的2倍。
- 创建新的node数组，将旧的数组中的node迁移到新的数组中。

#### 5. get() 方法

过程：

- 通过key得到的hash值，与数组长度取模，映射到一个数组下标。

- 在这个下标位置开始寻找key值相同的节点，找到返回value，未找到则返回null。


#### 6. HashMap 1.7

jdk 1.7 版本中HashMap是用数组+链表实现的，jdk 1.8 版本HashMap是用数组+链表+红黑树实现的。

#### 7. 为什么负载因子是0.75

如果负载因子过大，可能导致链表或红黑树上元素比较多，虽然空间利用率比较高，但是查询效率会变低。

如果负载因子过小，会导致空间利用率大大降低。

负载因子是0.75的时候，空间利用率比较高，而且避免了相当多的Hash冲突，使得底层的链表或者是红黑树的高度比较低，也提升了时间效率。

### 7.4.4 ConcurrentHashMap

#### 1.构造方法

和HashMap一样，懒惰初始化，计算数组长度sizeCtl并赋值。

#### 2.put方法

流程：

1. 如果node数组还没创建，创建一个新的node数组(使用CAS机制加锁)。
2. 根据key计算哈希值，与数组长度取模，映射到一个数组下标，找到头结点，
3. 如果头结点为空，使用CAS机制，添加一个node，如果成功直接返回。
4. 如果正在扩容，开始帮忙扩容，扩容过程以一个链表或红黑树为单位。
5. 添加node，首先synchronized关键字锁住头节点，向链表或红黑树中添加node，如果找到key相同的节点，直接修改value值。
6. 如果是链表中添加了一个节点，判断是否需要树化，或扩容。
7. 最后累加节点数量，判断是否需要扩容。累加过程和LongAdder比较相似，都是在多个累加单元上累加。

#### 3.get方法

流程：

1. 根据key计算哈希值，与数组长度取模，映射到一个数组下标，找到这个下标的node。
2. 判断是否是红黑树，或者是否正在扩容，在这个节点上寻找key相同的节点。
3. 不需要加锁，只需要保证可见性，使用了unsafe对象的getObjectAcquire方法。

#### 4.initTable方法

初始化node数组的方法。

流程：

- 创建数组之前需要加锁，通过CAS机制修改sizeCtl值为-1。
- 首先需要判断是否已经有线程加锁，也就是sizeCtl值是否为-1，如果是，等待另一线程创建成功即可。(不会阻塞，不断循环判断是否已创建好数组，如果没有调用yield让位)

#### 5.addCount方法

添加node后调用这个方法计数+1。

流程：

- 原理和LongAdder相似，设置多个累加单元累加计数，数量超过阈值就扩容。

扩容流程：

- 判断是否加锁，sizeCtl是否<0，如果是，说明其他线程正在执行扩容，进入帮忙扩容的流程。
- 如果没有加锁，先加锁，使用CAS方法将sizeCtl值修改为一个负数，开始扩容。

#### ConcurrentHashMap1.7

会创建一个segment数组，segment继承自ReentrantLock，每个segment指向一个entry数组(也就是一个链表的数组)。

加锁的粒度为一个segment。

put方法：

- 先根据key的hash值映射到一个segment数组的下标，将这个segment加锁。
- 将数据插入这个segment对应的链表数组中。
- 判断是否需要扩容，如果需要，创建一个长度两倍的链表数组，将旧的链表数组中所有node，迁移过去。(扩容过程是在put方法中执行的，已经加了锁)

get方法：

- 不用加锁，需要保证可见性即可，保证数组中元素的可见性，使用了Unsafe对象的getObjectAcquire方法。

# 8. 仿牛客网

## 8.1 数据库表设计

### 8.1.1 user

- id:int型自增主键 ；
- password 和 salt：密码，salt随机生成，与用户输入的密码拼接后，再经过一个hash散列算法得到password。

<img src="D:/Typora/picture/image-20220626140055386.png" alt="image-20220626140055386" style="zoom:80%;" />

```sql
CREATE TABLE `user` (
  `id` int NOT NULL AUTO_INCREMENT,
  `username` varchar(50) DEFAULT NULL,
  `password` varchar(50) DEFAULT NULL,
  `salt` varchar(50) DEFAULT NULL,
  `email` varchar(100) DEFAULT NULL,
  `type` int DEFAULT NULL COMMENT '0-普通用户; 1-超级管理员; 2-版主;',
  `status` int DEFAULT NULL COMMENT '0-未激活; 1-已激活;',
  `activation_code` varchar(100) DEFAULT NULL,
  `header_url` varchar(200) DEFAULT NULL,
  `create_time` timestamp NULL DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_username` (`username`(20)),
  KEY `index_email` (`email`(20))
) ENGINE=InnoDB AUTO_INCREMENT=152 DEFAULT CHARSET=utf8mb3;
```

### 8.1.2 login_ticket

- id:int型自增 ； user_id:表示用户信息 ； ticket：用来查询这个login_ticket。
- status：0表示有效，1表示无效。

<img src="D:/Typora/picture/image-20220626143943927.png" alt="image-20220626143943927" style="zoom:80%;" />

```sql
CREATE TABLE `login_ticket` (
  `id` int NOT NULL AUTO_INCREMENT,
  `user_id` int NOT NULL,
  `ticket` varchar(45) NOT NULL,
  `status` int DEFAULT '0' COMMENT '0-有效; 1-无效;',
  `expired` timestamp NOT NULL,
  PRIMARY KEY (`id`),
  KEY `index_ticket` (`ticket`(20))
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb3;
```

### 8.1.3 discuss_post

- id:int类型自增。
- user_id:发帖人

<img src="D:/Typora/picture/image-20220626162805181.png" alt="image-20220626162805181" style="zoom:80%;" />

```sql
CREATE TABLE `discuss_post` (
  `id` int NOT NULL AUTO_INCREMENT,
  `user_id` varchar(45) DEFAULT NULL,
  `title` varchar(100) DEFAULT NULL,
  `content` text,
  `type` int DEFAULT NULL COMMENT '0-普通; 1-置顶;',
  `status` int DEFAULT NULL COMMENT '0-正常; 1-精华; 2-拉黑;',
  `create_time` timestamp NULL DEFAULT NULL,
  `comment_count` int DEFAULT NULL,
  `score` double DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_user_id` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=30287 DEFAULT CHARSET=utf8mb3;
```

### 8.1.4 comment

- 包括【帖子的评论】，【评论的回复】。
- entity_type 表示哪种评论，1代表评论帖子，2代表回复评论。
- entity_id 表示回复目标的id。
- target_id 表示目标用户id。

<img src="D:/Typora/picture/image-20220626163815326.png" alt="image-20220626163815326" style="zoom:80%;" />

```sql
CREATE TABLE `comment` (
  `id` int NOT NULL AUTO_INCREMENT,
  `user_id` int DEFAULT NULL,
  `entity_type` int DEFAULT NULL,
  `entity_id` int DEFAULT NULL,
  `target_id` int DEFAULT NULL,
  `content` text,
  `status` int DEFAULT NULL,
  `create_time` timestamp NULL DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_user_id` (`user_id`) /*!80000 INVISIBLE */,
  KEY `index_entity_id` (`entity_id`)
) ENGINE=InnoDB AUTO_INCREMENT=238 DEFAULT CHARSET=utf8mb3;
```

### 8.1.5 message

<img src="D:/Typora/picture/image-20220626184510603.png" alt="image-20220626184510603" style="zoom:80%;" />

```sql
CREATE TABLE `message` (
  `id` int NOT NULL AUTO_INCREMENT,
  `from_id` int DEFAULT NULL,
  `to_id` int DEFAULT NULL,
  `conversation_id` varchar(45) NOT NULL,
  `content` text,
  `status` int DEFAULT NULL COMMENT '0-未读;1-已读;2-删除;',
  `create_time` timestamp NULL DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_from_id` (`from_id`),
  KEY `index_to_id` (`to_id`),
  KEY `index_conversation_id` (`conversation_id`)
) ENGINE=InnoDB AUTO_INCREMENT=387 DEFAULT CHARSET=utf8mb3;
```



## 8.2 登录模块

### 8.2.1 注册功能

首先前端页面传入【用户名】，【密码】，【邮箱】三个参数，

controller类：接受请求，用【实体类User】接受参数，调用service处理请求，返回map。

service类：

- 验证参数是否为空，验证用户名，邮箱是否已存在，如果不通过将错误信息放入map中返回；
- 如果通过，会返回空的map，并【将user插入数据库】中，状态为【未激活】，生成一个随机字符串作为【激活码】，用于用户激活，将激活请求放在邮件中发给用户。
- 这里会随机生成一个长度为5的字符串salt，并和用户请求中的密码拼接之后，再通过一个hash散列函数得到用户的password。

用户激活：点击邮箱中激活请求链接，请求参数中带有数据库表中的【用户ID】和【激活码】，服务器接受这两个参数，验证是否和数据库中信息相同即可，如果验证成功将数据库中user状态变为已激活。

### 8.2.2 登录功能

需要一个生成验证码的工具，这里使用的是kaptcha，controller层接受【用户名】，【密码】，service层验证是否正确。

登录成功后，用户会保存一个cookie，用于用户的登录认证，数据库中需要保存用户登录状态，保存在login_ticket表中

login_ticket表中字段包括：【用户ID】，【cookie的值】，【登录状态是否有效】，【过期时间】

退出登录时，将表中的信息修改位为登录过期。



用拦截器实现了【检查登录状态】和【显示用户信息】：

- 用户发起请求时，会带有一个用户检查登录状态的cookie，拦截器中preHandle方法，负责根据cookie验证登录状态是否有效，如果有效，将User加入一个容器中。
- 容器实际上是一个ThreadLocal对象，用于在一个线程不同组件之间传递信息，并且各线程的数据相互隔离。
- 拦截器的postHandle方法，负责在controller方法结束后修改ModelAndView，将User添加到【Request作用域】中。
- 拦截器的afterCompletion方法，负责在请求处理完后执行，删除容器中的User。
- 检查登录状态：在拦截器中检查容器中是否有User信息，如果有才能访问相应的controller方法，如果没有，直接重定向到登录页面。

### 8.2.3 修改头像功能

- controller接受用户传入的头像图片，使用MultipartFile对象接受。
- 将头像存储在本地或云端服务器，本项目中实现了存储在七牛云服务器中。
- 并修改数据库user表中的头像路径，然后实现根据这个路径返回头像。

## 8.3 核心功能模块

### 8.3.1 发布帖子

controller接受String类型的title和content，从容器中获取用户信息，如果没有用户信息，说明没有登陆，直接返回错误信息。

包装成discussPost实体类对象。

service层，实现对title和content的【过滤敏感词】和【转义HTML标记】，然后将discussPort插入数据库中。

### 8.3.2 添加评论

service层使用事务：

- 将comment插入到数据库中。
- 更新discuss_post中评论数量。

### 8.3.3 帖子详情

### 8.3.4 私信列表和发送私信

## 8.4 redis优化

### 8.4.1 点赞功能

可以对【帖子】或者【评论】或者【评论的回复】点赞，也可以取消点赞，使用频率很高，考虑性能问题，使用redis存储，存到内存里。

- 需要统计某个实体的【点赞数量】，并且需要查找某个用户对某实体【是否点赞】，所以使用【set类型】。
  - key代表某一条帖子或评论用【类型】和【id】表示，将点赞的【用户名】存到set中。

- 需要统计某用户收到的赞的总数量，使用【String类型】。
  - key代表某用户，每收到一个点赞 +1

由于有两步数据库的操作，所以使用【事务】保证两个操作的原子性。

### 8.4.2 关注和取消关注

关注目标可以是【用户】，【帖子】，这里定义为实体类，

- 需要查询某用户的【关注列表】，并且可以【按时间排序】，还要查询某用户【是否关注】了某实体，所以使用【zset类型】数据。
  - key：followee:userId:entityType -> zset(entityId,now)
- 需要查询某实体的【粉丝列表】，并且【按时间排序】，所以还要再使用【zset类型】数据。
  - key：follower:entityType:entityId -> zset(userId,now)

有两步数据库操作，需要使用【事务】保证两步的原子性。

### 8.4.3 登录模块优化

#### redis存储验证码

生成验证码时，将验证码保存在redis中，将这个数据key的信息存放在cookie中返回给客户端。

登录请求中会携带cookie，服务端拿到cookie后，根据cookie内容找到redis存储的对应的验证码，解决了分布式session的问题。

#### 显示登录信息

登录成功后，每次发起请求时，拦截器都会从数据库中查询登录状态，并查询user信息，将user信息加入到容器中。

所以将这个【登录状态】和【user】信息都放入redis中来进行优化。

具体只要修改service层中的方法即可。

- 登录时，将登录状态login_ticket加入redis中，每次请求都从redis中查找登录状态，退出登录时，修改登录状态为失效。

- 对于存储user信息，采用缓存的方式，先从redis中查找user是否存在，如果不存在，再去MySQL数据库中查找，找到后将user信息加入到redis中。

  修改user时，先更新数据库信息；再删除缓存。

## 8.5 Kafka优化

### 8.5.1 发送系统通知

【点赞】，【关注】，【评论】等操作后，系统自动通知目标用户。

这些操作频繁，为了提高性能，快速响应请求，使用kafka消息队列异步进行处理。【生产者消费者并发执行（异步方式）】

### 8.5.2 elasticsearch更新帖子

使用elasticsearch时，帖子发生变化后要同时更新到elasticsearch服务器中，这一步使用kafka消息队列异步完成，提高响应速度。

## 8.6 elasticsearch优化

使用elasticsearch实现【按关键字查询帖子】功能

发布帖子时，将帖子添加到elasticsearch服务器；帖子被修改后，使用kafka异步的更新elasticsearch中帖子；删除帖子时，也将帖子从es中删除。

## 8.7 其他优化

### 8.7.1 spring security

使用spring security进行权限管理，需要由拦截器进行登录认证时将用户信息存放到spring security容器中。

置顶、加精、删除功能：

- 既要修改数据库中数据，也要修改elasticsearch中数据。
- 需要进行身份认证，只有管理员权限可以操作

### 8.7.2 网站数据统计

统计【独立访客】和【日活跃用户】

- 【独立访客】，通过访问的IP重排统计数据，每天可能有大量访客，为了节约空间，使用HyperLogLog，性能也比较好。

- 【日活跃用户】，通过用户id重排数据，用户id为四字节整数，使用Bitmap也不会占用过大空间，因为每个id只占用一个bit位，并且Bitmap可以精准统计数据。


需要根据一段时间，获取独立访客和活跃用户，所以需要统计每一天的数据，查询时，合并时间段内每一天的数据。



统计的过程使用拦截器完成，在每次访问时，将这次的IP加入当天的独立访客HyperLogLog中，如果存在登录信息，将user信息加入当天的日活跃用户Bitmap中。 

### 8.7.3 热帖排行

热帖排行是根据帖子的分数排序，每次评论点赞都会改变帖子分数，如果每次都修改帖子分数，将会浪费大量性能。

解决：设置一个定时器，每隔一段时间定时刷新帖子分数，这里使用的是可以运行在分布式环境下的定时任务器quartz。

- 设置一个redis的set集合，每次评论点赞等事件发生时，将这个帖子的id加入到set集合中。
- 定时器每次执行任务时，取出set集合中所有数据，刷新帖子的分数，插入数据库，并且添加到elasticsearch服务器中。

### 8.7.4 优化网站性能

通过增加多级缓存的方式优化查询性能，其中按热度查询帖子的功能，热度分数隔段时间更新一次，适合添加到缓存中。

使用缓存 Caffeine + redis二级缓存的方式优化。

## 8.8 kafka面试题

### 1. 什么是MQ

MQ 真正的目的是【为了通讯】，为开发人员屏蔽底层复杂的通讯协议，定义了一套【应用层】的、【比较简单】的通讯协议，也就是【生产者/消费者模型】。

开发人员可以自定义【生产者】和【消费者】，【实现消息通讯】而【无视底层通讯协议】。

### 2. MQ的作用

通常来说，使用消息队列能为我们的系统带来下面三点好处：

1. 通过异步处理提高系统性能（减少响应所需时间）
2. 削峰/限流
   - 短时间内高并发请求的消息先放在消息队列中，然后服务端根据自身能力消费这些消息，避免服务端来不及处理而崩溃。
3. 降低系统耦合性。
   - 需要消费消息的系统直接去消息队列取消息进行消费即可，不需要和其他系统有耦合，这也提高了系统的扩展性。

### 3. kafka介绍

Kafka 是一个【高吞吐量】、【分布式】的【发布—订阅】消息系统。

并且是一个支持【多分区】，【多副本】，【基于zookeeper协调】的分布式消息系统。

与其他消息队列相比，Kafka【仅仅提供较少的核心功能】，但是提供【超高的吞吐量】，【ms级的延迟】，极高的【可用性】以及【可靠性】，而且【分布式系统可以任意扩展】。

kafka 的劣势是有可能造成【消息重复消费】，实际影响较小。

### 4. zookeeper的作用

#### 4.1 Broker注册

Broker是分布式部署并且彼此之间相互独立，Zookeeper作为注册中心对整个集群的Broker进行管理。

Broker在zookeeper中保存为一个临时节点，节点的路径是`/brokers/ids/[brokerid]`,每个节点会保存对应broker的【IP以及端口等信息】。

#### 4.2 Topic注册

在kafka中,一个topic会被分成多个区并被分到多个broker上，【分区的信息】以及【broker的分布情况】都保存在zookeeper中，根节点路径为`/brokers/topics`。

每个topic都会在topics下建立独立的子节点，每个topic节点下都会包含分区以及broker的对应信息。

- partition状态信息：`/brokers/topics/[topic]/partitions/[0…N]` 其中[0…N]表示partition索引号。

#### 4.3 负载均衡

对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。

当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。

当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

#### 4.4 分区和消费组

在Kafka中，规定了每个【消息分区】只能被同组的【一个消费者】进行消费，因此，需要在 Zookeeper 上记录【消息分区】与【Consumer】之间的关系，每个消费者一旦确定了对一个消息分区的消费权力，需要将其【Consumer ID】写入到 Zookeeper 对应消息分区的临时节点上，例如：`/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]`

#### 4.5 消费进度Offset

消费者对指定消息分区进行消息消费的过程中，需要定时地将分区消息的消费进度Offset记录到Zookeeper上。

其节点路径为:`/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]`

#### 4.6 消费者注册

消费者服务器在初始化启动时会注册到消费者分组。

消费者服务器启动时，到Zookeeper的指定节点下创建一个属于自己的消费者节点，例如`/consumers/[group_id]/ids/[consumer_id]`，完成节点创建后，消费者就会将自己订阅的Topic信息写入该临时节点。

### 5. 如何保证顺序消费

每个partition中的消息是顺序存储的，并且会顺序消费。

生产者：将所有消息发送到一个分区中，或者整个topic只设置一个分区，另外设置为同步发送，并且ack值不能设置为0，确保消息可以顺序到达broker中。

消费者：一个消费组只需要一个消费者从指定分区中获取所有消息消费即可。

### 6. 如何保证消息不丢失

生产者：

- 设置为同步发送，并且ack设置为1或者all，设置合理的【重试次数】和【间隔时间】，确保broker收到消息
- 为了防止分区的leader收到消息后就挂掉，可以将ack设置为all，设置多个副本，并设置 `min.insync.replicas > 1`。

消费者：

- 把自动提交改为手动提交offset。

其他：

- 设置 `unclean.leader.election.enable = false`；当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性

### 7. 如何保证不重复消费消息

消息重复消费原因：

- 生产者重试机制，消息因网络原因延迟到达时，可能触发重试，导致broker中有重复的消息。
- 消费者消费消息后，没能提交offset，导致重复消费同一个消息。

解决：

- 消费消息时【幂等校验】，比如【Redis 的set】、【MySQL 的主键】等天然的幂等功能。

## 8.9 elasticserch

### 1. 为什么使用es

*es是什么？*

Elasticsearch 是基于 Lucene 的 Restful 的【分布式】【实时】【全文搜索引擎】，每个字段都被索引并可被搜索，可以快速【存储、搜索、分析海量的数据】。

【全文检索】是指对【每一个词】建立一个【索引】，指明该词在【哪个数据中出现】以及【出现的次数】。查询时，根据要查找的词找到相应的数据。

*为什么使用es*

随着项目数据量的不断增大，如果继续使用以前的【数据库模糊查询】的方式去查询数据，效率非常低下。

而Es是一种可以【实时存储】和【实时分析】全文搜索引擎，并且数据量很大的时候可以【分布式集群部署】，所以项目中将数据放入es中，以提高查询速度。

### 2. 概念

【索引index】：索引类似于mysql 中的数据库，Elasticesearch 中的索引是存在数据的地方，包含了一堆有相似结构的文档数据。

【类型type】：类型是用来定义数据结构，可以认为是 mysql 中的一张表，es7以后，将逐步移除这个概念，默认_doc。

【映射mapping】：定义了一个索引中每个字段的类型，字段所使用的分词器等，相当于关系型数据库中的表结构。

【文档document】：类似于 MySQL 中的一行数据，不同之处在于 ES 中的每个文档可以有不同的字段，但是对于通用字段应该具有相同的数据类型，文档是es中的最小数据单元，可以认为一个文档就是一条记录。

【字段Field】：Field是Elasticsearch的最小单位，一个document里面有多个field。

【分片shard】：单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。

【副本replica】：任何服务器随时可能故障或宕机，此时 shard 可能会丢失，通过创建 replica 副本，可以在 shard 故障时提供备用服务，保证数据不丢失，另外 replica 还可以提升搜索操作的吞吐量。

### 3.什么是倒排索引

在搜索引擎中，每个文档都有对应的【文档ID】，倒排索引是通过分词策略，形成【关键词】到【文档id】的【关系映射表】，记录了每个关键词在【哪个文档中出现】以及【出现的次数】。

通过关键词查询文档会非常快。

*倒排索引的两个细节：*

- 倒排索引中的所有词项对应一个或多个文档。
- 倒排索引中的【词项】根据字典顺序升序排序。

### 4.text和keyword

两个类型的区别主要是分词：

- keyword 类型不会进行分词，直接把整个字符串内容当做一个关键词，比如：人名可以指定为keyword。
- Text 类型在存入 Elasticsearch 的时候，会先进行分词，可能分成多个关键字，根据分词后的内容建立倒排索引。

### 5.如何实现master选举

*何时会选举：*

master选举当然是由master-eligible节点发起，当一个master-eligible节点发现满足以下条件时发起选举：

1. 当前master eligible节点不是master
2. 当前master eligible节点与其它的节点通信无法发现master
3. 集群中无法连接到master的master eligible节点数量已达到 `discovery.zen.minimum_master_nodes` 所设定的值

*如何选举：*

通过投票选举：

- 先根据节点的clusterStateVersion比较，clusterStateVersion越大，优先级越高
- 当clusterStateVersion相同时，节点的Id越小，优先级越高
- 如果对某个节点的投票数达到阈值，并且该节点自己也选举自己，那这个节点就是master；否则重新选举一直到满足上述条件。

### 6.ES写数据的整体流程

1. 客户端选择 ES 的某个节点发送请求过去，这个节点就是协调节点 coordinating node
2. coordinating node 对 document 进行路由，找到文档对应的主分片所在的节点，将请求转发给这个节点。
3. 节点上的 primary shard 处理请求，然后将数据同步到 replica node。
4. coordinating node 等到 primary node 和所有 replica node 都执行成功之后，最后返回响应结果给客户端。

### 7.ES的搜索流程

搜索被执行成一个两阶段过程，即 Query 和 Fetch：

*Query阶段：*

在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。
备注：在搜索的时候是会查询 Filesystem Cache 的，但是有部分数据还在 MemoryBuffer，所以搜索是近实时的。
每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。

*Fetch阶段：*

协调节点根据 Query阶段产生的结果，去各个节点上查询 docId 实际的 document 内容，最后由协调节点返回结果给客户端。

### 8.解决脑裂问题

*可能的成因：*

1. 网络问题：集群间的网络延迟导致一些节点访问不到 master，认为 master 挂掉了从而选举出新的master，并对 master 上的分片和副本标红，分配新的主分片
2. 节点负载：主节点的角色既为 master 又为 data，访问量较大时可能会导致 ES 停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。
3. 内存回收：data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应。

*解决方案：*

1. 减少误判：discovery.zen.ping_timeout 超时时间，默认3s,也就是3s内没有响应就判断Wie下线，可以适当调大参数，比如6s。
2. 角色分离：即 master 节点与 data 节点分离，避免访问量过大导致的延迟。
   - 主节点配置为：node.master: true node.data: false
   - 从节点配置为：node.master: false node.data: true

### 9.笔记脚本

索引操作

<img src="D:/Typora/picture/image-20220720133605789.png" alt="image-20220720133605789" style="zoom:80%;" />

操作映射

<img src="D:/Typora/picture/image-20220720132325927.png" alt="image-20220720132325927" style="zoom:80%;" />

操作文档

<img src="D:/Typora/picture/image-20220720133507315.png" alt="image-20220720133507315" style="zoom:80%;" />

演示

```shell
GET myindex
GET _cat/indices?v

# 创建索引person
PUT person
GET person
DELETE myindex

#添加映射
PUT person/_mapping
{
  "properties":{
    "name":{
      "type":"keyword"
    },
    "age":{
      "type":"integer"
    }
  }
}

#查询映射
GET person/_mapping

# 创建索引并添加映射
PUT person1
{
  "mappings":{
    "properties": {
      "name":{
        "type": "keyword"
      },
      "age":{
        "type": "integer"
      }
    }
  }
}

# 添加映射
PUT person/_mapping
{
  "properties":{
    "address":{
      "type":"text"
    }
  }
}

# 添加文档，可以指定id，也可以不指定
PUT person/_doc/1
{
  "name":"张三",
  "age":"20",
  "address":"北京海淀区"
}
#查询文档
DELETE person/_doc/HsETGoIBiLOSXaDhf4aW
GET person/_search

POST person/_doc/2
{
  "name":"李四",
  "age":"30",
  "address":"北京昌平区"
}
PUT person/_doc/3
{
  "name":"王五2号",
  "age":"25",
  "address":"北京朝阳区"
}


GET _analyze
{
  "analyzer": "standard",
  "text":"我爱北京天安门"
}
GET _analyze
{
  "analyzer": "standard",
  "text":"I love beijing tiananmen"
}
GET _analyze
{
  "analyzer": "ik_smart",
  "text":"我爱北京天安门"
}
GET _analyze
{
  "analyzer": "ik_max_word",
  "text":"我爱北京天安门"
}

PUT person/_doc/4
{
  "name":"王五",
  "age":"25",
  "address":"华为5g手机"
}
GET person/_search
#查不到数据，因为默认使用的分词器是standard。
GET person/_search
{
  "query": {
    "term": {
      "address": {
        "value": "北京"
      }
    }
  }
}

#添加映射时，指定ik分词器
PUT person
{
  "mappings": {
    "properties": {
      "name":{
        "type":"keyword"
      },
      "address":{
        "type":"text",
        "analyzer":"ik_max_word"
      }
    }
  }
}

#match查询
GET person/_search
{
  "query":{
    "match":{
      "address":"华为手机"
    }
  }
}
# match_all
GET person/_search
{
  "query": {
    "match_all": {}
  },
  "from": 0,
  "size": 2
}
#+++++++++++++++++++++++++++++++++++++++++
PUT student_index_v1
{
  "mappings": {
    "properties": {
      "brithday":{
        "type": "date"
      }
    }
  }
}
GET student_index_v2/_search
PUT student_index_v1/_doc/1
{
  "birthday":"1999-11-11"
}
# 重建一个索引
DELETE student_index_v2
PUT student_index_v2
{
  "mappings": {
    "properties": {
      "brithday":{
        "type": "text"
      }
    }
  }
}
#_reindex 拷贝数据
POST _reindex
{
  "source": {
    "index": "student_index_v1"
  }
  , "dest": {
    "index": "student_index_v2"
  }
}
PUT student_index_v2/_doc/2
{
  "brithday":"1999年11月11日"
}
#重建后，删除student_index_v1,然后将新的索引别名修改位student_index_v1,避免了修改源代码。
DELETE student_index_v1
POST student_index_v2/_alias/student_index_v1
GET student_index_v1/_search
GET student_index_v2/_search
```

查询文档

<img src="D:/Typora/picture/image-20220720141944777.png" alt="image-20220720141944777" style="zoom:80%;" />





# 9. MYDB

## 9.0 概述

### 9.0.1 五个模块

1. Transaction Manager（TM） 
2. Data Manager（DM） 
3. Version Manager（VM） 
4. Index Manager（IM） 
5. Table Manager（TBM）

### 9.0.2 主要功能

- 数据的可靠性和数据恢复
- 两段锁协议（2PL）实现可串行化调度 
- MVCC 
- 两种事务隔离级别（读提交和可重复读） 
- 死锁处理 
- 简单的表和字段管理 
- 简单的 SQL 解析
- 基于 socket 的 server 和 client

### 9.0.3 各模块功能

项目描述：使用 Java 语言实现了简易的 MySQL 数据库，主要内容包括以下五个模块：

1. 事务管理模块：通过维护 XID 文件来维护事务的状态，事务 id 自增，并提供接口供其他模块来查询某个事务的状态。
2. 数据管理模块：直接管理数据库 DB 文件和日志文件。主要职责有：

   - 实现了 DB 文件的【分页管理】，并使用引用计数法实现【页面缓存】；
   - 管理日志文件，记录【写前日志】，保证在发生错误时可以根据日志进行【恢复】；
   - 抽象 DB 文件为 DataItem 供上层模块使用，并提供缓存。 
3. 版本管理模块：基于两段锁协议实现了调度序列的【可串行化】，实现了【MVCC】，实现了读已提交和可重复读【两种隔离级别】，解决了【死锁】问题。
4. 索引模块：实现了基于【B+树】的索引，where 条件中支持有索引的字段。 
5. 表字段管理模块：实现了对【字段】和【表】的管理，解析 SQL 语句，并根据语句操作表。

# 10 数据结构与算法

## 10.1 红黑树

AVL树要求左右子树高度差不能超过1，每次进行插入/删除操作时，可能会需要通过多次旋转操作保持平衡，频繁的插入/删除操作会使得性能下降很多。

红黑树相比AVL树，查询操作会牺牲一点性能，但是插入/删除操作避免了过多的自旋操作，整体性能更稳定，易于维护，插入/删除操作比较多时，红黑树整体性能略优于AVL树。

查询操作时间复杂度：红黑树满足到所有叶子结点经过的黑色节点数量相同，所以到叶子结点的最长路径不超过最短路径的2倍，整体时间复杂度还是log(n)。

插入/删除操作时间复杂度，每次操作平均要旋转一次和变换颜色,旋转操作的时间复杂度是O(1)，整体时间复杂度还是log(n)。



实质上红黑树是对【概念模型2-3-4树】的一种实现，2-3-4树的实现需要维护多种节点，比较复杂，所以选择以二叉树为基础，在二叉树的节点属性中加入一个【颜色属性】来表示2-3-4树中不同的节点。

2-3-4树中的【2节点】对应着红黑树中的【黑节点】，而2-3-4树中的【3节点或4节点】是以【红节点+黑节点】的方式存在，【红节点的意义】是与黑色父节点结合，表达2-3-4树中的3，4节点。

2-3-4树是【绝对平衡】的树，到所有叶子节点的距离相同，对应到红黑树中就是每个节点到叶子节点经过的【黑色节点数量相同】。
